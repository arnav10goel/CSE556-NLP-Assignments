{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.nn as nn\n",
    "from torch.optim import Adam\n",
    "from sklearn.metrics import f1_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 1\n",
    "- Loading validation embeddings for task 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the embeddings from the validation set\n",
    "val_embeddings_file = \"val_embeddings.pkl\"\n",
    "val_embeddings_loaded = pickle.load(open(val_embeddings_file, \"rb\"))\n",
    "\n",
    "# Load the labels from the validation set\n",
    "task1_val_labels = \"task1_labels_dev.pkl\"\n",
    "task1_val_labels_loaded = pickle.load(open(task1_val_labels, \"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode the labels by a fixed mapping\n",
    "mapping = {\n",
    "    \"-1\": 0,\n",
    "    \"sadness\": 1,\n",
    "    \"joy\": 2,\n",
    "    \"fear\": 3,\n",
    "    \"anger\": 4,\n",
    "    \"surprise\": 5,\n",
    "    \"disgust\": 6,\n",
    "    \"neutral\": 7\n",
    "}\n",
    "\n",
    "# Convert the labels to integers\n",
    "val_labels = [np.array([mapping[str(label)] for label in task1_val_labels_loaded[key]]) for key in task1_val_labels_loaded.keys()]\n",
    "\n",
    "# Convert the embeddings to a list\n",
    "val_embeddings = [val_embeddings_loaded[key] for key in val_embeddings_loaded.keys()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset Class and Dataloader for Validation Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EmotionDataset(Dataset):\n",
    "    def __init__(self, embeddings, labels):\n",
    "        self.embeddings = embeddings  # List of embedding matrices\n",
    "        self.labels = labels  # List of label arrays\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.embeddings)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return torch.tensor(self.embeddings[idx]), torch.tensor(self.labels[idx], dtype=torch.long)\n",
    "    \n",
    "def collate_fn(batch):\n",
    "    embeddings, labels = zip(*batch)\n",
    "    embeddings_pad = torch.nn.utils.rnn.pad_sequence(embeddings, batch_first=True, padding_value=0)\n",
    "    labels_pad = torch.nn.utils.rnn.pad_sequence(labels, batch_first=True, padding_value=-1)  # Use -1 for padding\n",
    "    return embeddings_pad, labels_pad\n",
    "\n",
    "# Make val dataset and dataloader\n",
    "val_dataset = EmotionDataset(val_embeddings, val_labels)\n",
    "val_dataloader = DataLoader(val_dataset, batch_size=32, shuffle=False, collate_fn=collate_fn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model - M1 (Task 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "class RNNModel(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size, num_layers=1):\n",
    "        super(RNNModel, self).__init__()\n",
    "        self.rnn = nn.RNN(input_size, hidden_size, num_layers, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_size, output_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        output, _ = self.rnn(x)\n",
    "        output = self.fc(output)\n",
    "        return output\n",
    "    \n",
    "# Initialize the model\n",
    "INPUT_SIZE = 384 # Dimension of the input embeddings\n",
    "HIDDEN_SIZE = 128 # Dimension of the hidden state\n",
    "OUTPUT_SIZE = 8 # Number of classes\n",
    "\n",
    "model = RNNModel(INPUT_SIZE, HIDDEN_SIZE, OUTPUT_SIZE)\n",
    "\n",
    "# Load the model from the saved state\n",
    "TASK_1_MODEL_PATH = \"M1_Task1.pth\"\n",
    "model.load_state_dict(torch.load(TASK_1_MODEL_PATH))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute F1 metrics\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "# Predictions and labels should be flattened arrays\n",
    "def compute_metrics(predictions, labels):\n",
    "    mask = labels != -1  # Ignore padded labels\n",
    "    masked_labels = labels[mask]\n",
    "    masked_predictions = predictions[mask]\n",
    "    weighted_f1 = f1_score(masked_labels, masked_predictions, average='weighted')\n",
    "    macro_f1 = f1_score(masked_labels, masked_predictions, average='macro')\n",
    "    return weighted_f1, macro_f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Weighted F1: 0.8887216999599405\n",
      "Validation Macro F1: 0.8618793949235899\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model on the validation set\n",
    "model.eval()\n",
    "val_predictions = []\n",
    "val_labels = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for embeddings, labels in val_dataloader:\n",
    "        output = model(embeddings)\n",
    "        \n",
    "        # Flatten the output and labels\n",
    "        output = output.view(-1, output.shape[-1])\n",
    "        labels = labels.view(-1)\n",
    "\n",
    "        # Get the predictions\n",
    "        predictions = output.argmax(dim=-1)\n",
    "\n",
    "        val_predictions.append(predictions.detach().cpu().numpy())\n",
    "        val_labels.append(labels.detach().cpu().numpy())\n",
    "\n",
    "val_predictions = np.concatenate(val_predictions)\n",
    "val_labels = np.concatenate(val_labels)\n",
    "\n",
    "weighted_f1_val, macro_f1_val = compute_metrics(val_predictions, val_labels)\n",
    "\n",
    "# Print the F1 scores\n",
    "print(\"Validation Weighted F1:\", weighted_f1_val)\n",
    "print(\"Validation Macro F1:\", macro_f1_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing Model M1 on a Test Set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- I am assuming the test set is in the same format as train and validation json files\n",
    "- I will load the json file here and compute the sentence-bert embeddings\n",
    "- Will then follow same methodology as above for computing F1 score over that"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import pickle\n",
    "\n",
    "# Load the model\n",
    "model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "\n",
    "# Import the test json file\n",
    "TEST_PATH = \"test.json\"\n",
    "with open(TEST_PATH) as f:\n",
    "    test_data = json.load(f)\n",
    "\n",
    "# Store the embeddings in a dictionary\n",
    "test_embeddings_dict = {}\n",
    "i = 0\n",
    "\n",
    "for test_dict in test_data:\n",
    "    # Get the relevant information from the dictionary\n",
    "    episode_key = test_dict[\"episode\"]\n",
    "    utterances = test_dict[\"utterances\"]\n",
    "\n",
    "    # Generate embeddings for the utterances\n",
    "    embeddings = model.encode(utterances)\n",
    "    i+=1\n",
    "    # Print the episode key\n",
    "    print(i)\n",
    "\n",
    "    # Store the embedding\n",
    "    test_embeddings_dict[episode_key] = embeddings"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
