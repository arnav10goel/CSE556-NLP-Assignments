{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from torch.nn.utils.rnn import pack_padded_sequence, pad_packed_sequence\n",
    "import random\n",
    "\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "import pickle\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Function to Load the Test Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to load the data from the json file\n",
    "def load_from_json(file_path):\n",
    "    with open(file_path, \"r\") as file:\n",
    "        data = json.load(file)\n",
    "    return data\n",
    "\n",
    "\"\"\"\n",
    "Task 1 - Embeddings\n",
    "\"\"\"\n",
    "fasttext_task1 = \"Task1_Fasttext_test_embeddings.pkl\"\n",
    "glove_task1 = \"Task1_GLoVe_test_embeddings.pkl\"\n",
    "word2vec_task1 = \"Task1_Word2Vec_test_embeddings.pkl\"\n",
    "\n",
    "# Load the embeddings\n",
    "fasttext_embeddings = pickle.load(open(fasttext_task1, \"rb\"))\n",
    "glove_embeddings = pickle.load(open(glove_task1, \"rb\"))\n",
    "word2vec_embeddings = pickle.load(open(word2vec_task1, \"rb\"))\n",
    "\n",
    "# Load the test labels\n",
    "test_label_path = \"NER_test_labels.json\"\n",
    "test_labels = load_from_json(test_label_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Discard sentences with length greater than 174\n",
    "fasttext_task1 = {k: v for k, v in fasttext_embeddings.items() if len(v) <= 174}\n",
    "glove_task1 = {k: v for k, v in glove_embeddings.items() if len(v) <= 174}\n",
    "word2vec_task1 = {k: v for k, v in word2vec_embeddings.items() if len(v) <= 174}\n",
    "\n",
    "test_labels = {k: v for k, v in test_labels.items() if k in fasttext_task1}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Padding the Sequences to the Same Length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(174, 1), (174, 300), (174, 300), (174, 300)\n",
      "(174, 1), (174, 300), (174, 300), (174, 300)\n",
      "(174, 1), (174, 300), (174, 300), (174, 300)\n",
      "(174, 1), (174, 300), (174, 300), (174, 300)\n",
      "(174, 1), (174, 300), (174, 300), (174, 300)\n",
      "(174, 1), (174, 300), (174, 300), (174, 300)\n",
      "(174, 1), (174, 300), (174, 300), (174, 300)\n",
      "(174, 1), (174, 300), (174, 300), (174, 300)\n",
      "(174, 1), (174, 300), (174, 300), (174, 300)\n",
      "(174, 1), (174, 300), (174, 300), (174, 300)\n",
      "(174, 1), (174, 300), (174, 300), (174, 300)\n",
      "(174, 1), (174, 300), (174, 300), (174, 300)\n",
      "(174, 1), (174, 300), (174, 300), (174, 300)\n",
      "(174, 1), (174, 300), (174, 300), (174, 300)\n",
      "(174, 1), (174, 300), (174, 300), (174, 300)\n",
      "(174, 1), (174, 300), (174, 300), (174, 300)\n",
      "(174, 1), (174, 300), (174, 300), (174, 300)\n",
      "(174, 1), (174, 300), (174, 300), (174, 300)\n",
      "(174, 1), (174, 300), (174, 300), (174, 300)\n",
      "(174, 1), (174, 300), (174, 300), (174, 300)\n",
      "(174, 1), (174, 300), (174, 300), (174, 300)\n",
      "(174, 1), (174, 300), (174, 300), (174, 300)\n",
      "(174, 1), (174, 300), (174, 300), (174, 300)\n",
      "(174, 1), (174, 300), (174, 300), (174, 300)\n",
      "(174, 1), (174, 300), (174, 300), (174, 300)\n",
      "(174, 1), (174, 300), (174, 300), (174, 300)\n",
      "(174, 1), (174, 300), (174, 300), (174, 300)\n",
      "(174, 1), (174, 300), (174, 300), (174, 300)\n",
      "(174, 1), (174, 300), (174, 300), (174, 300)\n",
      "(174, 1), (174, 300), (174, 300), (174, 300)\n",
      "(174, 14), (174, 300), (174, 300), (174, 300)\n",
      "(174, 1), (174, 300), (174, 300), (174, 300)\n",
      "(174, 1), (174, 300), (174, 300), (174, 300)\n",
      "(174, 1), (174, 300), (174, 300), (174, 300)\n",
      "(174, 1), (174, 300), (174, 300), (174, 300)\n",
      "(174, 1), (174, 300), (174, 300), (174, 300)\n",
      "(174, 1), (174, 300), (174, 300), (174, 300)\n",
      "(174, 1), (174, 300), (174, 300), (174, 300)\n",
      "(174, 1), (174, 300), (174, 300), (174, 300)\n",
      "(174, 1), (174, 300), (174, 300), (174, 300)\n",
      "(174, 1), (174, 300), (174, 300), (174, 300)\n",
      "(174, 1), (174, 300), (174, 300), (174, 300)\n",
      "(174, 1), (174, 300), (174, 300), (174, 300)\n",
      "(174, 1), (174, 300), (174, 300), (174, 300)\n",
      "(174, 1), (174, 300), (174, 300), (174, 300)\n",
      "(174, 1), (174, 300), (174, 300), (174, 300)\n",
      "(174, 1), (174, 300), (174, 300), (174, 300)\n",
      "(174, 1), (174, 300), (174, 300), (174, 300)\n",
      "(174, 1), (174, 300), (174, 300), (174, 300)\n",
      "(174, 1), (174, 300), (174, 300), (174, 300)\n",
      "(174, 1), (174, 300), (174, 300), (174, 300)\n",
      "(174, 1), (174, 300), (174, 300), (174, 300)\n",
      "(174, 1), (174, 300), (174, 300), (174, 300)\n",
      "(174, 1), (174, 300), (174, 300), (174, 300)\n",
      "(174, 1), (174, 300), (174, 300), (174, 300)\n",
      "(174, 1), (174, 300), (174, 300), (174, 300)\n",
      "(174, 1), (174, 300), (174, 300), (174, 300)\n",
      "(174, 1), (174, 300), (174, 300), (174, 300)\n",
      "(174, 1), (174, 300), (174, 300), (174, 300)\n",
      "(174, 1), (174, 300), (174, 300), (174, 300)\n",
      "(174, 1), (174, 300), (174, 300), (174, 300)\n",
      "(174, 1), (174, 300), (174, 300), (174, 300)\n",
      "(174, 1), (174, 300), (174, 300), (174, 300)\n",
      "(174, 1), (174, 300), (174, 300), (174, 300)\n",
      "(174, 1), (174, 300), (174, 300), (174, 300)\n",
      "(174, 1), (174, 300), (174, 300), (174, 300)\n",
      "(174, 1), (174, 300), (174, 300), (174, 300)\n",
      "(174, 1), (174, 300), (174, 300), (174, 300)\n",
      "(174, 1), (174, 300), (174, 300), (174, 300)\n",
      "(174, 1), (174, 300), (174, 300), (174, 300)\n",
      "(174, 1), (174, 300), (174, 300), (174, 300)\n",
      "(174, 1), (174, 300), (174, 300), (174, 300)\n",
      "(174, 13), (174, 300), (174, 300), (174, 300)\n",
      "(174, 1), (174, 300), (174, 300), (174, 300)\n",
      "(174, 11), (174, 300), (174, 300), (174, 300)\n",
      "(174, 1), (174, 300), (174, 300), (174, 300)\n",
      "(174, 1), (174, 300), (174, 300), (174, 300)\n",
      "(174, 1), (174, 300), (174, 300), (174, 300)\n",
      "(174, 1), (174, 300), (174, 300), (174, 300)\n",
      "(174, 11), (174, 300), (174, 300), (174, 300)\n",
      "(174, 1), (174, 300), (174, 300), (174, 300)\n",
      "(174, 1), (174, 300), (174, 300), (174, 300)\n",
      "(174, 1), (174, 300), (174, 300), (174, 300)\n",
      "(174, 1), (174, 300), (174, 300), (174, 300)\n",
      "(174, 1), (174, 300), (174, 300), (174, 300)\n",
      "(174, 1), (174, 300), (174, 300), (174, 300)\n",
      "(174, 1), (174, 300), (174, 300), (174, 300)\n",
      "(174, 1), (174, 300), (174, 300), (174, 300)\n",
      "(174, 1), (174, 300), (174, 300), (174, 300)\n",
      "(174, 1), (174, 300), (174, 300), (174, 300)\n",
      "(174, 1), (174, 300), (174, 300), (174, 300)\n",
      "(174, 1), (174, 300), (174, 300), (174, 300)\n",
      "(174, 1), (174, 300), (174, 300), (174, 300)\n",
      "(174, 1), (174, 300), (174, 300), (174, 300)\n",
      "(174, 1), (174, 300), (174, 300), (174, 300)\n",
      "(174, 1), (174, 300), (174, 300), (174, 300)\n",
      "(174, 1), (174, 300), (174, 300), (174, 300)\n",
      "(174, 1), (174, 300), (174, 300), (174, 300)\n",
      "(174, 1), (174, 300), (174, 300), (174, 300)\n",
      "(174, 1), (174, 300), (174, 300), (174, 300)\n",
      "(174, 1), (174, 300), (174, 300), (174, 300)\n",
      "(174, 1), (174, 300), (174, 300), (174, 300)\n",
      "(174, 1), (174, 300), (174, 300), (174, 300)\n",
      "(174, 1), (174, 300), (174, 300), (174, 300)\n",
      "(174, 1), (174, 300), (174, 300), (174, 300)\n",
      "(174, 1), (174, 300), (174, 300), (174, 300)\n",
      "(174, 1), (174, 300), (174, 300), (174, 300)\n",
      "(174, 1), (174, 300), (174, 300), (174, 300)\n",
      "(174, 1), (174, 300), (174, 300), (174, 300)\n",
      "(174, 1), (174, 300), (174, 300), (174, 300)\n",
      "(174, 1), (174, 300), (174, 300), (174, 300)\n",
      "(174, 1), (174, 300), (174, 300), (174, 300)\n",
      "(174, 1), (174, 300), (174, 300), (174, 300)\n",
      "(174, 1), (174, 300), (174, 300), (174, 300)\n",
      "(174, 1), (174, 300), (174, 300), (174, 300)\n",
      "(174, 1), (174, 300), (174, 300), (174, 300)\n",
      "(174, 1), (174, 300), (174, 300), (174, 300)\n",
      "(174, 1), (174, 300), (174, 300), (174, 300)\n",
      "(174, 1), (174, 300), (174, 300), (174, 300)\n",
      "(174, 1), (174, 300), (174, 300), (174, 300)\n",
      "(174, 1), (174, 300), (174, 300), (174, 300)\n",
      "(174, 1), (174, 300), (174, 300), (174, 300)\n",
      "(174, 11), (174, 300), (174, 300), (174, 300)\n",
      "(174, 1), (174, 300), (174, 300), (174, 300)\n",
      "(174, 1), (174, 300), (174, 300), (174, 300)\n",
      "(174, 1), (174, 300), (174, 300), (174, 300)\n",
      "(174, 1), (174, 300), (174, 300), (174, 300)\n",
      "(174, 1), (174, 300), (174, 300), (174, 300)\n",
      "(174, 1), (174, 300), (174, 300), (174, 300)\n",
      "(174, 1), (174, 300), (174, 300), (174, 300)\n",
      "(174, 11), (174, 300), (174, 300), (174, 300)\n",
      "(174, 1), (174, 300), (174, 300), (174, 300)\n",
      "(174, 1), (174, 300), (174, 300), (174, 300)\n",
      "(174, 1), (174, 300), (174, 300), (174, 300)\n",
      "(174, 1), (174, 300), (174, 300), (174, 300)\n",
      "(174, 1), (174, 300), (174, 300), (174, 300)\n",
      "(174, 1), (174, 300), (174, 300), (174, 300)\n",
      "(174, 1), (174, 300), (174, 300), (174, 300)\n",
      "(174, 1), (174, 300), (174, 300), (174, 300)\n",
      "(174, 1), (174, 300), (174, 300), (174, 300)\n",
      "(174, 1), (174, 300), (174, 300), (174, 300)\n",
      "(174, 1), (174, 300), (174, 300), (174, 300)\n",
      "(174, 1), (174, 300), (174, 300), (174, 300)\n",
      "(174, 1), (174, 300), (174, 300), (174, 300)\n",
      "(174, 1), (174, 300), (174, 300), (174, 300)\n",
      "(174, 1), (174, 300), (174, 300), (174, 300)\n",
      "(174, 1), (174, 300), (174, 300), (174, 300)\n",
      "(174, 1), (174, 300), (174, 300), (174, 300)\n",
      "(174, 1), (174, 300), (174, 300), (174, 300)\n",
      "(174, 1), (174, 300), (174, 300), (174, 300)\n",
      "(174, 1), (174, 300), (174, 300), (174, 300)\n",
      "(174, 1), (174, 300), (174, 300), (174, 300)\n",
      "(174, 1), (174, 300), (174, 300), (174, 300)\n",
      "(174, 13), (174, 300), (174, 300), (174, 300)\n",
      "(174, 7), (174, 300), (174, 300), (174, 300)\n",
      "(174, 1), (174, 300), (174, 300), (174, 300)\n",
      "(174, 1), (174, 300), (174, 300), (174, 300)\n",
      "(174, 1), (174, 300), (174, 300), (174, 300)\n",
      "(174, 1), (174, 300), (174, 300), (174, 300)\n",
      "(174, 1), (174, 300), (174, 300), (174, 300)\n",
      "(174, 1), (174, 300), (174, 300), (174, 300)\n",
      "(174, 1), (174, 300), (174, 300), (174, 300)\n",
      "(174, 1), (174, 300), (174, 300), (174, 300)\n",
      "(174, 1), (174, 300), (174, 300), (174, 300)\n",
      "(174, 1), (174, 300), (174, 300), (174, 300)\n",
      "(174, 1), (174, 300), (174, 300), (174, 300)\n",
      "(174, 1), (174, 300), (174, 300), (174, 300)\n",
      "(174, 1), (174, 300), (174, 300), (174, 300)\n",
      "(174, 1), (174, 300), (174, 300), (174, 300)\n",
      "(174, 1), (174, 300), (174, 300), (174, 300)\n",
      "(174, 1), (174, 300), (174, 300), (174, 300)\n",
      "(174, 1), (174, 300), (174, 300), (174, 300)\n",
      "(174, 5), (174, 300), (174, 300), (174, 300)\n",
      "(174, 1), (174, 300), (174, 300), (174, 300)\n",
      "(174, 1), (174, 300), (174, 300), (174, 300)\n",
      "(174, 12), (174, 300), (174, 300), (174, 300)\n",
      "(174, 1), (174, 300), (174, 300), (174, 300)\n",
      "(174, 1), (174, 300), (174, 300), (174, 300)\n",
      "(174, 1), (174, 300), (174, 300), (174, 300)\n",
      "(174, 1), (174, 300), (174, 300), (174, 300)\n",
      "(174, 1), (174, 300), (174, 300), (174, 300)\n",
      "(174, 1), (174, 300), (174, 300), (174, 300)\n",
      "(174, 1), (174, 300), (174, 300), (174, 300)\n",
      "(174, 1), (174, 300), (174, 300), (174, 300)\n",
      "(174, 1), (174, 300), (174, 300), (174, 300)\n",
      "(174, 1), (174, 300), (174, 300), (174, 300)\n",
      "(174, 1), (174, 300), (174, 300), (174, 300)\n",
      "(174, 1), (174, 300), (174, 300), (174, 300)\n",
      "(174, 1), (174, 300), (174, 300), (174, 300)\n",
      "(174, 1), (174, 300), (174, 300), (174, 300)\n",
      "(174, 1), (174, 300), (174, 300), (174, 300)\n",
      "(174, 1), (174, 300), (174, 300), (174, 300)\n",
      "(174, 1), (174, 300), (174, 300), (174, 300)\n",
      "(174, 1), (174, 300), (174, 300), (174, 300)\n",
      "(174, 1), (174, 300), (174, 300), (174, 300)\n",
      "(174, 1), (174, 300), (174, 300), (174, 300)\n",
      "(174, 1), (174, 300), (174, 300), (174, 300)\n",
      "(174, 1), (174, 300), (174, 300), (174, 300)\n",
      "(174, 1), (174, 300), (174, 300), (174, 300)\n",
      "(174, 11), (174, 300), (174, 300), (174, 300)\n",
      "(174, 1), (174, 300), (174, 300), (174, 300)\n",
      "(174, 1), (174, 300), (174, 300), (174, 300)\n",
      "(174, 1), (174, 300), (174, 300), (174, 300)\n",
      "(174, 1), (174, 300), (174, 300), (174, 300)\n",
      "(174, 1), (174, 300), (174, 300), (174, 300)\n",
      "(174, 1), (174, 300), (174, 300), (174, 300)\n",
      "(174, 1), (174, 300), (174, 300), (174, 300)\n",
      "(174, 1), (174, 300), (174, 300), (174, 300)\n",
      "(174, 1), (174, 300), (174, 300), (174, 300)\n",
      "(174, 1), (174, 300), (174, 300), (174, 300)\n",
      "(174, 1), (174, 300), (174, 300), (174, 300)\n",
      "(174, 1), (174, 300), (174, 300), (174, 300)\n",
      "(174, 1), (174, 300), (174, 300), (174, 300)\n",
      "(174, 1), (174, 300), (174, 300), (174, 300)\n",
      "(174, 1), (174, 300), (174, 300), (174, 300)\n",
      "(174, 1), (174, 300), (174, 300), (174, 300)\n",
      "(174, 1), (174, 300), (174, 300), (174, 300)\n",
      "(174, 11), (174, 300), (174, 300), (174, 300)\n",
      "(174, 1), (174, 300), (174, 300), (174, 300)\n",
      "(174, 1), (174, 300), (174, 300), (174, 300)\n",
      "(174, 1), (174, 300), (174, 300), (174, 300)\n",
      "(174, 1), (174, 300), (174, 300), (174, 300)\n",
      "(174, 1), (174, 300), (174, 300), (174, 300)\n",
      "(174, 1), (174, 300), (174, 300), (174, 300)\n",
      "(174, 11), (174, 300), (174, 300), (174, 300)\n",
      "(174, 1), (174, 300), (174, 300), (174, 300)\n",
      "(174, 1), (174, 300), (174, 300), (174, 300)\n",
      "(174, 1), (174, 300), (174, 300), (174, 300)\n",
      "(174, 1), (174, 300), (174, 300), (174, 300)\n",
      "(174, 7), (174, 300), (174, 300), (174, 300)\n",
      "(174, 1), (174, 300), (174, 300), (174, 300)\n",
      "(174, 1), (174, 300), (174, 300), (174, 300)\n",
      "(174, 1), (174, 300), (174, 300), (174, 300)\n",
      "(174, 1), (174, 300), (174, 300), (174, 300)\n",
      "(174, 1), (174, 300), (174, 300), (174, 300)\n",
      "(174, 1), (174, 300), (174, 300), (174, 300)\n",
      "(174, 1), (174, 300), (174, 300), (174, 300)\n",
      "(174, 1), (174, 300), (174, 300), (174, 300)\n",
      "(174, 1), (174, 300), (174, 300), (174, 300)\n",
      "(174, 1), (174, 300), (174, 300), (174, 300)\n",
      "(174, 1), (174, 300), (174, 300), (174, 300)\n",
      "(174, 1), (174, 300), (174, 300), (174, 300)\n",
      "(174, 1), (174, 300), (174, 300), (174, 300)\n",
      "(174, 1), (174, 300), (174, 300), (174, 300)\n",
      "(174, 1), (174, 300), (174, 300), (174, 300)\n",
      "(174, 1), (174, 300), (174, 300), (174, 300)\n",
      "(174, 1), (174, 300), (174, 300), (174, 300)\n",
      "(174, 1), (174, 300), (174, 300), (174, 300)\n",
      "(174, 1), (174, 300), (174, 300), (174, 300)\n",
      "(174, 1), (174, 300), (174, 300), (174, 300)\n",
      "(174, 1), (174, 300), (174, 300), (174, 300)\n",
      "(174, 1), (174, 300), (174, 300), (174, 300)\n",
      "(174, 1), (174, 300), (174, 300), (174, 300)\n",
      "(174, 1), (174, 300), (174, 300), (174, 300)\n",
      "(174, 1), (174, 300), (174, 300), (174, 300)\n",
      "(174, 1), (174, 300), (174, 300), (174, 300)\n",
      "(174, 1), (174, 300), (174, 300), (174, 300)\n",
      "(174, 1), (174, 300), (174, 300), (174, 300)\n",
      "(174, 1), (174, 300), (174, 300), (174, 300)\n",
      "(174, 1), (174, 300), (174, 300), (174, 300)\n",
      "(174, 1), (174, 300), (174, 300), (174, 300)\n",
      "(174, 1), (174, 300), (174, 300), (174, 300)\n",
      "(174, 1), (174, 300), (174, 300), (174, 300)\n",
      "(174, 1), (174, 300), (174, 300), (174, 300)\n",
      "(174, 1), (174, 300), (174, 300), (174, 300)\n",
      "(174, 1), (174, 300), (174, 300), (174, 300)\n",
      "(174, 1), (174, 300), (174, 300), (174, 300)\n",
      "(174, 1), (174, 300), (174, 300), (174, 300)\n",
      "(174, 1), (174, 300), (174, 300), (174, 300)\n",
      "(174, 1), (174, 300), (174, 300), (174, 300)\n",
      "(174, 1), (174, 300), (174, 300), (174, 300)\n",
      "(174, 1), (174, 300), (174, 300), (174, 300)\n",
      "(174, 1), (174, 300), (174, 300), (174, 300)\n",
      "(174, 1), (174, 300), (174, 300), (174, 300)\n",
      "(174, 1), (174, 300), (174, 300), (174, 300)\n",
      "(174, 1), (174, 300), (174, 300), (174, 300)\n",
      "(174, 1), (174, 300), (174, 300), (174, 300)\n",
      "(174, 1), (174, 300), (174, 300), (174, 300)\n",
      "(174, 1), (174, 300), (174, 300), (174, 300)\n",
      "(174, 1), (174, 300), (174, 300), (174, 300)\n",
      "(174, 1), (174, 300), (174, 300), (174, 300)\n",
      "(174, 1), (174, 300), (174, 300), (174, 300)\n",
      "(174, 1), (174, 300), (174, 300), (174, 300)\n",
      "(174, 1), (174, 300), (174, 300), (174, 300)\n",
      "(174, 1), (174, 300), (174, 300), (174, 300)\n",
      "(174, 1), (174, 300), (174, 300), (174, 300)\n",
      "(174, 1), (174, 300), (174, 300), (174, 300)\n",
      "(174, 1), (174, 300), (174, 300), (174, 300)\n",
      "(174, 1), (174, 300), (174, 300), (174, 300)\n",
      "(174, 1), (174, 300), (174, 300), (174, 300)\n",
      "(174, 1), (174, 300), (174, 300), (174, 300)\n",
      "(174, 1), (174, 300), (174, 300), (174, 300)\n",
      "(174, 1), (174, 300), (174, 300), (174, 300)\n",
      "(174, 1), (174, 300), (174, 300), (174, 300)\n",
      "(174, 1), (174, 300), (174, 300), (174, 300)\n",
      "(174, 1), (174, 300), (174, 300), (174, 300)\n",
      "(174, 1), (174, 300), (174, 300), (174, 300)\n",
      "(174, 1), (174, 300), (174, 300), (174, 300)\n",
      "(174, 11), (174, 300), (174, 300), (174, 300)\n",
      "(174, 1), (174, 300), (174, 300), (174, 300)\n",
      "(174, 1), (174, 300), (174, 300), (174, 300)\n",
      "(174, 1), (174, 300), (174, 300), (174, 300)\n",
      "(174, 1), (174, 300), (174, 300), (174, 300)\n",
      "(174, 1), (174, 300), (174, 300), (174, 300)\n",
      "(174, 1), (174, 300), (174, 300), (174, 300)\n",
      "(174, 1), (174, 300), (174, 300), (174, 300)\n",
      "(174, 1), (174, 300), (174, 300), (174, 300)\n",
      "(174, 1), (174, 300), (174, 300), (174, 300)\n",
      "(174, 1), (174, 300), (174, 300), (174, 300)\n",
      "(174, 1), (174, 300), (174, 300), (174, 300)\n",
      "(174, 1), (174, 300), (174, 300), (174, 300)\n",
      "(174, 1), (174, 300), (174, 300), (174, 300)\n",
      "(174, 1), (174, 300), (174, 300), (174, 300)\n",
      "(174, 1), (174, 300), (174, 300), (174, 300)\n",
      "(174, 1), (174, 300), (174, 300), (174, 300)\n",
      "(174, 1), (174, 300), (174, 300), (174, 300)\n",
      "(174, 1), (174, 300), (174, 300), (174, 300)\n",
      "(174, 1), (174, 300), (174, 300), (174, 300)\n",
      "(174, 1), (174, 300), (174, 300), (174, 300)\n",
      "(174, 1), (174, 300), (174, 300), (174, 300)\n",
      "(174, 1), (174, 300), (174, 300), (174, 300)\n",
      "(174, 1), (174, 300), (174, 300), (174, 300)\n",
      "(174, 1), (174, 300), (174, 300), (174, 300)\n",
      "(174, 1), (174, 300), (174, 300), (174, 300)\n",
      "(174, 1), (174, 300), (174, 300), (174, 300)\n",
      "(174, 13), (174, 300), (174, 300), (174, 300)\n",
      "(174, 1), (174, 300), (174, 300), (174, 300)\n",
      "(174, 1), (174, 300), (174, 300), (174, 300)\n",
      "(174, 1), (174, 300), (174, 300), (174, 300)\n",
      "(174, 1), (174, 300), (174, 300), (174, 300)\n",
      "(174, 1), (174, 300), (174, 300), (174, 300)\n",
      "(174, 1), (174, 300), (174, 300), (174, 300)\n",
      "(174, 1), (174, 300), (174, 300), (174, 300)\n",
      "(174, 1), (174, 300), (174, 300), (174, 300)\n",
      "(174, 1), (174, 300), (174, 300), (174, 300)\n",
      "(174, 1), (174, 300), (174, 300), (174, 300)\n",
      "(174, 1), (174, 300), (174, 300), (174, 300)\n",
      "(174, 1), (174, 300), (174, 300), (174, 300)\n",
      "(174, 1), (174, 300), (174, 300), (174, 300)\n",
      "(174, 1), (174, 300), (174, 300), (174, 300)\n",
      "(174, 1), (174, 300), (174, 300), (174, 300)\n",
      "(174, 1), (174, 300), (174, 300), (174, 300)\n",
      "(174, 1), (174, 300), (174, 300), (174, 300)\n",
      "(174, 1), (174, 300), (174, 300), (174, 300)\n",
      "(174, 1), (174, 300), (174, 300), (174, 300)\n",
      "(174, 1), (174, 300), (174, 300), (174, 300)\n",
      "(174, 1), (174, 300), (174, 300), (174, 300)\n",
      "(174, 1), (174, 300), (174, 300), (174, 300)\n",
      "(174, 1), (174, 300), (174, 300), (174, 300)\n",
      "(174, 1), (174, 300), (174, 300), (174, 300)\n",
      "(174, 1), (174, 300), (174, 300), (174, 300)\n",
      "(174, 1), (174, 300), (174, 300), (174, 300)\n",
      "(174, 1), (174, 300), (174, 300), (174, 300)\n",
      "(174, 9), (174, 300), (174, 300), (174, 300)\n",
      "(174, 1), (174, 300), (174, 300), (174, 300)\n",
      "(174, 1), (174, 300), (174, 300), (174, 300)\n",
      "(174, 1), (174, 300), (174, 300), (174, 300)\n",
      "(174, 1), (174, 300), (174, 300), (174, 300)\n",
      "(174, 1), (174, 300), (174, 300), (174, 300)\n",
      "(174, 1), (174, 300), (174, 300), (174, 300)\n",
      "(174, 1), (174, 300), (174, 300), (174, 300)\n",
      "(174, 1), (174, 300), (174, 300), (174, 300)\n",
      "(174, 1), (174, 300), (174, 300), (174, 300)\n",
      "(174, 1), (174, 300), (174, 300), (174, 300)\n",
      "(174, 1), (174, 300), (174, 300), (174, 300)\n",
      "(174, 1), (174, 300), (174, 300), (174, 300)\n",
      "(174, 1), (174, 300), (174, 300), (174, 300)\n",
      "(174, 1), (174, 300), (174, 300), (174, 300)\n",
      "(174, 1), (174, 300), (174, 300), (174, 300)\n",
      "(174, 1), (174, 300), (174, 300), (174, 300)\n",
      "(174, 1), (174, 300), (174, 300), (174, 300)\n",
      "(174, 1), (174, 300), (174, 300), (174, 300)\n",
      "(174, 1), (174, 300), (174, 300), (174, 300)\n",
      "(174, 1), (174, 300), (174, 300), (174, 300)\n",
      "(174, 1), (174, 300), (174, 300), (174, 300)\n",
      "(174, 1), (174, 300), (174, 300), (174, 300)\n",
      "(174, 1), (174, 300), (174, 300), (174, 300)\n",
      "(174, 1), (174, 300), (174, 300), (174, 300)\n",
      "(174, 1), (174, 300), (174, 300), (174, 300)\n",
      "(174, 1), (174, 300), (174, 300), (174, 300)\n",
      "(174, 1), (174, 300), (174, 300), (174, 300)\n",
      "(174, 1), (174, 300), (174, 300), (174, 300)\n",
      "(174, 1), (174, 300), (174, 300), (174, 300)\n",
      "(174, 1), (174, 300), (174, 300), (174, 300)\n",
      "(174, 1), (174, 300), (174, 300), (174, 300)\n",
      "(174, 1), (174, 300), (174, 300), (174, 300)\n",
      "(174, 1), (174, 300), (174, 300), (174, 300)\n",
      "(174, 1), (174, 300), (174, 300), (174, 300)\n",
      "(174, 1), (174, 300), (174, 300), (174, 300)\n",
      "(174, 1), (174, 300), (174, 300), (174, 300)\n",
      "(174, 1), (174, 300), (174, 300), (174, 300)\n",
      "(174, 1), (174, 300), (174, 300), (174, 300)\n",
      "(174, 1), (174, 300), (174, 300), (174, 300)\n",
      "(174, 1), (174, 300), (174, 300), (174, 300)\n",
      "(174, 1), (174, 300), (174, 300), (174, 300)\n",
      "(174, 1), (174, 300), (174, 300), (174, 300)\n",
      "(174, 9), (174, 300), (174, 300), (174, 300)\n",
      "(174, 1), (174, 300), (174, 300), (174, 300)\n",
      "(174, 1), (174, 300), (174, 300), (174, 300)\n",
      "(174, 1), (174, 300), (174, 300), (174, 300)\n",
      "(174, 1), (174, 300), (174, 300), (174, 300)\n",
      "(174, 1), (174, 300), (174, 300), (174, 300)\n",
      "(174, 1), (174, 300), (174, 300), (174, 300)\n",
      "(174, 1), (174, 300), (174, 300), (174, 300)\n",
      "(174, 1), (174, 300), (174, 300), (174, 300)\n",
      "(174, 1), (174, 300), (174, 300), (174, 300)\n",
      "(174, 1), (174, 300), (174, 300), (174, 300)\n",
      "(174, 1), (174, 300), (174, 300), (174, 300)\n",
      "(174, 1), (174, 300), (174, 300), (174, 300)\n",
      "(174, 1), (174, 300), (174, 300), (174, 300)\n",
      "(174, 1), (174, 300), (174, 300), (174, 300)\n",
      "(174, 1), (174, 300), (174, 300), (174, 300)\n",
      "(174, 1), (174, 300), (174, 300), (174, 300)\n",
      "(174, 1), (174, 300), (174, 300), (174, 300)\n",
      "(174, 1), (174, 300), (174, 300), (174, 300)\n",
      "(174, 1), (174, 300), (174, 300), (174, 300)\n",
      "(174, 1), (174, 300), (174, 300), (174, 300)\n",
      "(174, 1), (174, 300), (174, 300), (174, 300)\n",
      "(174, 1), (174, 300), (174, 300), (174, 300)\n",
      "(174, 1), (174, 300), (174, 300), (174, 300)\n",
      "(174, 1), (174, 300), (174, 300), (174, 300)\n",
      "(174, 1), (174, 300), (174, 300), (174, 300)\n",
      "(174, 1), (174, 300), (174, 300), (174, 300)\n",
      "(174, 1), (174, 300), (174, 300), (174, 300)\n",
      "(174, 1), (174, 300), (174, 300), (174, 300)\n",
      "(174, 1), (174, 300), (174, 300), (174, 300)\n",
      "(174, 1), (174, 300), (174, 300), (174, 300)\n",
      "(174, 1), (174, 300), (174, 300), (174, 300)\n",
      "(174, 1), (174, 300), (174, 300), (174, 300)\n",
      "(174, 1), (174, 300), (174, 300), (174, 300)\n",
      "(174, 1), (174, 300), (174, 300), (174, 300)\n",
      "(174, 1), (174, 300), (174, 300), (174, 300)\n",
      "(174, 1), (174, 300), (174, 300), (174, 300)\n",
      "(174, 1), (174, 300), (174, 300), (174, 300)\n",
      "(174, 5), (174, 300), (174, 300), (174, 300)\n",
      "(174, 1), (174, 300), (174, 300), (174, 300)\n",
      "(174, 1), (174, 300), (174, 300), (174, 300)\n",
      "(174, 1), (174, 300), (174, 300), (174, 300)\n",
      "(174, 1), (174, 300), (174, 300), (174, 300)\n",
      "(174, 1), (174, 300), (174, 300), (174, 300)\n",
      "(174, 1), (174, 300), (174, 300), (174, 300)\n",
      "(174, 1), (174, 300), (174, 300), (174, 300)\n",
      "(174, 1), (174, 300), (174, 300), (174, 300)\n",
      "(174, 1), (174, 300), (174, 300), (174, 300)\n",
      "(174, 1), (174, 300), (174, 300), (174, 300)\n",
      "(174, 1), (174, 300), (174, 300), (174, 300)\n",
      "(174, 1), (174, 300), (174, 300), (174, 300)\n",
      "(174, 1), (174, 300), (174, 300), (174, 300)\n",
      "(174, 1), (174, 300), (174, 300), (174, 300)\n",
      "(174, 1), (174, 300), (174, 300), (174, 300)\n",
      "(174, 1), (174, 300), (174, 300), (174, 300)\n",
      "(174, 1), (174, 300), (174, 300), (174, 300)\n",
      "(174, 1), (174, 300), (174, 300), (174, 300)\n",
      "(174, 1), (174, 300), (174, 300), (174, 300)\n",
      "(174, 1), (174, 300), (174, 300), (174, 300)\n",
      "(174, 1), (174, 300), (174, 300), (174, 300)\n",
      "(174, 1), (174, 300), (174, 300), (174, 300)\n",
      "(174, 1), (174, 300), (174, 300), (174, 300)\n",
      "(174, 11), (174, 300), (174, 300), (174, 300)\n",
      "(174, 11), (174, 300), (174, 300), (174, 300)\n",
      "(174, 1), (174, 300), (174, 300), (174, 300)\n",
      "(174, 1), (174, 300), (174, 300), (174, 300)\n",
      "(174, 1), (174, 300), (174, 300), (174, 300)\n",
      "(174, 11), (174, 300), (174, 300), (174, 300)\n",
      "(174, 1), (174, 300), (174, 300), (174, 300)\n",
      "(174, 1), (174, 300), (174, 300), (174, 300)\n",
      "(174, 1), (174, 300), (174, 300), (174, 300)\n",
      "(174, 1), (174, 300), (174, 300), (174, 300)\n",
      "(174, 1), (174, 300), (174, 300), (174, 300)\n",
      "(174, 1), (174, 300), (174, 300), (174, 300)\n",
      "(174, 1), (174, 300), (174, 300), (174, 300)\n",
      "(174, 1), (174, 300), (174, 300), (174, 300)\n",
      "(174, 1), (174, 300), (174, 300), (174, 300)\n",
      "(174, 1), (174, 300), (174, 300), (174, 300)\n",
      "(174, 1), (174, 300), (174, 300), (174, 300)\n",
      "(174, 1), (174, 300), (174, 300), (174, 300)\n",
      "(174, 1), (174, 300), (174, 300), (174, 300)\n",
      "(174, 1), (174, 300), (174, 300), (174, 300)\n",
      "(174, 1), (174, 300), (174, 300), (174, 300)\n",
      "(174, 1), (174, 300), (174, 300), (174, 300)\n",
      "(174, 1), (174, 300), (174, 300), (174, 300)\n",
      "(174, 1), (174, 300), (174, 300), (174, 300)\n",
      "(174, 1), (174, 300), (174, 300), (174, 300)\n",
      "(174, 14), (174, 300), (174, 300), (174, 300)\n",
      "(174, 1), (174, 300), (174, 300), (174, 300)\n",
      "(174, 1), (174, 300), (174, 300), (174, 300)\n",
      "(174, 1), (174, 300), (174, 300), (174, 300)\n",
      "(174, 1), (174, 300), (174, 300), (174, 300)\n",
      "(174, 1), (174, 300), (174, 300), (174, 300)\n",
      "(174, 1), (174, 300), (174, 300), (174, 300)\n",
      "(174, 11), (174, 300), (174, 300), (174, 300)\n",
      "(174, 1), (174, 300), (174, 300), (174, 300)\n",
      "(174, 1), (174, 300), (174, 300), (174, 300)\n",
      "(174, 1), (174, 300), (174, 300), (174, 300)\n",
      "(174, 1), (174, 300), (174, 300), (174, 300)\n",
      "(174, 1), (174, 300), (174, 300), (174, 300)\n",
      "(174, 1), (174, 300), (174, 300), (174, 300)\n",
      "(174, 1), (174, 300), (174, 300), (174, 300)\n",
      "(174, 1), (174, 300), (174, 300), (174, 300)\n",
      "(174, 1), (174, 300), (174, 300), (174, 300)\n",
      "(174, 1), (174, 300), (174, 300), (174, 300)\n",
      "(174, 1), (174, 300), (174, 300), (174, 300)\n",
      "(174, 1), (174, 300), (174, 300), (174, 300)\n",
      "(174, 14), (174, 300), (174, 300), (174, 300)\n",
      "(174, 1), (174, 300), (174, 300), (174, 300)\n",
      "(174, 1), (174, 300), (174, 300), (174, 300)\n",
      "(174, 1), (174, 300), (174, 300), (174, 300)\n",
      "(174, 1), (174, 300), (174, 300), (174, 300)\n",
      "(174, 1), (174, 300), (174, 300), (174, 300)\n",
      "(174, 1), (174, 300), (174, 300), (174, 300)\n",
      "(174, 1), (174, 300), (174, 300), (174, 300)\n",
      "(174, 1), (174, 300), (174, 300), (174, 300)\n",
      "(174, 1), (174, 300), (174, 300), (174, 300)\n",
      "(174, 1), (174, 300), (174, 300), (174, 300)\n",
      "(174, 1), (174, 300), (174, 300), (174, 300)\n",
      "(174, 1), (174, 300), (174, 300), (174, 300)\n",
      "(174, 1), (174, 300), (174, 300), (174, 300)\n",
      "(174, 1), (174, 300), (174, 300), (174, 300)\n",
      "(174, 1), (174, 300), (174, 300), (174, 300)\n",
      "(174, 1), (174, 300), (174, 300), (174, 300)\n",
      "(174, 1), (174, 300), (174, 300), (174, 300)\n",
      "(174, 1), (174, 300), (174, 300), (174, 300)\n",
      "(174, 1), (174, 300), (174, 300), (174, 300)\n",
      "(174, 1), (174, 300), (174, 300), (174, 300)\n",
      "(174, 1), (174, 300), (174, 300), (174, 300)\n",
      "(174, 1), (174, 300), (174, 300), (174, 300)\n",
      "(174, 1), (174, 300), (174, 300), (174, 300)\n",
      "(174, 1), (174, 300), (174, 300), (174, 300)\n",
      "(174, 1), (174, 300), (174, 300), (174, 300)\n",
      "(174, 1), (174, 300), (174, 300), (174, 300)\n",
      "(174, 1), (174, 300), (174, 300), (174, 300)\n",
      "(174, 1), (174, 300), (174, 300), (174, 300)\n",
      "(174, 1), (174, 300), (174, 300), (174, 300)\n",
      "(174, 1), (174, 300), (174, 300), (174, 300)\n",
      "(174, 1), (174, 300), (174, 300), (174, 300)\n",
      "(174, 1), (174, 300), (174, 300), (174, 300)\n",
      "(174, 1), (174, 300), (174, 300), (174, 300)\n",
      "(174, 1), (174, 300), (174, 300), (174, 300)\n",
      "(174, 1), (174, 300), (174, 300), (174, 300)\n",
      "(174, 1), (174, 300), (174, 300), (174, 300)\n",
      "(174, 1), (174, 300), (174, 300), (174, 300)\n",
      "(174, 1), (174, 300), (174, 300), (174, 300)\n",
      "(174, 1), (174, 300), (174, 300), (174, 300)\n",
      "(174, 1), (174, 300), (174, 300), (174, 300)\n",
      "(174, 1), (174, 300), (174, 300), (174, 300)\n",
      "(174, 1), (174, 300), (174, 300), (174, 300)\n",
      "(174, 13), (174, 300), (174, 300), (174, 300)\n",
      "(174, 1), (174, 300), (174, 300), (174, 300)\n",
      "(174, 1), (174, 300), (174, 300), (174, 300)\n",
      "(174, 1), (174, 300), (174, 300), (174, 300)\n",
      "(174, 1), (174, 300), (174, 300), (174, 300)\n",
      "(174, 1), (174, 300), (174, 300), (174, 300)\n",
      "(174, 1), (174, 300), (174, 300), (174, 300)\n",
      "(174, 1), (174, 300), (174, 300), (174, 300)\n",
      "(174, 1), (174, 300), (174, 300), (174, 300)\n",
      "(174, 1), (174, 300), (174, 300), (174, 300)\n",
      "(174, 1), (174, 300), (174, 300), (174, 300)\n",
      "(174, 1), (174, 300), (174, 300), (174, 300)\n",
      "(174, 1), (174, 300), (174, 300), (174, 300)\n",
      "(174, 1), (174, 300), (174, 300), (174, 300)\n",
      "(174, 1), (174, 300), (174, 300), (174, 300)\n",
      "(174, 1), (174, 300), (174, 300), (174, 300)\n",
      "(174, 1), (174, 300), (174, 300), (174, 300)\n",
      "(174, 1), (174, 300), (174, 300), (174, 300)\n",
      "(174, 1), (174, 300), (174, 300), (174, 300)\n",
      "(174, 1), (174, 300), (174, 300), (174, 300)\n",
      "(174, 1), (174, 300), (174, 300), (174, 300)\n",
      "(174, 1), (174, 300), (174, 300), (174, 300)\n",
      "(174, 1), (174, 300), (174, 300), (174, 300)\n",
      "(174, 1), (174, 300), (174, 300), (174, 300)\n",
      "(174, 1), (174, 300), (174, 300), (174, 300)\n",
      "(174, 1), (174, 300), (174, 300), (174, 300)\n",
      "(174, 14), (174, 300), (174, 300), (174, 300)\n",
      "(174, 1), (174, 300), (174, 300), (174, 300)\n",
      "(174, 1), (174, 300), (174, 300), (174, 300)\n",
      "(174, 1), (174, 300), (174, 300), (174, 300)\n",
      "(174, 1), (174, 300), (174, 300), (174, 300)\n",
      "(174, 1), (174, 300), (174, 300), (174, 300)\n",
      "(174, 1), (174, 300), (174, 300), (174, 300)\n",
      "(174, 1), (174, 300), (174, 300), (174, 300)\n",
      "(174, 1), (174, 300), (174, 300), (174, 300)\n",
      "(174, 1), (174, 300), (174, 300), (174, 300)\n",
      "(174, 1), (174, 300), (174, 300), (174, 300)\n",
      "(174, 1), (174, 300), (174, 300), (174, 300)\n",
      "(174, 1), (174, 300), (174, 300), (174, 300)\n",
      "(174, 1), (174, 300), (174, 300), (174, 300)\n",
      "(174, 1), (174, 300), (174, 300), (174, 300)\n",
      "(174, 1), (174, 300), (174, 300), (174, 300)\n",
      "(174, 1), (174, 300), (174, 300), (174, 300)\n",
      "(174, 1), (174, 300), (174, 300), (174, 300)\n",
      "(174, 1), (174, 300), (174, 300), (174, 300)\n",
      "(174, 1), (174, 300), (174, 300), (174, 300)\n",
      "(174, 1), (174, 300), (174, 300), (174, 300)\n",
      "(174, 1), (174, 300), (174, 300), (174, 300)\n",
      "(174, 13), (174, 300), (174, 300), (174, 300)\n",
      "(174, 1), (174, 300), (174, 300), (174, 300)\n",
      "(174, 1), (174, 300), (174, 300), (174, 300)\n",
      "(174, 1), (174, 300), (174, 300), (174, 300)\n",
      "(174, 1), (174, 300), (174, 300), (174, 300)\n",
      "(174, 1), (174, 300), (174, 300), (174, 300)\n",
      "(174, 1), (174, 300), (174, 300), (174, 300)\n",
      "(174, 1), (174, 300), (174, 300), (174, 300)\n",
      "(174, 1), (174, 300), (174, 300), (174, 300)\n",
      "(174, 1), (174, 300), (174, 300), (174, 300)\n",
      "(174, 1), (174, 300), (174, 300), (174, 300)\n",
      "(174, 1), (174, 300), (174, 300), (174, 300)\n",
      "(174, 1), (174, 300), (174, 300), (174, 300)\n",
      "(174, 1), (174, 300), (174, 300), (174, 300)\n",
      "(174, 1), (174, 300), (174, 300), (174, 300)\n",
      "(174, 1), (174, 300), (174, 300), (174, 300)\n",
      "(174, 1), (174, 300), (174, 300), (174, 300)\n",
      "(174, 1), (174, 300), (174, 300), (174, 300)\n",
      "(174, 1), (174, 300), (174, 300), (174, 300)\n",
      "(174, 1), (174, 300), (174, 300), (174, 300)\n",
      "(174, 1), (174, 300), (174, 300), (174, 300)\n",
      "(174, 1), (174, 300), (174, 300), (174, 300)\n",
      "(174, 1), (174, 300), (174, 300), (174, 300)\n",
      "(174, 1), (174, 300), (174, 300), (174, 300)\n",
      "(174, 1), (174, 300), (174, 300), (174, 300)\n",
      "(174, 1), (174, 300), (174, 300), (174, 300)\n",
      "(174, 1), (174, 300), (174, 300), (174, 300)\n",
      "(174, 1), (174, 300), (174, 300), (174, 300)\n",
      "(174, 1), (174, 300), (174, 300), (174, 300)\n",
      "(174, 1), (174, 300), (174, 300), (174, 300)\n",
      "(174, 1), (174, 300), (174, 300), (174, 300)\n",
      "(174, 11), (174, 300), (174, 300), (174, 300)\n",
      "(174, 1), (174, 300), (174, 300), (174, 300)\n",
      "(174, 1), (174, 300), (174, 300), (174, 300)\n",
      "(174, 11), (174, 300), (174, 300), (174, 300)\n",
      "(174, 1), (174, 300), (174, 300), (174, 300)\n",
      "(174, 1), (174, 300), (174, 300), (174, 300)\n",
      "(174, 1), (174, 300), (174, 300), (174, 300)\n",
      "(174, 1), (174, 300), (174, 300), (174, 300)\n",
      "(174, 1), (174, 300), (174, 300), (174, 300)\n",
      "(174, 1), (174, 300), (174, 300), (174, 300)\n",
      "(174, 1), (174, 300), (174, 300), (174, 300)\n",
      "(174, 11), (174, 300), (174, 300), (174, 300)\n",
      "(174, 1), (174, 300), (174, 300), (174, 300)\n",
      "(174, 1), (174, 300), (174, 300), (174, 300)\n",
      "(174, 1), (174, 300), (174, 300), (174, 300)\n",
      "(174, 1), (174, 300), (174, 300), (174, 300)\n",
      "(174, 1), (174, 300), (174, 300), (174, 300)\n",
      "(174, 1), (174, 300), (174, 300), (174, 300)\n",
      "(174, 1), (174, 300), (174, 300), (174, 300)\n",
      "(174, 1), (174, 300), (174, 300), (174, 300)\n",
      "(174, 1), (174, 300), (174, 300), (174, 300)\n",
      "(174, 1), (174, 300), (174, 300), (174, 300)\n",
      "(174, 1), (174, 300), (174, 300), (174, 300)\n",
      "(174, 1), (174, 300), (174, 300), (174, 300)\n",
      "(174, 1), (174, 300), (174, 300), (174, 300)\n",
      "(174, 1), (174, 300), (174, 300), (174, 300)\n",
      "(174, 1), (174, 300), (174, 300), (174, 300)\n",
      "(174, 1), (174, 300), (174, 300), (174, 300)\n",
      "(174, 1), (174, 300), (174, 300), (174, 300)\n",
      "(174, 1), (174, 300), (174, 300), (174, 300)\n",
      "(174, 1), (174, 300), (174, 300), (174, 300)\n",
      "(174, 1), (174, 300), (174, 300), (174, 300)\n",
      "(174, 1), (174, 300), (174, 300), (174, 300)\n",
      "(174, 1), (174, 300), (174, 300), (174, 300)\n",
      "(174, 1), (174, 300), (174, 300), (174, 300)\n",
      "(174, 1), (174, 300), (174, 300), (174, 300)\n",
      "(174, 1), (174, 300), (174, 300), (174, 300)\n",
      "(174, 1), (174, 300), (174, 300), (174, 300)\n",
      "(174, 1), (174, 300), (174, 300), (174, 300)\n",
      "(174, 1), (174, 300), (174, 300), (174, 300)\n",
      "(174, 1), (174, 300), (174, 300), (174, 300)\n",
      "(174, 1), (174, 300), (174, 300), (174, 300)\n",
      "(174, 11), (174, 300), (174, 300), (174, 300)\n",
      "(174, 1), (174, 300), (174, 300), (174, 300)\n",
      "(174, 1), (174, 300), (174, 300), (174, 300)\n",
      "(174, 1), (174, 300), (174, 300), (174, 300)\n",
      "(174, 1), (174, 300), (174, 300), (174, 300)\n",
      "(174, 1), (174, 300), (174, 300), (174, 300)\n",
      "(174, 1), (174, 300), (174, 300), (174, 300)\n",
      "(174, 1), (174, 300), (174, 300), (174, 300)\n",
      "(174, 1), (174, 300), (174, 300), (174, 300)\n",
      "(174, 1), (174, 300), (174, 300), (174, 300)\n",
      "(174, 14), (174, 300), (174, 300), (174, 300)\n",
      "(174, 1), (174, 300), (174, 300), (174, 300)\n",
      "(174, 1), (174, 300), (174, 300), (174, 300)\n",
      "(174, 1), (174, 300), (174, 300), (174, 300)\n",
      "(174, 1), (174, 300), (174, 300), (174, 300)\n",
      "(174, 1), (174, 300), (174, 300), (174, 300)\n",
      "(174, 1), (174, 300), (174, 300), (174, 300)\n",
      "(174, 1), (174, 300), (174, 300), (174, 300)\n",
      "(174, 1), (174, 300), (174, 300), (174, 300)\n",
      "(174, 1), (174, 300), (174, 300), (174, 300)\n",
      "(174, 1), (174, 300), (174, 300), (174, 300)\n",
      "(174, 1), (174, 300), (174, 300), (174, 300)\n",
      "(174, 1), (174, 300), (174, 300), (174, 300)\n",
      "(174, 1), (174, 300), (174, 300), (174, 300)\n",
      "(174, 1), (174, 300), (174, 300), (174, 300)\n",
      "(174, 1), (174, 300), (174, 300), (174, 300)\n",
      "(174, 1), (174, 300), (174, 300), (174, 300)\n",
      "(174, 1), (174, 300), (174, 300), (174, 300)\n",
      "(174, 1), (174, 300), (174, 300), (174, 300)\n",
      "(174, 1), (174, 300), (174, 300), (174, 300)\n",
      "(174, 1), (174, 300), (174, 300), (174, 300)\n",
      "(174, 1), (174, 300), (174, 300), (174, 300)\n",
      "(174, 1), (174, 300), (174, 300), (174, 300)\n",
      "(174, 1), (174, 300), (174, 300), (174, 300)\n",
      "(174, 1), (174, 300), (174, 300), (174, 300)\n",
      "(174, 1), (174, 300), (174, 300), (174, 300)\n",
      "(174, 1), (174, 300), (174, 300), (174, 300)\n",
      "(174, 1), (174, 300), (174, 300), (174, 300)\n",
      "(174, 1), (174, 300), (174, 300), (174, 300)\n",
      "(174, 1), (174, 300), (174, 300), (174, 300)\n",
      "(174, 9), (174, 300), (174, 300), (174, 300)\n",
      "(174, 1), (174, 300), (174, 300), (174, 300)\n",
      "(174, 1), (174, 300), (174, 300), (174, 300)\n",
      "(174, 1), (174, 300), (174, 300), (174, 300)\n",
      "(174, 1), (174, 300), (174, 300), (174, 300)\n",
      "(174, 1), (174, 300), (174, 300), (174, 300)\n",
      "(174, 1), (174, 300), (174, 300), (174, 300)\n",
      "(174, 1), (174, 300), (174, 300), (174, 300)\n",
      "(174, 1), (174, 300), (174, 300), (174, 300)\n",
      "(174, 1), (174, 300), (174, 300), (174, 300)\n",
      "(174, 1), (174, 300), (174, 300), (174, 300)\n",
      "(174, 1), (174, 300), (174, 300), (174, 300)\n",
      "(174, 1), (174, 300), (174, 300), (174, 300)\n",
      "(174, 1), (174, 300), (174, 300), (174, 300)\n",
      "(174, 1), (174, 300), (174, 300), (174, 300)\n",
      "(174, 1), (174, 300), (174, 300), (174, 300)\n",
      "(174, 1), (174, 300), (174, 300), (174, 300)\n",
      "(174, 1), (174, 300), (174, 300), (174, 300)\n",
      "(174, 1), (174, 300), (174, 300), (174, 300)\n",
      "(174, 1), (174, 300), (174, 300), (174, 300)\n",
      "(174, 1), (174, 300), (174, 300), (174, 300)\n",
      "(174, 1), (174, 300), (174, 300), (174, 300)\n",
      "(174, 1), (174, 300), (174, 300), (174, 300)\n",
      "(174, 1), (174, 300), (174, 300), (174, 300)\n",
      "(174, 1), (174, 300), (174, 300), (174, 300)\n",
      "(174, 1), (174, 300), (174, 300), (174, 300)\n",
      "(174, 1), (174, 300), (174, 300), (174, 300)\n",
      "(174, 1), (174, 300), (174, 300), (174, 300)\n",
      "(174, 1), (174, 300), (174, 300), (174, 300)\n",
      "(174, 1), (174, 300), (174, 300), (174, 300)\n",
      "(174, 1), (174, 300), (174, 300), (174, 300)\n",
      "(174, 1), (174, 300), (174, 300), (174, 300)\n",
      "(174, 1), (174, 300), (174, 300), (174, 300)\n",
      "(174, 1), (174, 300), (174, 300), (174, 300)\n",
      "(174, 1), (174, 300), (174, 300), (174, 300)\n",
      "(174, 1), (174, 300), (174, 300), (174, 300)\n",
      "(174, 1), (174, 300), (174, 300), (174, 300)\n",
      "(174, 11), (174, 300), (174, 300), (174, 300)\n",
      "(174, 1), (174, 300), (174, 300), (174, 300)\n",
      "(174, 1), (174, 300), (174, 300), (174, 300)\n",
      "(174, 1), (174, 300), (174, 300), (174, 300)\n",
      "(174, 1), (174, 300), (174, 300), (174, 300)\n",
      "(174, 1), (174, 300), (174, 300), (174, 300)\n",
      "(174, 1), (174, 300), (174, 300), (174, 300)\n",
      "(174, 1), (174, 300), (174, 300), (174, 300)\n",
      "(174, 1), (174, 300), (174, 300), (174, 300)\n",
      "(174, 1), (174, 300), (174, 300), (174, 300)\n",
      "(174, 1), (174, 300), (174, 300), (174, 300)\n",
      "(174, 1), (174, 300), (174, 300), (174, 300)\n",
      "(174, 14), (174, 300), (174, 300), (174, 300)\n",
      "(174, 1), (174, 300), (174, 300), (174, 300)\n",
      "(174, 1), (174, 300), (174, 300), (174, 300)\n",
      "(174, 1), (174, 300), (174, 300), (174, 300)\n",
      "(174, 1), (174, 300), (174, 300), (174, 300)\n",
      "(174, 1), (174, 300), (174, 300), (174, 300)\n",
      "(174, 1), (174, 300), (174, 300), (174, 300)\n",
      "(174, 1), (174, 300), (174, 300), (174, 300)\n",
      "(174, 1), (174, 300), (174, 300), (174, 300)\n",
      "(174, 1), (174, 300), (174, 300), (174, 300)\n",
      "(174, 1), (174, 300), (174, 300), (174, 300)\n",
      "(174, 1), (174, 300), (174, 300), (174, 300)\n",
      "(174, 11), (174, 300), (174, 300), (174, 300)\n",
      "(174, 1), (174, 300), (174, 300), (174, 300)\n",
      "(174, 1), (174, 300), (174, 300), (174, 300)\n",
      "(174, 1), (174, 300), (174, 300), (174, 300)\n",
      "(174, 1), (174, 300), (174, 300), (174, 300)\n",
      "(174, 1), (174, 300), (174, 300), (174, 300)\n",
      "(174, 1), (174, 300), (174, 300), (174, 300)\n",
      "(174, 1), (174, 300), (174, 300), (174, 300)\n",
      "(174, 1), (174, 300), (174, 300), (174, 300)\n",
      "(174, 1), (174, 300), (174, 300), (174, 300)\n",
      "(174, 1), (174, 300), (174, 300), (174, 300)\n",
      "(174, 14), (174, 300), (174, 300), (174, 300)\n",
      "(174, 1), (174, 300), (174, 300), (174, 300)\n",
      "(174, 1), (174, 300), (174, 300), (174, 300)\n",
      "(174, 1), (174, 300), (174, 300), (174, 300)\n",
      "(174, 1), (174, 300), (174, 300), (174, 300)\n",
      "(174, 1), (174, 300), (174, 300), (174, 300)\n",
      "(174, 1), (174, 300), (174, 300), (174, 300)\n",
      "(174, 11), (174, 300), (174, 300), (174, 300)\n",
      "(174, 1), (174, 300), (174, 300), (174, 300)\n",
      "(174, 1), (174, 300), (174, 300), (174, 300)\n",
      "(174, 1), (174, 300), (174, 300), (174, 300)\n",
      "(174, 1), (174, 300), (174, 300), (174, 300)\n",
      "(174, 1), (174, 300), (174, 300), (174, 300)\n",
      "(174, 1), (174, 300), (174, 300), (174, 300)\n",
      "(174, 1), (174, 300), (174, 300), (174, 300)\n",
      "(174, 1), (174, 300), (174, 300), (174, 300)\n",
      "(174, 1), (174, 300), (174, 300), (174, 300)\n",
      "(174, 1), (174, 300), (174, 300), (174, 300)\n",
      "(174, 1), (174, 300), (174, 300), (174, 300)\n",
      "(174, 1), (174, 300), (174, 300), (174, 300)\n",
      "(174, 1), (174, 300), (174, 300), (174, 300)\n",
      "(174, 1), (174, 300), (174, 300), (174, 300)\n",
      "(174, 1), (174, 300), (174, 300), (174, 300)\n",
      "(174, 1), (174, 300), (174, 300), (174, 300)\n",
      "(174, 1), (174, 300), (174, 300), (174, 300)\n",
      "(174, 1), (174, 300), (174, 300), (174, 300)\n",
      "(174, 1), (174, 300), (174, 300), (174, 300)\n",
      "(174, 11), (174, 300), (174, 300), (174, 300)\n",
      "(174, 1), (174, 300), (174, 300), (174, 300)\n",
      "(174, 1), (174, 300), (174, 300), (174, 300)\n",
      "(174, 1), (174, 300), (174, 300), (174, 300)\n",
      "(174, 1), (174, 300), (174, 300), (174, 300)\n",
      "(174, 1), (174, 300), (174, 300), (174, 300)\n",
      "(174, 1), (174, 300), (174, 300), (174, 300)\n",
      "(174, 1), (174, 300), (174, 300), (174, 300)\n",
      "(174, 1), (174, 300), (174, 300), (174, 300)\n",
      "(174, 1), (174, 300), (174, 300), (174, 300)\n",
      "(174, 1), (174, 300), (174, 300), (174, 300)\n",
      "(174, 1), (174, 300), (174, 300), (174, 300)\n",
      "(174, 1), (174, 300), (174, 300), (174, 300)\n",
      "(174, 1), (174, 300), (174, 300), (174, 300)\n",
      "(174, 14), (174, 300), (174, 300), (174, 300)\n",
      "(174, 1), (174, 300), (174, 300), (174, 300)\n",
      "(174, 1), (174, 300), (174, 300), (174, 300)\n",
      "(174, 1), (174, 300), (174, 300), (174, 300)\n",
      "(174, 1), (174, 300), (174, 300), (174, 300)\n",
      "(174, 1), (174, 300), (174, 300), (174, 300)\n",
      "(174, 1), (174, 300), (174, 300), (174, 300)\n",
      "(174, 1), (174, 300), (174, 300), (174, 300)\n",
      "(174, 1), (174, 300), (174, 300), (174, 300)\n",
      "(174, 1), (174, 300), (174, 300), (174, 300)\n",
      "(174, 9), (174, 300), (174, 300), (174, 300)\n",
      "(174, 1), (174, 300), (174, 300), (174, 300)\n",
      "(174, 1), (174, 300), (174, 300), (174, 300)\n",
      "(174, 1), (174, 300), (174, 300), (174, 300)\n",
      "(174, 1), (174, 300), (174, 300), (174, 300)\n",
      "(174, 1), (174, 300), (174, 300), (174, 300)\n",
      "(174, 1), (174, 300), (174, 300), (174, 300)\n",
      "(174, 1), (174, 300), (174, 300), (174, 300)\n",
      "(174, 1), (174, 300), (174, 300), (174, 300)\n",
      "(174, 1), (174, 300), (174, 300), (174, 300)\n",
      "(174, 1), (174, 300), (174, 300), (174, 300)\n",
      "(174, 1), (174, 300), (174, 300), (174, 300)\n",
      "(174, 1), (174, 300), (174, 300), (174, 300)\n",
      "(174, 1), (174, 300), (174, 300), (174, 300)\n",
      "(174, 1), (174, 300), (174, 300), (174, 300)\n",
      "(174, 1), (174, 300), (174, 300), (174, 300)\n",
      "(174, 1), (174, 300), (174, 300), (174, 300)\n",
      "(174, 1), (174, 300), (174, 300), (174, 300)\n",
      "(174, 1), (174, 300), (174, 300), (174, 300)\n",
      "(174, 1), (174, 300), (174, 300), (174, 300)\n",
      "(174, 1), (174, 300), (174, 300), (174, 300)\n",
      "(174, 1), (174, 300), (174, 300), (174, 300)\n",
      "(174, 1), (174, 300), (174, 300), (174, 300)\n",
      "(174, 1), (174, 300), (174, 300), (174, 300)\n",
      "(174, 1), (174, 300), (174, 300), (174, 300)\n",
      "(174, 1), (174, 300), (174, 300), (174, 300)\n",
      "(174, 1), (174, 300), (174, 300), (174, 300)\n",
      "(174, 1), (174, 300), (174, 300), (174, 300)\n",
      "(174, 1), (174, 300), (174, 300), (174, 300)\n",
      "(174, 1), (174, 300), (174, 300), (174, 300)\n",
      "(174, 1), (174, 300), (174, 300), (174, 300)\n",
      "(174, 1), (174, 300), (174, 300), (174, 300)\n",
      "(174, 1), (174, 300), (174, 300), (174, 300)\n",
      "(174, 1), (174, 300), (174, 300), (174, 300)\n",
      "(174, 1), (174, 300), (174, 300), (174, 300)\n",
      "(174, 1), (174, 300), (174, 300), (174, 300)\n",
      "(174, 1), (174, 300), (174, 300), (174, 300)\n",
      "(174, 1), (174, 300), (174, 300), (174, 300)\n",
      "(174, 1), (174, 300), (174, 300), (174, 300)\n",
      "(174, 1), (174, 300), (174, 300), (174, 300)\n",
      "(174, 1), (174, 300), (174, 300), (174, 300)\n",
      "(174, 1), (174, 300), (174, 300), (174, 300)\n",
      "(174, 1), (174, 300), (174, 300), (174, 300)\n",
      "(174, 1), (174, 300), (174, 300), (174, 300)\n",
      "(174, 1), (174, 300), (174, 300), (174, 300)\n",
      "(174, 1), (174, 300), (174, 300), (174, 300)\n",
      "(174, 1), (174, 300), (174, 300), (174, 300)\n",
      "(174, 1), (174, 300), (174, 300), (174, 300)\n",
      "(174, 1), (174, 300), (174, 300), (174, 300)\n",
      "(174, 1), (174, 300), (174, 300), (174, 300)\n",
      "(174, 1), (174, 300), (174, 300), (174, 300)\n",
      "(174, 11), (174, 300), (174, 300), (174, 300)\n",
      "(174, 1), (174, 300), (174, 300), (174, 300)\n",
      "(174, 1), (174, 300), (174, 300), (174, 300)\n",
      "(174, 1), (174, 300), (174, 300), (174, 300)\n",
      "(174, 1), (174, 300), (174, 300), (174, 300)\n",
      "(174, 1), (174, 300), (174, 300), (174, 300)\n",
      "(174, 1), (174, 300), (174, 300), (174, 300)\n",
      "(174, 1), (174, 300), (174, 300), (174, 300)\n",
      "(174, 1), (174, 300), (174, 300), (174, 300)\n",
      "(174, 1), (174, 300), (174, 300), (174, 300)\n",
      "(174, 1), (174, 300), (174, 300), (174, 300)\n",
      "(174, 1), (174, 300), (174, 300), (174, 300)\n",
      "(174, 1), (174, 300), (174, 300), (174, 300)\n",
      "(174, 1), (174, 300), (174, 300), (174, 300)\n",
      "(174, 1), (174, 300), (174, 300), (174, 300)\n",
      "(174, 1), (174, 300), (174, 300), (174, 300)\n",
      "(174, 1), (174, 300), (174, 300), (174, 300)\n",
      "(174, 1), (174, 300), (174, 300), (174, 300)\n",
      "(174, 1), (174, 300), (174, 300), (174, 300)\n",
      "(174, 1), (174, 300), (174, 300), (174, 300)\n",
      "(174, 1), (174, 300), (174, 300), (174, 300)\n",
      "(174, 1), (174, 300), (174, 300), (174, 300)\n",
      "(174, 11), (174, 300), (174, 300), (174, 300)\n",
      "(174, 1), (174, 300), (174, 300), (174, 300)\n",
      "(174, 1), (174, 300), (174, 300), (174, 300)\n",
      "(174, 1), (174, 300), (174, 300), (174, 300)\n",
      "(174, 1), (174, 300), (174, 300), (174, 300)\n",
      "(174, 1), (174, 300), (174, 300), (174, 300)\n",
      "(174, 1), (174, 300), (174, 300), (174, 300)\n",
      "(174, 1), (174, 300), (174, 300), (174, 300)\n",
      "(174, 1), (174, 300), (174, 300), (174, 300)\n",
      "(174, 1), (174, 300), (174, 300), (174, 300)\n",
      "(174, 1), (174, 300), (174, 300), (174, 300)\n",
      "(174, 1), (174, 300), (174, 300), (174, 300)\n",
      "(174, 1), (174, 300), (174, 300), (174, 300)\n",
      "(174, 1), (174, 300), (174, 300), (174, 300)\n",
      "(174, 1), (174, 300), (174, 300), (174, 300)\n",
      "(174, 1), (174, 300), (174, 300), (174, 300)\n",
      "(174, 1), (174, 300), (174, 300), (174, 300)\n",
      "(174, 1), (174, 300), (174, 300), (174, 300)\n",
      "(174, 14), (174, 300), (174, 300), (174, 300)\n",
      "(174, 1), (174, 300), (174, 300), (174, 300)\n",
      "(174, 1), (174, 300), (174, 300), (174, 300)\n",
      "(174, 1), (174, 300), (174, 300), (174, 300)\n",
      "(174, 1), (174, 300), (174, 300), (174, 300)\n",
      "(174, 1), (174, 300), (174, 300), (174, 300)\n",
      "(174, 1), (174, 300), (174, 300), (174, 300)\n",
      "(174, 1), (174, 300), (174, 300), (174, 300)\n",
      "(174, 1), (174, 300), (174, 300), (174, 300)\n",
      "(174, 1), (174, 300), (174, 300), (174, 300)\n",
      "(174, 1), (174, 300), (174, 300), (174, 300)\n",
      "(174, 1), (174, 300), (174, 300), (174, 300)\n",
      "(174, 1), (174, 300), (174, 300), (174, 300)\n",
      "(174, 1), (174, 300), (174, 300), (174, 300)\n",
      "(174, 1), (174, 300), (174, 300), (174, 300)\n",
      "(174, 1), (174, 300), (174, 300), (174, 300)\n",
      "(174, 1), (174, 300), (174, 300), (174, 300)\n",
      "(174, 1), (174, 300), (174, 300), (174, 300)\n",
      "(174, 1), (174, 300), (174, 300), (174, 300)\n",
      "(174, 1), (174, 300), (174, 300), (174, 300)\n",
      "(174, 1), (174, 300), (174, 300), (174, 300)\n",
      "(174, 1), (174, 300), (174, 300), (174, 300)\n",
      "(174, 1), (174, 300), (174, 300), (174, 300)\n",
      "(174, 1), (174, 300), (174, 300), (174, 300)\n",
      "(174, 1), (174, 300), (174, 300), (174, 300)\n",
      "(174, 1), (174, 300), (174, 300), (174, 300)\n"
     ]
    }
   ],
   "source": [
    "max_length = 174\n",
    "\n",
    "# Pad the embeddings\n",
    "for key in fasttext_task1:\n",
    "    label = test_labels[key]\n",
    "    embeddings_fasttext = fasttext_task1[key]\n",
    "    embeddings_glove = glove_task1[key]\n",
    "    embeddings_word2vec = word2vec_task1[key]\n",
    "\n",
    "    # Pad the labels\n",
    "    if len(label) < max_length:\n",
    "        label = label + ['O'] * (max_length - len(label))\n",
    "\n",
    "    # Pad the embeddings\n",
    "    if len(embeddings_fasttext) < max_length:\n",
    "        embeddings_fasttext = np.concatenate((embeddings_fasttext, np.zeros((max_length - len(embeddings_fasttext), 300))), axis=0)\n",
    "        embeddings_glove = np.concatenate((embeddings_glove, np.zeros((max_length - len(embeddings_glove), 300))), axis=0)\n",
    "        embeddings_word2vec = np.concatenate((embeddings_word2vec, np.zeros((max_length - len(embeddings_word2vec), 300))), axis=0)\n",
    "\n",
    "    # Update the 4 dictionaries\n",
    "    fasttext_task1[key] = embeddings_fasttext\n",
    "    glove_task1[key] = embeddings_glove\n",
    "    word2vec_task1[key] = embeddings_word2vec\n",
    "    test_labels[key] = label\n",
    "\n",
    "# Iterate and check the length of the sentences\n",
    "for key in test_labels:\n",
    "    print(f\"({len(test_labels[key])}, {len(test_labels[key][0])}), ({len(fasttext_task1[key])}, {len(fasttext_task1[key][0])}), ({len(glove_task1[key])}, {len(glove_task1[key][0])}), ({len(word2vec_task1[key])}, {len(word2vec_task1[key][0])})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Labels to Index for all Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Task 1 - Labels to Index\n",
    "\"\"\"\n",
    "\n",
    "\"\"\"\n",
    "RNN\n",
    "\"\"\"\n",
    "labels_to_index_rnn_fasttext = {'B_COURT': 0, 'I_GPE': 1, 'I_PROVISION': 2, 'B_ORG': 3, 'I_STATUTE': 4, 'I_RESPONDENT': 5, 'B_OTHER_PERSON': 6, 'B_CASE_NUMBER': 7, 'B_GPE': 8, 'B_PRECEDENT': 9, 'I_CASE_NUMBER': 10, 'I_OTHER_PERSON': 11, 'B_PROVISION': 12, 'B_JUDGE': 13, 'I_COURT': 14, 'I_JUDGE': 15, 'B_RESPONDENT': 16, 'B_WITNESS': 17, 'B_PETITIONER': 18, 'I_PETITIONER': 19, 'I_PRECEDENT': 20, 'I_WITNESS': 21, 'I_ORG': 22, 'O': 23, 'B_STATUTE': 24, 'I_DATE': 25, 'B_DATE': 26}\n",
    "labels_to_index_rnn_glove = {'I_OTHER_PERSON': 0, 'I_DATE': 1, 'I_ORG': 2, 'B_WITNESS': 3, 'B_OTHER_PERSON': 4, 'B_PETITIONER': 5, 'I_STATUTE': 6, 'B_PRECEDENT': 7, 'B_ORG': 8, 'I_PROVISION': 9, 'I_WITNESS': 10, 'B_GPE': 11, 'B_DATE': 12, 'I_COURT': 13, 'I_PRECEDENT': 14, 'B_PROVISION': 15, 'B_RESPONDENT': 16, 'I_RESPONDENT': 17, 'B_JUDGE': 18, 'B_COURT': 19, 'I_JUDGE': 20, 'I_GPE': 21, 'B_STATUTE': 22, 'O': 23, 'I_CASE_NUMBER': 24, 'B_CASE_NUMBER': 25, 'I_PETITIONER': 26}\n",
    "labels_to_index_rnn_word2vec = {'I_RESPONDENT': 0, 'B_PRECEDENT': 1, 'I_PRECEDENT': 2, 'I_ORG': 3, 'I_COURT': 4, 'I_JUDGE': 5, 'B_ORG': 6, 'B_DATE': 7, 'I_GPE': 8, 'B_OTHER_PERSON': 9, 'B_RESPONDENT': 10, 'I_STATUTE': 11, 'I_DATE': 12, 'I_CASE_NUMBER': 13, 'I_PETITIONER': 14, 'B_WITNESS': 15, 'B_JUDGE': 16, 'B_CASE_NUMBER': 17, 'B_PETITIONER': 18, 'I_OTHER_PERSON': 19, 'O': 20, 'B_STATUTE': 21, 'I_PROVISION': 22, 'I_WITNESS': 23, 'B_GPE': 24, 'B_PROVISION': 25, 'B_COURT': 26}\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "LSTM\n",
    "\"\"\"\n",
    "labels_to_index_lstm_fasttext = {'B_GPE': 0, 'I_ORG': 1, 'I_PRECEDENT': 2, 'I_COURT': 3, 'I_WITNESS': 4, 'B_DATE': 5, 'I_CASE_NUMBER': 6, 'B_ORG': 7, 'I_DATE': 8, 'I_OTHER_PERSON': 9, 'B_PROVISION': 10, 'B_CASE_NUMBER': 11, 'I_GPE': 12, 'I_RESPONDENT': 13, 'B_JUDGE': 14, 'I_JUDGE': 15, 'B_PRECEDENT': 16, 'B_PETITIONER': 17, 'I_PROVISION': 18, 'B_OTHER_PERSON': 19, 'B_STATUTE': 20, 'B_RESPONDENT': 21, 'I_PETITIONER': 22, 'B_WITNESS': 23, 'B_COURT': 24, 'O': 25, 'I_STATUTE': 26}\n",
    "labels_to_index_lstm_glove = {'B_JUDGE': 0, 'B_PRECEDENT': 1, 'I_STATUTE': 2, 'B_WITNESS': 3, 'B_ORG': 4, 'I_PETITIONER': 5, 'B_CASE_NUMBER': 6, 'I_GPE': 7, 'B_OTHER_PERSON': 8, 'I_COURT': 9, 'B_DATE': 10, 'I_WITNESS': 11, 'B_PETITIONER': 12, 'I_DATE': 13, 'I_PRECEDENT': 14, 'I_CASE_NUMBER': 15, 'B_GPE': 16, 'B_COURT': 17, 'I_OTHER_PERSON': 18, 'B_RESPONDENT': 19, 'O': 20, 'I_ORG': 21, 'I_JUDGE': 22, 'I_RESPONDENT': 23, 'B_STATUTE': 24, 'I_PROVISION': 25, 'B_PROVISION': 26}\n",
    "labels_to_index_lstm_word2vec = {'I_OTHER_PERSON': 0, 'I_WITNESS': 1, 'B_RESPONDENT': 2, 'B_OTHER_PERSON': 3, 'B_STATUTE': 4, 'B_COURT': 5, 'I_ORG': 6, 'I_CASE_NUMBER': 7, 'I_DATE': 8, 'B_PRECEDENT': 9, 'B_PETITIONER': 10, 'B_DATE': 11, 'I_STATUTE': 12, 'I_PETITIONER': 13, 'B_ORG': 14, 'B_CASE_NUMBER': 15, 'I_COURT': 16, 'I_PRECEDENT': 17, 'I_PROVISION': 18, 'I_RESPONDENT': 19, 'B_GPE': 20, 'I_GPE': 21, 'O': 22, 'B_PROVISION': 23, 'I_JUDGE': 24, 'B_JUDGE': 25, 'B_WITNESS': 26}\n",
    "\n",
    "\"\"\"\n",
    "GRU\n",
    "\"\"\"\n",
    "labels_to_index_gru_fasttext = {'I_OTHER_PERSON': 0, 'B_WITNESS': 1, 'B_JUDGE': 2, 'I_WITNESS': 3, 'B_COURT': 4, 'I_STATUTE': 5, 'B_CASE_NUMBER': 6, 'I_PRECEDENT': 7, 'I_CASE_NUMBER': 8, 'I_RESPONDENT': 9, 'B_GPE': 10, 'I_ORG': 11, 'O': 12, 'B_ORG': 13, 'I_GPE': 14, 'B_DATE': 15, 'I_PROVISION': 16, 'I_JUDGE': 17, 'B_RESPONDENT': 18, 'I_DATE': 19, 'B_STATUTE': 20, 'B_PROVISION': 21, 'B_OTHER_PERSON': 22, 'B_PETITIONER': 23, 'B_PRECEDENT': 24, 'I_PETITIONER': 25, 'I_COURT': 26}\n",
    "labels_to_index_gru_glove = {'I_COURT': 0, 'B_ORG': 1, 'I_DATE': 2, 'I_ORG': 3, 'I_STATUTE': 4, 'B_COURT': 5, 'B_CASE_NUMBER': 6, 'I_CASE_NUMBER': 7, 'B_PROVISION': 8, 'O': 9, 'B_PRECEDENT': 10, 'I_PROVISION': 11, 'B_RESPONDENT': 12, 'B_OTHER_PERSON': 13, 'I_WITNESS': 14, 'I_PRECEDENT': 15, 'I_JUDGE': 16, 'I_RESPONDENT': 17, 'B_PETITIONER': 18, 'B_WITNESS': 19, 'B_GPE': 20, 'B_DATE': 21, 'I_GPE': 22, 'I_OTHER_PERSON': 23, 'I_PETITIONER': 24, 'B_STATUTE': 25, 'B_JUDGE': 26}\n",
    "labels_to_index_gru_word2vec = {'O': 0, 'B_ORG': 1, 'B_STATUTE': 2, 'B_OTHER_PERSON': 3, 'I_PROVISION': 4, 'I_DATE': 5, 'I_WITNESS': 6, 'I_OTHER_PERSON': 7, 'B_JUDGE': 8, 'B_DATE': 9, 'I_PETITIONER': 10, 'B_COURT': 11, 'I_GPE': 12, 'I_JUDGE': 13, 'B_WITNESS': 14, 'B_RESPONDENT': 15, 'I_RESPONDENT': 16, 'I_PRECEDENT': 17, 'B_PETITIONER': 18, 'I_CASE_NUMBER': 19, 'B_PROVISION': 20, 'B_CASE_NUMBER': 21, 'I_STATUTE': 22, 'B_GPE': 23, 'B_PRECEDENT': 24, 'I_COURT': 25, 'I_ORG': 26}\n",
    "\n",
    "\"\"\"\n",
    "BiLSTM-CRF\n",
    "\"\"\"\n",
    "labels_to_index_bilstmcrf_word2vec = {'I_RESPONDENT': 0, 'I_PROVISION': 1, 'B_PROVISION': 2, 'B_STATUTE': 3, 'B_CASE_NUMBER': 4, 'I_STATUTE': 5, 'B_COURT': 6, 'B_PETITIONER': 7, 'B_PRECEDENT': 8, 'B_RESPONDENT': 9, 'B_ORG': 10, 'I_COURT': 11, 'I_CASE_NUMBER': 12, 'B_WITNESS': 13, 'I_WITNESS': 14, 'I_GPE': 15, 'I_JUDGE': 16, 'B_GPE': 17, 'B_JUDGE': 18, 'I_ORG': 19, 'B_DATE': 20, 'I_DATE': 21, 'I_PETITIONER': 22, 'O': 23, 'I_PRECEDENT': 24, 'B_OTHER_PERSON': 25, 'I_OTHER_PERSON': 26}\n",
    "labels_to_index_bilstmcrf_glove = {'I_PRECEDENT': 0, 'O': 1, 'B_COURT': 2, 'I_JUDGE': 3, 'B_OTHER_PERSON': 4, 'I_PROVISION': 5, 'B_CASE_NUMBER': 6, 'I_COURT': 7, 'B_ORG': 8, 'I_STATUTE': 9, 'I_CASE_NUMBER': 10, 'B_GPE': 11, 'I_GPE': 12, 'I_OTHER_PERSON': 13, 'I_RESPONDENT': 14, 'B_PROVISION': 15, 'B_PRECEDENT': 16, 'B_DATE': 17, 'B_WITNESS': 18, 'B_STATUTE': 19, 'I_ORG': 20, 'B_JUDGE': 21, 'B_RESPONDENT': 22, 'I_DATE': 23, 'B_PETITIONER': 24, 'I_PETITIONER': 25, 'I_WITNESS': 26}\n",
    "labels_to_index_bilstmcrf_fasttext = {'B_PRECEDENT': 0, 'I_PROVISION': 1, 'I_ORG': 2, 'B_ORG': 3, 'B_CASE_NUMBER': 4, 'I_WITNESS': 5, 'B_OTHER_PERSON': 6, 'I_OTHER_PERSON': 7, 'B_WITNESS': 8, 'B_PETITIONER': 9, 'I_STATUTE': 10, 'B_RESPONDENT': 11, 'I_GPE': 12, 'I_CASE_NUMBER': 13, 'O': 14, 'I_RESPONDENT': 15, 'B_GPE': 16, 'B_STATUTE': 17, 'B_DATE': 18, 'I_PRECEDENT': 19, 'I_PETITIONER': 20, 'B_COURT': 21, 'B_JUDGE': 22, 'I_JUDGE': 23, 'B_PROVISION': 24, 'I_DATE': 25, 'I_COURT': 26}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def labels_to_indices(labels, label_to_index):\n",
    "    return [[label_to_index[label] for label in sentence_labels] for sentence_labels in labels]\n",
    "\n",
    "# Convert the labels to indices\n",
    "test_labels_rnn_fasttext = labels_to_indices(test_labels.values(), labels_to_index_rnn_fasttext)\n",
    "test_labels_rnn_glove = labels_to_indices(test_labels.values(), labels_to_index_rnn_glove)\n",
    "test_labels_rnn_word2vec = labels_to_indices(test_labels.values(), labels_to_index_rnn_word2vec)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Converting to Tensors and Dataloaders for RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/c9/s8062nf53sv0b6gfv3ct0lv80000gn/T/ipykernel_38715/22124876.py:2: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at /Users/runner/work/pytorch/pytorch/pytorch/torch/csrc/utils/tensor_new.cpp:278.)\n",
      "  embeddings_fasttext_tensor = torch.tensor([fasttext_task1[key] for key in test_labels], dtype=torch.float)\n"
     ]
    }
   ],
   "source": [
    "# Convert to tensor\n",
    "embeddings_fasttext_tensor = torch.tensor([fasttext_task1[key] for key in test_labels], dtype=torch.float)\n",
    "embeddings_glove_tensor = torch.tensor([glove_task1[key] for key in test_labels], dtype=torch.float)\n",
    "embeddings_word2vec_tensor = torch.tensor([word2vec_task1[key] for key in test_labels], dtype=torch.float)\n",
    "\n",
    "# Get label tensors for RNN\n",
    "test_labels_rnn_fasttext_tensor = torch.tensor(test_labels_rnn_fasttext, dtype=torch.long)\n",
    "test_labels_rnn_glove_tensor = torch.tensor(test_labels_rnn_glove, dtype=torch.long)\n",
    "test_labels_rnn_word2vec_tensor = torch.tensor(test_labels_rnn_word2vec, dtype=torch.long)\n",
    "\n",
    "\"\"\"\n",
    "Dataloaders for RNN\n",
    "\"\"\"\n",
    "test_dataset_fasttext = TensorDataset(embeddings_fasttext_tensor, test_labels_rnn_fasttext_tensor)\n",
    "test_dataloader_fasttext_rnn = DataLoader(test_dataset_fasttext, batch_size=32, shuffle=False)\n",
    "\n",
    "test_dataset_glove = TensorDataset(embeddings_glove_tensor, test_labels_rnn_glove_tensor)\n",
    "test_dataloader_glove_rnn = DataLoader(test_dataset_glove, batch_size=32, shuffle=False)\n",
    "\n",
    "test_dataset_word2vec = TensorDataset(embeddings_word2vec_tensor, test_labels_rnn_word2vec_tensor)\n",
    "test_dataloader_word2ve_rnn = DataLoader(test_dataset_word2vec, batch_size=32, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 174, 300]) torch.Size([32, 174])\n"
     ]
    }
   ],
   "source": [
    "# Iterate through dataloaders to check the shape of the data\n",
    "for i, (x, y) in enumerate(test_dataloader_fasttext_rnn):\n",
    "    print(x.shape, y.shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 1 - RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FasttextRNNModel(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, output_dim, num_layers):\n",
    "        super(FasttextRNNModel, self).__init__()\n",
    "        self.rnn = nn.RNN(input_dim, hidden_dim, num_layers, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_dim, output_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out, _ = self.rnn(x)\n",
    "        out = self.fc(out)\n",
    "        return out\n",
    "    \n",
    "class RNNModel(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, output_dim, num_layers):\n",
    "        super(RNNModel, self).__init__()\n",
    "        self.rnn = nn.RNN(input_dim, hidden_dim, num_layers, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_dim, output_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out, _ = self.rnn(x)\n",
    "        out = self.fc(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Task1 - RNN Word2Vec - F1: 0.4389956021286754\n",
      "Task1 - RNN Word2Vec - Accuracy: 0.9813870783721128\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "For Word2Vec\n",
    "\"\"\"\n",
    "model_word2vec_rnn_task1 = RNNModel(input_dim=300, hidden_dim=256, output_dim=27, num_layers=1)\n",
    "\n",
    "# Load the model\n",
    "model_word2vec_rnn_task1.load_state_dict(torch.load(\"Task1_RNN_Word2Vec_model.pth\"))\n",
    "\n",
    "# Set the model to evaluation mode\n",
    "model_word2vec_rnn_task1.eval()\n",
    "\n",
    "# Evaluation\n",
    "test_preds_rnn_word2vec_task1 = []\n",
    "test_true_rnn_word2vec_task1 = []\n",
    "\n",
    "with torch.no_grad():  # Do not compute gradients\n",
    "    for inputs, labels in test_dataloader_word2ve_rnn:\n",
    "        outputs = model_word2vec_rnn_task1(inputs)\n",
    "        _, predicted = torch.max(outputs.data, 2)  # Get the predicted classes\n",
    "        \n",
    "        test_preds_rnn_word2vec_task1 .extend(predicted.view(-1).numpy())  # Flatten and store predictions\n",
    "        test_true_rnn_word2vec_task1.extend(labels.view(-1).numpy())  # Flatten and store true labels\n",
    "\n",
    "# Calculate the F1-score\n",
    "f1_score_rnn_word2vec_task1 = f1_score(test_true_rnn_word2vec_task1, test_preds_rnn_word2vec_task1, average='macro')\n",
    "\n",
    "# Calculate the accuracy\n",
    "accuracy_rnn_word2vec_task1 = accuracy_score(test_true_rnn_word2vec_task1, test_preds_rnn_word2vec_task1)\n",
    "\n",
    "print(f\"Task1 - RNN Word2Vec - F1: {f1_score_rnn_word2vec_task1}\")\n",
    "print(f\"Task1 - RNN Word2Vec - Accuracy: {accuracy_rnn_word2vec_task1}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Task1 - RNN GLoVe - F1: 0.5291016245424054\n",
      "Task1 - RNN GLoVe - Accuracy: 0.9854470863828909\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "For GLoVe\n",
    "\"\"\"\n",
    "model_glove_rnn_task1 = RNNModel(input_dim=300, hidden_dim=256, output_dim=27, num_layers=1)\n",
    "\n",
    "# Load the model\n",
    "model_glove_rnn_task1.load_state_dict(torch.load(\"Task1_RNN_GloVe_model.pth\"))\n",
    "\n",
    "# Set the model to evaluation mode\n",
    "model_glove_rnn_task1.eval()\n",
    "\n",
    "# Evaluation\n",
    "test_preds_rnn_glove_task1 = []\n",
    "test_true_rnn_glove_task1 = []\n",
    "\n",
    "with torch.no_grad():  # Do not compute gradients\n",
    "    for inputs, labels in test_dataloader_glove_rnn:\n",
    "        outputs = model_glove_rnn_task1(inputs)\n",
    "        _, predicted = torch.max(outputs.data, 2)  # Get the predicted classes\n",
    "        \n",
    "        test_preds_rnn_glove_task1.extend(predicted.view(-1).numpy())  # Flatten and store predictions\n",
    "        test_true_rnn_glove_task1.extend(labels.view(-1).numpy())\n",
    "\n",
    "# Calculate the F1-score\n",
    "f1_score_rnn_glove_task1 = f1_score(test_true_rnn_glove_task1, test_preds_rnn_glove_task1, average='macro')\n",
    "\n",
    "# Calculate the accuracy\n",
    "accuracy_rnn_glove_task1 = accuracy_score(test_true_rnn_glove_task1, test_preds_rnn_glove_task1)\n",
    "\n",
    "print(f\"Task1 - RNN GLoVe - F1: {f1_score_rnn_glove_task1}\")\n",
    "print(f\"Task1 - RNN GLoVe - Accuracy: {accuracy_rnn_glove_task1}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Task1 - RNN Fasttext - F1: 0.5253642307341272\n",
      "Task1 - RNN Fasttext - Accuracy: 0.9861146512277125\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "For Fasttext\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "model_fasttext_rnn_task1 = FasttextRNNModel(input_dim=300, hidden_dim=128, output_dim=27, num_layers=1)\n",
    "\n",
    "# Load the model\n",
    "model_fasttext_rnn_task1.load_state_dict(torch.load(\"Task1_RNN_FastText_model.pth\"))\n",
    "\n",
    "# Set the model to evaluation mode\n",
    "model_fasttext_rnn_task1.eval()\n",
    "\n",
    "# Evaluation\n",
    "test_preds_rnn_fasttext_task1 = []\n",
    "test_true_rnn_fasttext_task1 = []\n",
    "\n",
    "with torch.no_grad():  # Do not compute gradients\n",
    "    for inputs, labels in test_dataloader_fasttext_rnn:\n",
    "        outputs = model_fasttext_rnn_task1(inputs)\n",
    "        _, predicted = torch.max(outputs.data, 2)  # Get the predicted classes\n",
    "        \n",
    "        test_preds_rnn_fasttext_task1.extend(predicted.view(-1).numpy())  # Flatten and store predictions\n",
    "        test_true_rnn_fasttext_task1.extend(labels.view(-1).numpy())\n",
    "\n",
    "# Calculate the F1-score\n",
    "f1_score_rnn_fasttext_task1 = f1_score(test_true_rnn_fasttext_task1, test_preds_rnn_fasttext_task1, average='macro')\n",
    "\n",
    "# Calculate the accuracy\n",
    "accuracy_rnn_fasttext_task1 = accuracy_score(test_true_rnn_fasttext_task1, test_preds_rnn_fasttext_task1)\n",
    "\n",
    "print(f\"Task1 - RNN Fasttext - F1: {f1_score_rnn_fasttext_task1}\")\n",
    "print(f\"Task1 - RNN Fasttext - Accuracy: {accuracy_rnn_fasttext_task1}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Delete the models and the dataloaders\n",
    "del model_fasttext_rnn_task1\n",
    "del model_glove_rnn_task1\n",
    "del model_word2vec_rnn_task1\n",
    "del test_dataloader_fasttext_rnn\n",
    "del test_dataloader_glove_rnn\n",
    "del test_dataloader_word2ve_rnn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 1 - LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the LSTM model\n",
    "class LSTMModel(nn.Module):\n",
    "    def __init__(self, input_dim=300, hidden_dim=256, output_dim=27, num_layers=1, dropout=0):\n",
    "        super(LSTMModel, self).__init__()\n",
    "        self.lstm = nn.LSTM(input_dim, hidden_dim, num_layers, batch_first=True, dropout=dropout)\n",
    "        self.fc = nn.Linear(hidden_dim, output_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out, _ = self.lstm(x)\n",
    "        out = self.fc(out)  # Take the output of the last timestep\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 174, 300]) torch.Size([32, 174])\n"
     ]
    }
   ],
   "source": [
    "# Convert labels to indices for LSTM\n",
    "test_labels_lstm_fasttext = labels_to_indices(test_labels.values(), labels_to_index_lstm_fasttext)\n",
    "test_labels_lstm_glove = labels_to_indices(test_labels.values(), labels_to_index_lstm_glove)\n",
    "test_labels_lstm_word2vec = labels_to_indices(test_labels.values(), labels_to_index_lstm_word2vec)\n",
    "\n",
    "# Convert labels to tensor\n",
    "test_labels_lstm_fasttext_tensor = torch.tensor(test_labels_lstm_fasttext, dtype=torch.long)\n",
    "test_labels_lstm_glove_tensor = torch.tensor(test_labels_lstm_glove, dtype=torch.long)\n",
    "test_labels_lstm_word2vec_tensor = torch.tensor(test_labels_lstm_word2vec, dtype=torch.long)\n",
    "\n",
    "# Dataloaders for LSTM\n",
    "test_dataset_fasttext_lstm = TensorDataset(embeddings_fasttext_tensor, test_labels_lstm_fasttext_tensor)\n",
    "test_dataloader_fasttext_lstm = DataLoader(test_dataset_fasttext_lstm, batch_size=32, shuffle=False)\n",
    "\n",
    "test_dataset_glove_lstm = TensorDataset(embeddings_glove_tensor, test_labels_lstm_glove_tensor)\n",
    "test_dataloader_glove_lstm = DataLoader(test_dataset_glove_lstm, batch_size=32, shuffle=False)\n",
    "\n",
    "test_dataset_word2vec_lstm = TensorDataset(embeddings_word2vec_tensor, test_labels_lstm_word2vec_tensor)\n",
    "test_dataloader_word2vec_lstm = DataLoader(test_dataset_word2vec_lstm, batch_size=32, shuffle=False)\n",
    "\n",
    "# Iterate through dataloaders to check the shape of the data\n",
    "for i, (x, y) in enumerate(test_dataloader_fasttext_lstm):\n",
    "    print(x.shape, y.shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Task1 - LSTM Word2Vec - F1: 0.5073440588693289\n",
      "Task1 - LSTM Word2Vec - Accuracy: 0.984069475294032\n",
      "Task1 - LSTM GLoVe - F1: 0.5693615397028231\n",
      "Task1 - LSTM GLoVe - Accuracy: 0.9866972532741021\n",
      "Task1 - LSTM Fasttext - F1: 0.5347081648623497\n",
      "Task1 - LSTM Fasttext - Accuracy: 0.9869703479833473\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "For Word2Vec\n",
    "\"\"\"\n",
    "model_word2vec_lstm_task1 = LSTMModel(input_dim=300, hidden_dim=256, output_dim=27, num_layers=1)\n",
    "\n",
    "# Load the model\n",
    "model_word2vec_lstm_task1.load_state_dict(torch.load(\"Task1_LSTM_Word2Vec_model.pth\"))\n",
    "\n",
    "# Set the model to evaluation mode\n",
    "model_word2vec_lstm_task1.eval()\n",
    "\n",
    "# Evaluation\n",
    "test_preds_lstm_word2vec_task1 = []\n",
    "test_true_lstm_word2vec_task1 = []\n",
    "\n",
    "with torch.no_grad():  # Do not compute gradients\n",
    "    for inputs, labels in test_dataloader_word2vec_lstm:\n",
    "        outputs = model_word2vec_lstm_task1(inputs)\n",
    "        _, predicted = torch.max(outputs.data, 2)  # Get the predicted classes\n",
    "        \n",
    "        test_preds_lstm_word2vec_task1.extend(predicted.view(-1).numpy())  # Flatten and store predictions\n",
    "        test_true_lstm_word2vec_task1.extend(labels.view(-1).numpy())  # Flatten and store true labels\n",
    "\n",
    "# Calculate the F1-score\n",
    "f1_score_lstm_word2vec_task1 = f1_score(test_true_lstm_word2vec_task1, test_preds_lstm_word2vec_task1, average='macro')\n",
    "\n",
    "# Calculate the accuracy\n",
    "accuracy_lstm_word2vec_task1 = accuracy_score(test_true_lstm_word2vec_task1, test_preds_lstm_word2vec_task1)\n",
    "\n",
    "print(f\"Task1 - LSTM Word2Vec - F1: {f1_score_lstm_word2vec_task1}\")\n",
    "print(f\"Task1 - LSTM Word2Vec - Accuracy: {accuracy_lstm_word2vec_task1}\")\n",
    "\n",
    "\"\"\"\n",
    "For GLoVe\n",
    "\"\"\"\n",
    "\n",
    "model_glove_lstm_task1 = LSTMModel(input_dim=300, hidden_dim=256, output_dim=27, num_layers=1)\n",
    "\n",
    "# Load the model\n",
    "model_glove_lstm_task1.load_state_dict(torch.load(\"Task1_LSTM_GloVe_model.pth\"))\n",
    "\n",
    "# Set the model to evaluation mode\n",
    "model_glove_lstm_task1.eval()\n",
    "\n",
    "# Evaluation\n",
    "test_preds_lstm_glove_task1 = []\n",
    "test_true_lstm_glove_task1 = []\n",
    "\n",
    "with torch.no_grad():  # Do not compute gradients\n",
    "    for inputs, labels in test_dataloader_glove_lstm:\n",
    "        outputs = model_glove_lstm_task1(inputs)\n",
    "        _, predicted = torch.max(outputs.data, 2)  # Get the predicted classes\n",
    "        \n",
    "        test_preds_lstm_glove_task1.extend(predicted.view(-1).numpy())  # Flatten and store predictions\n",
    "        test_true_lstm_glove_task1.extend(labels.view(-1).numpy())\n",
    "\n",
    "# Calculate the F1-score\n",
    "f1_score_lstm_glove_task1 = f1_score(test_true_lstm_glove_task1, test_preds_lstm_glove_task1, average='macro')\n",
    "\n",
    "# Calculate the accuracy\n",
    "accuracy_lstm_glove_task1 = accuracy_score(test_true_lstm_glove_task1, test_preds_lstm_glove_task1)\n",
    "\n",
    "print(f\"Task1 - LSTM GLoVe - F1: {f1_score_lstm_glove_task1}\")\n",
    "print(f\"Task1 - LSTM GLoVe - Accuracy: {accuracy_lstm_glove_task1}\")\n",
    "\n",
    "\"\"\"\n",
    "For Fasttext\n",
    "\"\"\"\n",
    "\n",
    "model_fasttext_lstm_task1 = LSTMModel(input_dim=300, hidden_dim=256, output_dim=27, num_layers=1)\n",
    "\n",
    "# Load the model\n",
    "model_fasttext_lstm_task1.load_state_dict(torch.load(\"Task1_LSTM_Fasttext_model.pth\"))\n",
    "\n",
    "# Set the model to evaluation mode\n",
    "model_fasttext_lstm_task1.eval()\n",
    "\n",
    "# Evaluation\n",
    "test_preds_lstm_fasttext_task1 = []\n",
    "test_true_lstm_fasttext_task1 = []\n",
    "\n",
    "with torch.no_grad():  # Do not compute gradients\n",
    "    for inputs, labels in test_dataloader_fasttext_lstm:\n",
    "        outputs = model_fasttext_lstm_task1(inputs)\n",
    "        _, predicted = torch.max(outputs.data, 2)  # Get the predicted classes\n",
    "        \n",
    "        test_preds_lstm_fasttext_task1.extend(predicted.view(-1).numpy())  # Flatten and store predictions\n",
    "        test_true_lstm_fasttext_task1.extend(labels.view(-1).numpy())\n",
    "\n",
    "# Calculate the F1-score\n",
    "f1_score_lstm_fasttext_task1 = f1_score(test_true_lstm_fasttext_task1, test_preds_lstm_fasttext_task1, average='macro')\n",
    "\n",
    "# Calculate the accuracy\n",
    "accuracy_lstm_fasttext_task1 = accuracy_score(test_true_lstm_fasttext_task1, test_preds_lstm_fasttext_task1)\n",
    "\n",
    "print(f\"Task1 - LSTM Fasttext - F1: {f1_score_lstm_fasttext_task1}\")\n",
    "print(f\"Task1 - LSTM Fasttext - Accuracy: {accuracy_lstm_fasttext_task1}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Delete the models and the dataloaders\n",
    "del model_fasttext_lstm_task1\n",
    "del model_glove_lstm_task1\n",
    "del model_word2vec_lstm_task1\n",
    "\n",
    "del test_dataloader_fasttext_lstm\n",
    "del test_dataloader_glove_lstm\n",
    "del test_dataloader_word2vec_lstm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 1 - GRU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the GRU model\n",
    "class GRUModel(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, output_dim, num_layers, dropout):\n",
    "        super(GRUModel, self).__init__()\n",
    "        self.gru = nn.GRU(input_dim, hidden_dim, num_layers, batch_first=True, dropout=dropout)\n",
    "        self.fc = nn.Linear(hidden_dim, output_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out, _ = self.gru(x)\n",
    "        out = self.fc(out)  # Take the output of the last timestep\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 174, 300]) torch.Size([32, 174])\n"
     ]
    }
   ],
   "source": [
    "# Convert labels to indices for GRU\n",
    "test_labels_gru_fasttext = labels_to_indices(test_labels.values(), labels_to_index_gru_fasttext)\n",
    "test_labels_gru_glove = labels_to_indices(test_labels.values(), labels_to_index_gru_glove)\n",
    "test_labels_gru_word2vec = labels_to_indices(test_labels.values(), labels_to_index_gru_word2vec)\n",
    "\n",
    "# Convert labels to tensor\n",
    "test_labels_gru_fasttext_tensor = torch.tensor(test_labels_gru_fasttext, dtype=torch.long)\n",
    "test_labels_gru_glove_tensor = torch.tensor(test_labels_gru_glove, dtype=torch.long)\n",
    "test_labels_gru_word2vec_tensor = torch.tensor(test_labels_gru_word2vec, dtype=torch.long)\n",
    "\n",
    "# Dataloaders for GRU\n",
    "test_dataset_fasttext_gru = TensorDataset(embeddings_fasttext_tensor, test_labels_gru_fasttext_tensor)\n",
    "test_dataloader_fasttext_gru = DataLoader(test_dataset_fasttext_gru, batch_size=32, shuffle=False)\n",
    "\n",
    "test_dataset_glove_gru = TensorDataset(embeddings_glove_tensor, test_labels_gru_glove_tensor)\n",
    "test_dataloader_glove_gru = DataLoader(test_dataset_glove_gru, batch_size=32, shuffle=False)\n",
    "\n",
    "test_dataset_word2vec_gru = TensorDataset(embeddings_word2vec_tensor, test_labels_gru_word2vec_tensor)\n",
    "test_dataloader_word2vec_gru = DataLoader(test_dataset_word2vec_gru, batch_size=32, shuffle=False)\n",
    "\n",
    "# Iterate through dataloaders to check the shape of the data\n",
    "for i, (x, y) in enumerate(test_dataloader_fasttext_gru):\n",
    "    print(x.shape, y.shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Task1 - GRU Word2Vec - F1: 0.5565088645009443\n",
      "Task1 - GRU Word2Vec - Accuracy: 0.9840087875808664\n",
      "Task1 - GRU GLoVe - F1: 0.5974169569786105\n",
      "Task1 - GRU GLoVe - Accuracy: 0.9866729781888359\n",
      "Task1 - GRU Fasttext - F1: 0.5513825692058083\n",
      "Task1 - GRU Fasttext - Accuracy: 0.9877350131692337\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "For Word2Vec\n",
    "\"\"\"\n",
    "model_word2vec_gru_task1 = GRUModel(input_dim=300, hidden_dim=256, output_dim=27, num_layers=1, dropout=0)\n",
    "\n",
    "# Load the model\n",
    "model_word2vec_gru_task1.load_state_dict(torch.load(\"Task1_GRU_Word2Vec_model.pth\"))\n",
    "\n",
    "# Set the model to evaluation mode\n",
    "model_word2vec_gru_task1.eval()\n",
    "\n",
    "# Evaluation\n",
    "test_preds_gru_word2vec_task1 = []\n",
    "test_true_gru_word2vec_task1 = []\n",
    "\n",
    "with torch.no_grad():  # Do not compute gradients\n",
    "    for inputs, labels in test_dataloader_word2vec_gru:\n",
    "        outputs = model_word2vec_gru_task1(inputs)\n",
    "        _, predicted = torch.max(outputs.data, 2)  # Get the predicted classes\n",
    "        \n",
    "        test_preds_gru_word2vec_task1.extend(predicted.view(-1).numpy())  # Flatten and store predictions\n",
    "        test_true_gru_word2vec_task1.extend(labels.view(-1).numpy())  # Flatten and store true labels\n",
    "\n",
    "# Calculate the F1-score\n",
    "f1_score_gru_word2vec_task1 = f1_score(test_true_gru_word2vec_task1, test_preds_gru_word2vec_task1, average='macro')\n",
    "\n",
    "# Calculate the accuracy\n",
    "accuracy_gru_word2vec_task1 = accuracy_score(test_true_gru_word2vec_task1, test_preds_gru_word2vec_task1)\n",
    "\n",
    "print(f\"Task1 - GRU Word2Vec - F1: {f1_score_gru_word2vec_task1}\")\n",
    "print(f\"Task1 - GRU Word2Vec - Accuracy: {accuracy_gru_word2vec_task1}\")\n",
    "\n",
    "\"\"\"\n",
    "For GLoVe\n",
    "\"\"\"\n",
    "\n",
    "model_glove_gru_task1 = GRUModel(input_dim=300, hidden_dim=256, output_dim=27, num_layers=1, dropout=0)\n",
    "\n",
    "# Load the model\n",
    "model_glove_gru_task1.load_state_dict(torch.load(\"Task1_GRU_GLoVe_model.pth\"))\n",
    "\n",
    "# Set the model to evaluation mode\n",
    "model_glove_gru_task1.eval()\n",
    "\n",
    "# Evaluation\n",
    "test_preds_gru_glove_task1 = []\n",
    "test_true_gru_glove_task1 = []\n",
    "\n",
    "with torch.no_grad():  # Do not compute gradients\n",
    "    for inputs, labels in test_dataloader_glove_gru:\n",
    "        outputs = model_glove_gru_task1(inputs)\n",
    "        _, predicted = torch.max(outputs.data, 2)  # Get the predicted classes\n",
    "        \n",
    "        test_preds_gru_glove_task1.extend(predicted.view(-1).numpy())  # Flatten and store predictions\n",
    "        test_true_gru_glove_task1.extend(labels.view(-1).numpy())\n",
    "\n",
    "# Calculate the F1-score\n",
    "f1_score_gru_glove_task1 = f1_score(test_true_gru_glove_task1, test_preds_gru_glove_task1, average='macro')\n",
    "\n",
    "# Calculate the accuracy\n",
    "accuracy_gru_glove_task1 = accuracy_score(test_true_gru_glove_task1, test_preds_gru_glove_task1)\n",
    "\n",
    "print(f\"Task1 - GRU GLoVe - F1: {f1_score_gru_glove_task1}\")\n",
    "print(f\"Task1 - GRU GLoVe - Accuracy: {accuracy_gru_glove_task1}\")\n",
    "\n",
    "\"\"\"\n",
    "For Fasttext\n",
    "\"\"\"\n",
    "\n",
    "model_fasttext_gru_task1 = GRUModel(input_dim=300, hidden_dim=256, output_dim=27, num_layers=1, dropout=0)\n",
    "\n",
    "# Load the model\n",
    "model_fasttext_gru_task1.load_state_dict(torch.load(\"Task1_GRU_Fasttext_model.pth\"))\n",
    "\n",
    "# Set the model to evaluation mode\n",
    "model_fasttext_gru_task1.eval()\n",
    "\n",
    "# Evaluation\n",
    "test_preds_gru_fasttext_task1 = []\n",
    "test_true_gru_fasttext_task1 = []\n",
    "\n",
    "with torch.no_grad():  # Do not compute gradients\n",
    "    for inputs, labels in test_dataloader_fasttext_gru:\n",
    "        outputs = model_fasttext_gru_task1(inputs)\n",
    "        _, predicted = torch.max(outputs.data, 2)  # Get the predicted classes\n",
    "        \n",
    "        test_preds_gru_fasttext_task1.extend(predicted.view(-1).numpy())  # Flatten and store predictions\n",
    "        test_true_gru_fasttext_task1.extend(labels.view(-1).numpy())\n",
    "\n",
    "# Calculate the F1-score\n",
    "f1_score_gru_fasttext_task1 = f1_score(test_true_gru_fasttext_task1, test_preds_gru_fasttext_task1, average='macro')\n",
    "\n",
    "# Calculate the accuracy\n",
    "accuracy_gru_fasttext_task1 = accuracy_score(test_true_gru_fasttext_task1, test_preds_gru_fasttext_task1)\n",
    "\n",
    "print(f\"Task1 - GRU Fasttext - F1: {f1_score_gru_fasttext_task1}\")\n",
    "print(f\"Task1 - GRU Fasttext - Accuracy: {accuracy_gru_fasttext_task1}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Delete the models and the dataloaders\n",
    "del model_fasttext_gru_task1\n",
    "del model_glove_gru_task1\n",
    "del model_word2vec_gru_task1\n",
    "\n",
    "del test_dataloader_fasttext_gru\n",
    "del test_dataloader_glove_gru\n",
    "del test_dataloader_word2vec_gru"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 1 - BiLSTM - CRF (Part 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_sum_exp(x):\n",
    "    \"\"\"calculate log(sum(exp(x))) = max(x) + log(sum(exp(x - max(x))))\n",
    "    \"\"\"\n",
    "    max_score = x.max(-1)[0]\n",
    "    return max_score + (x - max_score.unsqueeze(-1)).exp().sum(-1).log()\n",
    "\n",
    "\n",
    "IMPOSSIBLE = -1e4\n",
    "\n",
    "\n",
    "class CRF(nn.Module):\n",
    "    \"\"\"General CRF module.\n",
    "    The CRF module contain a inner Linear Layer which transform the input from features space to tag space.\n",
    "\n",
    "    :param in_features: number of features for the input\n",
    "    :param num_tag: number of tags. DO NOT include START, STOP tags, they are included internal.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, in_features, num_tags):\n",
    "        super(CRF, self).__init__()\n",
    "\n",
    "        self.num_tags = num_tags + 2\n",
    "        self.start_idx = self.num_tags - 2\n",
    "        self.stop_idx = self.num_tags - 1\n",
    "\n",
    "        self.fc = nn.Linear(in_features, self.num_tags)\n",
    "\n",
    "        # transition factor, Tij mean transition from j to i\n",
    "        self.transitions = nn.Parameter(torch.randn(self.num_tags, self.num_tags), requires_grad=True)\n",
    "        self.transitions.data[self.start_idx, :] = IMPOSSIBLE\n",
    "        self.transitions.data[:, self.stop_idx] = IMPOSSIBLE\n",
    "\n",
    "    def forward(self, features):\n",
    "        \"\"\"decode tags\n",
    "\n",
    "        :param features: [B, L, C], batch of unary scores\n",
    "        :param masks: [B, L] masks\n",
    "        :return: (best_score, best_paths)\n",
    "            best_score: [B]\n",
    "            best_paths: [B, L]\n",
    "        \"\"\"\n",
    "        features = self.fc(features)\n",
    "        return self.__viterbi_decode(features)\n",
    "\n",
    "    def loss(self, features, tags):\n",
    "        \"\"\"negative log likelihood loss\n",
    "        B: batch size, L: sequence length, D: dimension\n",
    "\n",
    "        :param features: [B, L, D]\n",
    "        :param ys: tags, [B, L]\n",
    "        :param masks: masks for padding, [B, L]\n",
    "        :return: loss\n",
    "        \"\"\"\n",
    "        features = self.fc(features)\n",
    "        forward_score = self.__forward_algorithm(features)\n",
    "        gold_score = self.__score_sentence(features, tags)\n",
    "        return (forward_score - gold_score).mean()\n",
    "\n",
    "    def __score_sentence(self, features, tags):\n",
    "        \"\"\"Gives the score of a provided tag sequence\n",
    "\n",
    "        :param features: [B, L, C]\n",
    "        :param tags: [B, L]\n",
    "        :param masks: [B, L]\n",
    "        :return: [B] score in the log space\n",
    "        \"\"\"\n",
    "        B, L, C = features.shape\n",
    "\n",
    "        # emission score\n",
    "        emit_scores = features.gather(dim=2, index=tags.unsqueeze(-1)).squeeze(-1)\n",
    "\n",
    "        # transition score\n",
    "        start_tag = torch.full((B, 1), self.start_idx, dtype=torch.long, device=tags.device)\n",
    "        tags = torch.cat([start_tag, tags], dim=1)  # [B, L+1]\n",
    "        trans_scores = self.transitions[tags[:, 1:], tags[:, :-1]]\n",
    "\n",
    "        # last transition score to STOP tag\n",
    "        last_tag = tags[:, -1]\n",
    "        last_scores = self.transitions[self.stop_idx, last_tag]\n",
    "\n",
    "        score = (trans_scores + emit_scores).sum(dim=1) + last_scores\n",
    "        return score\n",
    "\n",
    "    def __viterbi_decode(self, features):\n",
    "        \"\"\"decode to tags using viterbi algorithm\n",
    "\n",
    "        :param features: [B, L, C], batch of unary scores\n",
    "        :param masks: [B, L] masks\n",
    "        :return: (best_score, best_paths)\n",
    "            best_score: [B]\n",
    "            best_paths: [B, L]\n",
    "        \"\"\"\n",
    "        B, L, C = features.shape\n",
    "\n",
    "        bps = torch.zeros(B, L, C, dtype=torch.long, device=features.device)  # back pointers\n",
    "\n",
    "        # Initialize the viterbi variables in log space\n",
    "        max_score = torch.full((B, C), IMPOSSIBLE, device=features.device)  # [B, C]\n",
    "        max_score[:, self.start_idx] = 0\n",
    "\n",
    "        for t in range(L):\n",
    "            emit_score_t = features[:, t]  # [B, C]\n",
    "\n",
    "            # [B, 1, C] + [C, C]\n",
    "            acc_score_t = max_score.unsqueeze(1) + self.transitions  # [B, C, C]\n",
    "            acc_score_t, bps[:, t, :] = acc_score_t.max(dim=-1)\n",
    "            acc_score_t += emit_score_t\n",
    "            max_score = acc_score_t\n",
    "\n",
    "        # Transition to STOP_TAG\n",
    "        max_score += self.transitions[self.stop_idx]\n",
    "        best_score, best_tag = max_score.max(dim=-1)\n",
    "\n",
    "        # Follow the back pointers to decode the best path.\n",
    "        best_paths = []\n",
    "        bps = bps.cpu().numpy()\n",
    "        for b in range(B):\n",
    "            best_tag_b = best_tag[b].item()\n",
    "            best_path = [best_tag_b]\n",
    "            for bps_t in reversed(bps[b]):\n",
    "                best_tag_b = bps_t[best_tag_b]\n",
    "                best_path.append(best_tag_b)\n",
    "            # drop the last tag and reverse the left\n",
    "            best_paths.append(best_path[-2::-1])\n",
    "\n",
    "        return best_score, best_paths\n",
    "\n",
    "    def __forward_algorithm(self, features):\n",
    "        \"\"\"calculate the partition function with forward algorithm.\n",
    "        TRICK: log_sum_exp([x1, x2, x3, x4, ...]) = log_sum_exp([log_sum_exp([x1, x2]), log_sum_exp([x3, x4]), ...])\n",
    "\n",
    "        :param features: features. [B, L, C]\n",
    "        :param masks: [B, L] masks\n",
    "        :return:    [B], score in the log space\n",
    "        \"\"\"\n",
    "        B, L, C = features.shape\n",
    "\n",
    "        scores = torch.full((B, C), IMPOSSIBLE, device=features.device)  # [B, C]\n",
    "        scores[:, self.start_idx] = 0.\n",
    "        trans = self.transitions.unsqueeze(0)  # [1, C, C]\n",
    "\n",
    "        # Iterate through the sentence\n",
    "        for t in range(L):\n",
    "            emit_score_t = features[:, t].unsqueeze(2)  # [B, C, 1]\n",
    "            score_t = scores.unsqueeze(1) + trans + emit_score_t  # [B, 1, C] + [1, C, C] + [B, C, 1] => [B, C, C]\n",
    "            score_t = log_sum_exp(score_t)  # [B, C]\n",
    "\n",
    "            scores = score_t\n",
    "            \n",
    "        scores = log_sum_exp(scores + self.transitions[self.stop_idx])\n",
    "        return scores\n",
    "    \n",
    "class BiLSTM_CRF(nn.Module):\n",
    "    def __init__(self, tagset_size, embedding_dim, hidden_dim, num_lstm_layers=2):\n",
    "        super(BiLSTM_CRF, self).__init__()\n",
    "        self.embedding_dim = embedding_dim\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.tagset_size = tagset_size\n",
    "\n",
    "        self.lstm = nn.LSTM(embedding_dim, hidden_dim // 2, num_layers=num_lstm_layers,\n",
    "                       bidirectional=True, batch_first=True)\n",
    "        self.crf = CRF(hidden_dim, self.tagset_size)\n",
    "\n",
    "\n",
    "    def loss(self, embd, tags):\n",
    "        # Get the emission scores from the BiLSTM\n",
    "        lstm_out, _ = self.lstm(embd)\n",
    "\n",
    "        # Calculate and return the CRF loss\n",
    "        return self.crf.loss(lstm_out, tags)\n",
    "\n",
    "    def forward(self, embd):\n",
    "        # Directly pass the embeddings to the LSTM\n",
    "        lstm_out, _ = self.lstm(embd)\n",
    "\n",
    "        # Pass the output of LSTM to CRF\n",
    "        scores, tag_seq = self.crf(lstm_out)\n",
    "        return scores, tag_seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 174, 300]) torch.Size([32, 174])\n"
     ]
    }
   ],
   "source": [
    "# Convert labels to indices for BiLSTM-CRF\n",
    "test_labels_bilstmcrf_fasttext = labels_to_indices(test_labels.values(), labels_to_index_bilstmcrf_fasttext)\n",
    "test_labels_bilstmcrf_glove = labels_to_indices(test_labels.values(), labels_to_index_bilstmcrf_glove)\n",
    "test_labels_bilstmcrf_word2vec = labels_to_indices(test_labels.values(), labels_to_index_bilstmcrf_word2vec)\n",
    "\n",
    "# Convert labels to tensor\n",
    "test_labels_bilstmcrf_fasttext_tensor = torch.tensor(test_labels_bilstmcrf_fasttext, dtype=torch.long)\n",
    "test_labels_bilstmcrf_glove_tensor = torch.tensor(test_labels_bilstmcrf_glove, dtype=torch.long)\n",
    "test_labels_bilstmcrf_word2vec_tensor = torch.tensor(test_labels_bilstmcrf_word2vec, dtype=torch.long)\n",
    "\n",
    "# Dataloaders for BiLSTM-CRF\n",
    "test_dataset_fasttext_bilstmcrf = TensorDataset(embeddings_fasttext_tensor, test_labels_bilstmcrf_fasttext_tensor)\n",
    "test_dataloader_fasttext_bilstmcrf = DataLoader(test_dataset_fasttext_bilstmcrf, batch_size=32, shuffle=False)\n",
    "\n",
    "test_dataset_glove_bilstmcrf = TensorDataset(embeddings_glove_tensor, test_labels_bilstmcrf_glove_tensor)\n",
    "test_dataloader_glove_bilstmcrf = DataLoader(test_dataset_glove_bilstmcrf, batch_size=32, shuffle=False)\n",
    "\n",
    "test_dataset_word2vec_bilstmcrf = TensorDataset(embeddings_word2vec_tensor, test_labels_bilstmcrf_word2vec_tensor)\n",
    "test_dataloader_word2vec_bilstmcrf = DataLoader(test_dataset_word2vec_bilstmcrf, batch_size=32, shuffle=False)\n",
    "\n",
    "# Iterate through dataloaders to check the shape of the data\n",
    "for i, (x, y) in enumerate(test_dataloader_fasttext_bilstmcrf):\n",
    "    print(x.shape, y.shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Task1 - BiLSTM-CRF Word2Vec - F1: 0.6442874163417016\n",
      "Task1 - BiLSTM-CRF Word2Vec - Accuracy: 0.9873890932041899\n",
      "Task1 - BiLSTM-CRF GLoVe - F1: 0.663692296870113\n",
      "Task1 - BiLSTM-CRF GLoVe - Accuracy: 0.9901443153819077\n",
      "Task1 - BiLSTM-CRF Fasttext - F1: 0.6245697543149539\n",
      "Task1 - BiLSTM-CRF Fasttext - Accuracy: 0.9900532838121594\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "For Word2Vec\n",
    "\"\"\"\n",
    "\n",
    "model_word2vec_bilstmcrf_task1 = BiLSTM_CRF(tagset_size=27, embedding_dim=300, hidden_dim=256, num_lstm_layers=2)\n",
    "\n",
    "# Load the model\n",
    "model_word2vec_bilstmcrf_task1.load_state_dict(torch.load(\"Task1_BiLSTMCRF_Word2Vec.pt\"))\n",
    "\n",
    "# Evaluation\n",
    "test_preds_bilstmcrf_word2vec_task1 = []\n",
    "test_true_bilstmcrf_word2vec_task1 = []\n",
    "\n",
    "with torch.no_grad():  # Do not compute gradients\n",
    "    for embeddings, labels in test_dataloader_word2vec_bilstmcrf:\n",
    "\n",
    "        # Run forward pass\n",
    "        loss = model_word2vec_bilstmcrf_task1.loss(embeddings, labels)\n",
    "\n",
    "        # Prediction\n",
    "        _, predicted = model_word2vec_bilstmcrf_task1(embeddings)\n",
    "        # Assuming 'predicted' is a list of lists with variable lengths\n",
    "        max_len = max(len(p) for p in predicted)\n",
    "\n",
    "        # Pad the sequences\n",
    "        padded_predicted = [p + [0] * (max_len - len(p)) for p in predicted]\n",
    "        predicted = torch.tensor(padded_predicted, dtype=torch.long)\n",
    "\n",
    "        labels = labels.view(-1)\n",
    "        predicted = predicted.view(-1)\n",
    "\n",
    "        # Append the predictions and true labels\n",
    "        test_preds_bilstmcrf_word2vec_task1.extend(predicted.tolist())\n",
    "        test_true_bilstmcrf_word2vec_task1.extend(labels.tolist())\n",
    "\n",
    "# Calculate the F1-score\n",
    "f1_score_bilstmcrf_word2vec_task1 = f1_score(test_true_bilstmcrf_word2vec_task1, test_preds_bilstmcrf_word2vec_task1, average='macro')\n",
    "\n",
    "# Calculate the accuracy\n",
    "accuracy_bilstmcrf_word2vec_task1 = accuracy_score(test_true_bilstmcrf_word2vec_task1, test_preds_bilstmcrf_word2vec_task1)\n",
    "\n",
    "print(f\"Task1 - BiLSTM-CRF Word2Vec - F1: {f1_score_bilstmcrf_word2vec_task1}\")\n",
    "print(f\"Task1 - BiLSTM-CRF Word2Vec - Accuracy: {accuracy_bilstmcrf_word2vec_task1}\")\n",
    "\n",
    "\"\"\"\n",
    "For GLoVe\n",
    "\"\"\"\n",
    "\n",
    "model_glove_bilstmcrf_task1 = BiLSTM_CRF(tagset_size=27, embedding_dim=300, hidden_dim=256, num_lstm_layers=2)\n",
    "\n",
    "# Load the model\n",
    "model_glove_bilstmcrf_task1.load_state_dict(torch.load(\"Task1_BiLSTMCRF_GLOVE.pt\"))\n",
    "\n",
    "# Evaluation\n",
    "test_preds_bilstmcrf_glove_task1 = []\n",
    "test_true_bilstmcrf_glove_task1 = []\n",
    "\n",
    "with torch.no_grad():  # Do not compute gradients\n",
    "    for embeddings, labels in test_dataloader_glove_bilstmcrf:\n",
    "\n",
    "        # Run forward pass\n",
    "        loss = model_glove_bilstmcrf_task1.loss(embeddings, labels)\n",
    "\n",
    "        # Prediction\n",
    "        _, predicted = model_glove_bilstmcrf_task1(embeddings)\n",
    "        # Assuming 'predicted' is a list of lists with variable lengths\n",
    "        max_len = max(len(p) for p in predicted)\n",
    "\n",
    "        # Pad the sequences\n",
    "        padded_predicted = [p + [0] * (max_len - len(p)) for p in predicted]\n",
    "        predicted = torch.tensor(padded_predicted, dtype=torch.long)\n",
    "\n",
    "        labels = labels.view(-1)\n",
    "        predicted = predicted.view(-1)\n",
    "\n",
    "        # Append the predictions and true labels\n",
    "        test_preds_bilstmcrf_glove_task1.extend(predicted.tolist())\n",
    "        test_true_bilstmcrf_glove_task1.extend(labels.tolist())\n",
    "\n",
    "# Calculate the F1-score\n",
    "f1_score_bilstmcrf_glove_task1 = f1_score(test_true_bilstmcrf_glove_task1, test_preds_bilstmcrf_glove_task1, average='macro')\n",
    "\n",
    "# Calculate the accuracy\n",
    "accuracy_bilstmcrf_glove_task1 = accuracy_score(test_true_bilstmcrf_glove_task1, test_preds_bilstmcrf_glove_task1)\n",
    "\n",
    "print(f\"Task1 - BiLSTM-CRF GLoVe - F1: {f1_score_bilstmcrf_glove_task1}\")\n",
    "print(f\"Task1 - BiLSTM-CRF GLoVe - Accuracy: {accuracy_bilstmcrf_glove_task1}\")\n",
    "\n",
    "\"\"\"\n",
    "For Fasttext\n",
    "\"\"\"\n",
    "\n",
    "model_fasttext_bilstmcrf_task1 = BiLSTM_CRF(tagset_size=27, embedding_dim=300, hidden_dim=256, num_lstm_layers=2)\n",
    "\n",
    "# Load the model\n",
    "model_fasttext_bilstmcrf_task1.load_state_dict(torch.load(\"Task1_BiLSTMCRF_Fasttext.pt\"))\n",
    "\n",
    "# Evaluation\n",
    "test_preds_bilstmcrf_fasttext_task1 = []\n",
    "test_true_bilstmcrf_fasttext_task1 = []\n",
    "\n",
    "with torch.no_grad():  # Do not compute gradients\n",
    "    for embeddings, labels in test_dataloader_fasttext_bilstmcrf:\n",
    "\n",
    "        # Run forward pass\n",
    "        loss = model_fasttext_bilstmcrf_task1.loss(embeddings, labels)\n",
    "\n",
    "        # Prediction\n",
    "        _, predicted = model_fasttext_bilstmcrf_task1(embeddings)\n",
    "        # Assuming 'predicted' is a list of lists with variable lengths\n",
    "        max_len = max(len(p) for p in predicted)\n",
    "\n",
    "        # Pad the sequences\n",
    "        padded_predicted = [p + [0] * (max_len - len(p)) for p in predicted]\n",
    "        predicted = torch.tensor(padded_predicted, dtype=torch.long)\n",
    "\n",
    "        labels = labels.view(-1)\n",
    "        predicted = predicted.view(-1)\n",
    "\n",
    "        # Append the predictions and true labels\n",
    "        test_preds_bilstmcrf_fasttext_task1.extend(predicted.tolist())\n",
    "        test_true_bilstmcrf_fasttext_task1.extend(labels.tolist())\n",
    "\n",
    "# Calculate the F1-score\n",
    "f1_score_bilstmcrf_fasttext_task1 = f1_score(test_true_bilstmcrf_fasttext_task1, test_preds_bilstmcrf_fasttext_task1, average='macro')\n",
    "\n",
    "# Calculate the accuracy\n",
    "accuracy_bilstmcrf_fasttext_task1 = accuracy_score(test_true_bilstmcrf_fasttext_task1, test_preds_bilstmcrf_fasttext_task1)\n",
    "\n",
    "print(f\"Task1 - BiLSTM-CRF Fasttext - F1: {f1_score_bilstmcrf_fasttext_task1}\")\n",
    "print(f\"Task1 - BiLSTM-CRF Fasttext - Accuracy: {accuracy_bilstmcrf_fasttext_task1}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plotting Label-Wise F1 Scores\n",
    "- Plotting label-wise F1 scores for best model i.e. BiLSTM-CRF for the three embeddings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For Word2Vec: \n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 864x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import f1_score\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_labelwise_f1_scores(label_dict, predicted_list, true_list):\n",
    "    # Reverse the dictionary mapping to convert indexes back to labels\n",
    "    index_to_label = {v: k for k, v in label_dict.items()}\n",
    "\n",
    "    # Convert indexes to actual labels\n",
    "    true_labels = [index_to_label[idx] for idx in true_list]\n",
    "    predicted_labels = [index_to_label[idx] for idx in predicted_list]\n",
    "\n",
    "    # Remove the B- and I- prefixes from the labels\n",
    "    true_labels_stripped = [label[2:] if label.startswith(('B_', 'I_')) else label for label in true_labels]\n",
    "    predicted_labels_stripped = [label[2:] if label.startswith(('B_', 'I_')) else label for label in predicted_labels]\n",
    "\n",
    "    # Remove 'O' label if present\n",
    "    unique_labels_stripped = list(set(true_labels_stripped + predicted_labels_stripped))\n",
    "    unique_labels_stripped.remove('O') if 'O' in unique_labels_stripped else None\n",
    "\n",
    "    # Calculate F1 scores for each unique label\n",
    "    f1_scores = f1_score(true_labels_stripped, predicted_labels_stripped, labels=unique_labels_stripped, average=None)\n",
    "\n",
    "    # Create a mapping of labels to their F1 scores\n",
    "    label_f1_scores = dict(zip(unique_labels_stripped, f1_scores))\n",
    "\n",
    "    # Sort labels by F1 score\n",
    "    sorted_labels = sorted(label_f1_scores, key=label_f1_scores.get, reverse=True)\n",
    "    sorted_f1_scores = [label_f1_scores[label] for label in sorted_labels]\n",
    "\n",
    "    # Plot the F1 scores\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    plt.bar(sorted_labels, sorted_f1_scores, color='skyblue')\n",
    "    plt.xlabel('Labels')\n",
    "    plt.ylabel('F1 Score')\n",
    "    plt.title('Label-wise F1 Scores')\n",
    "    plt.xticks(rotation=90)  # Rotate labels to prevent overlap\n",
    "    plt.tight_layout()  # Adjust layout to fit all label names\n",
    "    plt.show()\n",
    "\n",
    "print(\"For Word2Vec: \")\n",
    "plot_labelwise_f1_scores(labels_to_index_bilstmcrf_word2vec, test_preds_bilstmcrf_word2vec_task1, test_true_bilstmcrf_word2vec_task1) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For GLoVe: \n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA1gAAAGoCAYAAABbkkSYAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8/fFQqAAAACXBIWXMAAAsTAAALEwEAmpwYAAA5dElEQVR4nO3deZhkZXn+8e8NiKCAiIxG2REUccFRRBQXIi5gFKLRBJS4Q8xPFLcgLnFLNLjGPRHjFtdI3FAxqHGLO6MsCqJOQAKoERDCqmzP749zWoqiu5kZT/XpOvX9XFdfnK27n2Jmququ877Pm6pCkiRJkvSHW6/vAiRJkiRpKAxYkiRJktQRA5YkSZIkdcSAJUmSJEkdMWBJkiRJUkcMWJIkSZLUEQOWJGmtJflqkqct9feO/Ixtk1yaZP0/5OdIktQ1A5YkzbAkP0/y4L7rWFtV9T9VtUlVXdPVz0yyfZJqg9vc18ntudsmOTbJL9prtr+Rn3W/JN9K8n9JfpPkm0nu1VWtkqTly4AlSdL1bd6Gt02qarf22LXAfwB/dmPfnGQz4LPAW4EtgK2AVwC/67JI795J0vJkwJIk3UCSWyb5bJLzklzYbm89dtntk3wvycVJPp1ki5Hv37O9g3NRkpOT7L2Gv/cVSd7abt8kyWVJXtfub5zkt0m2GLnbtEF77klJzkhySZIzkzx+5Gc+JcmP28dxfJLt1vb/R1X9b1W9AzhhDS6/Q/s9H6mqa6rqiqr6QlWdMlLTIW1NlyQ5Lck92uN3aodQXpTk1CT7j3zP+5L8U5LjklwG/HGS2yX5ePvndGaSZ41cv0eSVe2fz/8meePaPm5J0tozYEmS5rMe8F5gO2Bb4ArgbWPXPAF4CnBb4GrgLQBJtgI+B/w9zR2c5wMfT7JiDX7v14C92+17Ab8CHtDu3wf4SVX9ZvQbkty8/d37VdWmwH2Bk9pzBwAvAh4NrAD+C/jIGtTxh/gpcE2S9yfZL8ktx+p9LPBymv9/mwH7AxckuQnwGeALwK2BZwIfSnLHkW9/HPAqYFPgW+31J9PcJdsHeHaSh7XXvhl4c1VtBtwe+NgEHqskaYwBS5J0A1V1QVV9vKour6pLaN7UP3Dssg9U1Y+q6jLgb4E/b4etHQwcV1XHVdW1VfVFYBXw8DX41d8Gdk5yK5pg9W5gqySbtL//awt837XAXZJsXFW/rKpT2+NPB/6hqn5cVVcDrwbufiN3sc5v7yBdlOT5a1Dz9VTVxcD9gALeBZzXzt+6TXvJ04DXVtUJ1VhdVWcBewKbAEdV1ZVV9WWaoYYHjfz4T1fVN6vqWuCuwIqqemV7/Rnt7zuwvfYqYKckW1bVpVX1nbV9LJKktWfAkiTdQJKbJXlnkrOSXAx8Hdh8bN7P2SPbZwE3Abakuev12JGQchFN4LjtPL/n1JGGEvevqitowtgDaQLW12ju1OzFAgGrDXh/QROmfpnkc0l2aU9vB7x5pI7fAKG547OQLatq8/br9Yv+j1pAG+ieVFVbA3cBbge8qT29DfDf83zb7YCz2/A056yxWkf/n28H3G7s//OLgLkg91Sa4YqnJzkhySPW5bFIktbOBn0XIElalp4H3BG4d1X9KsndgRNpwsmcbUa2t6W5Y3I+TQj4QFUdcmO/pKruPM/hrwEPAlbSzHn6GvAwYA+aoDffzzkeOD7JxjRDE98F3L+t5VVV9aEbq2VSqur0JO8D/qo9dDbNkL1xvwC2SbLeSMjalmbI4e9/3Mj22cCZVbXzAr/3Z8BBSdajGSL570lu1QZSSdKEeAdLknSTJBuNfG1AM8fnCuCitnnFy+b5voOT7JrkZsArgX9v26Z/EHhkkoclWb/9mXvP0yRjIV+jmZ90WlVdCXyVZljdmVV13vjFSW6T5IB2LtbvgEtphgwC/DPwwiR3bq+9RTsHaq0l2Qi4abt703Z/vut2SfK8ucebZBuaYX5zQ/T+BXh+knumsVM7ZPG7wOXAEW2Dj72BRwIfXaCk7wGXJHlB2wBk/SR3SdsOPsnBSVa0Ye2i9nuuXeBnSZI6YsCSJB1HE6bmvl5OM5xtY5o7Ut+haVE+7gPA+2gaUWwEPAugqs4G5ppLnEdzp+VvWPPXnG+1v3vubtVpwG9Z4O5V+3OfS3MH6Dc0Qwn/uq3lk8BrgI+2Qx1/BOy3hnWMu4ImvAGc3u7P5xLg3sB3225/32l/7/Pamo6hmdP24fbaTwFbtGHykW195wPvAJ5QVafP90vaMPsI4O7Ame33/Atwi/aSfYFTk1xK0/DiwHYIpiRpglJVN36VJEmSJOlGeQdLkiRJkjpiwJIkSZKkjhiwJEmSJKkjBixJkiRJ6sjUrYO15ZZb1vbbb993GZIkSZJm2Pe///3zq2rF+PGpC1jbb789q1at6rsMSZIkSTMsyVnzHXeIoCRJkiR1xIAlSZIkSR0xYEmSJElSRwxYkiRJktQRA5YkSZIkdcSAJUmSJEkdMWBJkiRJUkcMWJIkSZLUEQOWJEmSJHXEgCVJkiRJHTFgSZIkSVJHDFiSJEmS1JEN+i5gCI468fy+S1hrR67csu8SJEmSpMHxDpYkSZIkdcSAJUmSJEkdMWBJkiRJUkecg6U1Mo3zzMC5ZpIkSVpa3sGSJEmSpI54B0tqeZdOkiRJfygDljRDDJGSJEmT5RBBSZIkSeqIAUuSJEmSOmLAkiRJkqSOGLAkSZIkqSMGLEmSJEnqiAFLkiRJkjpiwJIkSZKkjhiwJEmSJKkjLjQsaXCmcUFlF1OWJGkYvIMlSZIkSR0xYEmSJElSRwxYkiRJktQRA5YkSZIkdcSAJUmSJEkdMWBJkiRJUkcMWJIkSZLUEQOWJEmSJHXEgCVJkiRJHTFgSZIkSVJHDFiSJEmS1BEDliRJkiR1xIAlSZIkSR0xYEmSJElSRwxYkiRJktQRA5YkSZIkdcSAJUmSJEkdMWBJkiRJUkcMWJIkSZLUEQOWJEmSJHVkogEryb5JfpJkdZIj5zm/bZKvJDkxySlJHj7JeiRJkiRpkiYWsJKsD7wd2A/YFTgoya5jl70E+FhVrQQOBN4xqXokSZIkadImeQdrD2B1VZ1RVVcCHwUOGLumgM3a7VsAv5hgPZIkSZI0UZMMWFsBZ4/sn9MeG/Vy4OAk5wDHAc+c7wclOTTJqiSrzjvvvEnUKkmSJEl/sL6bXBwEvK+qtgYeDnwgyQ1qqqqjq2r3qtp9xYoVS16kJEmSJK2JSQasc4FtRva3bo+NeirwMYCq+jawEbDlBGuSJEmSpImZZMA6Adg5yQ5JNqRpYnHs2DX/A+wDkORONAHLMYCSJEmSptLEAlZVXQ0cBhwP/JimW+CpSV6ZZP/2sucBhyQ5GfgI8KSqqknVJEmSJEmTtMEkf3hVHUfTvGL02EtHtk8D9ppkDZIkSZK0VPpuciFJkiRJg2HAkiRJkqSOTHSIoCRpMo468fy+S1gnR660Uawkadi8gyVJkiRJHTFgSZIkSVJHDFiSJEmS1BEDliRJkiR1xIAlSZIkSR0xYEmSJElSRwxYkiRJktQRA5YkSZIkdcSAJUmSJEkdMWBJkiRJUkcMWJIkSZLUEQOWJEmSJHXEgCVJkiRJHTFgSZIkSVJHDFiSJEmS1BEDliRJkiR1xIAlSZIkSR0xYEmSJElSRwxYkiRJktQRA5YkSZIkdcSAJUmSJEkd2aDvAiRJms9RJ57fdwnr5MiVW/ZdgiSpR97BkiRJkqSOGLAkSZIkqSMGLEmSJEnqiAFLkiRJkjpiwJIkSZKkjhiwJEmSJKkjBixJkiRJ6ogBS5IkSZI6YsCSJEmSpI4YsCRJkiSpIwYsSZIkSeqIAUuSJEmSOmLAkiRJkqSOGLAkSZIkqSMGLEmSJEnqiAFLkiRJkjpiwJIkSZKkjhiwJEmSJKkjBixJkiRJ6ogBS5IkSZI6YsCSJEmSpI4YsCRJkiSpIwYsSZIkSerIBn0XIEnSrDrqxPP7LmGdHLlyy75LkKRlyztYkiRJktQRA5YkSZIkdWSiASvJvkl+kmR1kiMXuObPk5yW5NQkH55kPZIkSZI0SRObg5VkfeDtwEOAc4ATkhxbVaeNXLMz8EJgr6q6MMmtJ1WPJEmSJE3aJO9g7QGsrqozqupK4KPAAWPXHAK8vaouBKiqX0+wHkmSJEmaqEkGrK2As0f2z2mPjboDcIck30zynST7zveDkhyaZFWSVeedd96EypUkSZKkP0zfTS42AHYG9gYOAt6VZPPxi6rq6Kravap2X7FixdJWKEmSJElraJIB61xgm5H9rdtjo84Bjq2qq6rqTOCnNIFLkiRJkqbOJAPWCcDOSXZIsiFwIHDs2DWforl7RZItaYYMnjHBmiRJkiRpYiYWsKrqauAw4Hjgx8DHqurUJK9Msn972fHABUlOA74C/E1VXTCpmiRJkiRpkibWph2gqo4Djhs79tKR7QKe235JkiRJ0lTru8mFJEmSJA2GAUuSJEmSOmLAkiRJkqSOGLAkSZIkqSMGLEmSJEnqiAFLkiRJkjpiwJIkSZKkjqxRwEpyvyRPbrdXJNlhsmVJkiRJ0vS50YCV5GXAC4AXtoduAnxwkkVJkiRJ0jRakztYjwL2By4DqKpfAJtOsihJkiRJmkZrErCurKoCCiDJzSdbkiRJkiRNpzUJWB9L8k5g8ySHAF8C3jXZsiRJkiRp+myw2MkkAf4N2AW4GLgj8NKq+uIS1CZJkiRJU2XRgFVVleS4qrorYKiSJElr5agTz++7hHVy5Mot+y5B0pRakyGCP0hyr4lXIkmSJElTbtE7WK17A49PchZNJ8HQ3Ny620QrkyRJkqQpsyYB62ETr0KSJEmSBuBGhwhW1VnA5sAj26/N22OSJEmSpBE3GrCSHA58CLh1+/XBJM+cdGGSJEmSNG3WZIjgU4F7V9VlAEleA3wbeOskC5MkSZKkabMmXQQDXDOyf017TJIkSZI0Yk3uYL0X+G6ST7b7fwq8e2IVSZIkSdKUutGAVVVvTPJV4H7toSdX1YkTrUqSJEmSptCNBqwkewKnVtUP2v3Nkty7qr478eokSZIkaYqsyRysfwIuHdm/tD0mSZIkSRqxJnOwUlU1t1NV1yZZk++TJEmaCUedeH7fJay1I1du2XcJ0iCtyR2sM5I8K8lN2q/DgTMmXZgkSZIkTZs1CVhPB+4LnNt+3Rs4dJJFSZIkSdI0WpMugr8GDlyCWiRJkiRpqi14ByvJIUl2breT5D1J/i/JKUnusXQlSpIkSdJ0WGyI4OHAz9vtg4DdgB2B5wJvnmxZkiRJkjR9FhsieHVVXdVuPwL416q6APhSktdOvjRJkiQtF9PYKRHslqilt9gdrGuT3DbJRsA+wJdGzm082bIkSZIkafosdgfrpcAqYH3g2Ko6FSDJA7FNuyRJkiTdwIIBq6o+m2Q7YNOqunDk1CrgLyZemSRJkiRNmUXbtFfV1cCFY8cum2hFkiRJkjSl1mShYUmSJEnSGjBgSZIkSVJH1ilgJdml60IkSZIkadqt6x2sL3RahSRJkiQNwIJNLpK8ZaFTwOYTqUaSJEmSpthiXQSfDDwP+N085w6aTDmSJEmSNL0WC1gnAD+qqm+Nn0jy8olVJEmSJElTarGA9Rjgt/OdqKodJlOOJEmSJE2vxZpcbFJVly9ZJZIkSZI05RYLWJ+a20jy8cmXIkmSJEnTbbGAlZHtHSddiCRJkiRNu8UCVi2wLUmSJEmax2JNLnZLcjHNnayN223a/aqqzSZenSRJkiRNkQUDVlWtv5SFSJIkSdK0W2yIoCRJkiRpLUw0YCXZN8lPkqxOcuQi1/1Zkkqy+yTrkSRJkqRJmljASrI+8HZgP2BX4KAku85z3abA4cB3J1WLJEmSJC2FSd7B2gNYXVVnVNWVwEeBA+a57u+A1wC/nWAtkiRJkjRxkwxYWwFnj+yf0x77vST3ALapqs8t9oOSHJpkVZJV5513XveVSpIkSVIHemtykWQ94I3A827s2qo6uqp2r6rdV6xYMfniJEmSJGkdTDJgnQtsM7K/dXtszqbAXYCvJvk5sCdwrI0uJEmSJE2rSQasE4Cdk+yQZEPgQODYuZNV9X9VtWVVbV9V2wPfAfavqlUTrEmSJEmSJmZiAauqrgYOA44Hfgx8rKpOTfLKJPtP6vdKkiRJUl82mOQPr6rjgOPGjr10gWv3nmQtkiRJkjRpvTW5kCRJkqShMWBJkiRJUkcMWJIkSZLUEQOWJEmSJHXEgCVJkiRJHTFgSZIkSVJHDFiSJEmS1BEDliRJkiR1xIAlSZIkSR0xYEmSJElSRwxYkiRJktQRA5YkSZIkdcSAJUmSJEkdMWBJkiRJUkcMWJIkSZLUEQOWJEmSJHXEgCVJkiRJHTFgSZIkSVJHNui7AEmSJGk5OOrE8/suYZ0cuXLLvkvQCO9gSZIkSVJHDFiSJEmS1BEDliRJkiR1xIAlSZIkSR0xYEmSJElSRwxYkiRJktQR27RLkiRJM8JW9JPnHSxJkiRJ6ogBS5IkSZI6YsCSJEmSpI4YsCRJkiSpIwYsSZIkSeqIAUuSJEmSOmLAkiRJkqSOGLAkSZIkqSMGLEmSJEnqiAFLkiRJkjpiwJIkSZKkjhiwJEmSJKkjBixJkiRJ6ogBS5IkSZI6YsCSJEmSpI4YsCRJkiSpIwYsSZIkSeqIAUuSJEmSOmLAkiRJkqSOGLAkSZIkqSMGLEmSJEnqiAFLkiRJkjpiwJIkSZKkjhiwJEmSJKkjBixJkiRJ6shEA1aSfZP8JMnqJEfOc/65SU5LckqS/0yy3STrkSRJkqRJmljASrI+8HZgP2BX4KAku45ddiKwe1XdDfh34LWTqkeSJEmSJm2Sd7D2AFZX1RlVdSXwUeCA0Quq6itVdXm7+x1g6wnWI0mSJEkTNcmAtRVw9sj+Oe2xhTwV+Px8J5IcmmRVklXnnXdehyVKkiRJUneWRZOLJAcDuwOvm+98VR1dVbtX1e4rVqxY2uIkSZIkaQ1tMMGffS6wzcj+1u2x60nyYODFwAOr6ncTrEeSJEmSJmqSd7BOAHZOskOSDYEDgWNHL0iyEngnsH9V/XqCtUiSJEnSxE0sYFXV1cBhwPHAj4GPVdWpSV6ZZP/2stcBmwDHJDkpybEL/DhJkiRJWvYmOUSQqjoOOG7s2EtHth88yd8vSZIkSUtpWTS5kCRJkqQhMGBJkiRJUkcMWJIkSZLUEQOWJEmSJHXEgCVJkiRJHTFgSZIkSVJHDFiSJEmS1BEDliRJkiR1xIAlSZIkSR0xYEmSJElSRwxYkiRJktQRA5YkSZIkdcSAJUmSJEkdMWBJkiRJUkcMWJIkSZLUEQOWJEmSJHXEgCVJkiRJHTFgSZIkSVJHDFiSJEmS1BEDliRJkiR1xIAlSZIkSR0xYEmSJElSRwxYkiRJktQRA5YkSZIkdcSAJUmSJEkdMWBJkiRJUkcMWJIkSZLUEQOWJEmSJHXEgCVJkiRJHTFgSZIkSVJHDFiSJEmS1BEDliRJkiR1xIAlSZIkSR0xYEmSJElSRwxYkiRJktQRA5YkSZIkdcSAJUmSJEkdMWBJkiRJUkcMWJIkSZLUEQOWJEmSJHXEgCVJkiRJHTFgSZIkSVJHDFiSJEmS1BEDliRJkiR1xIAlSZIkSR0xYEmSJElSRwxYkiRJktQRA5YkSZIkdcSAJUmSJEkdMWBJkiRJUkcMWJIkSZLUkYkGrCT7JvlJktVJjpzn/E2T/Ft7/rtJtp9kPZIkSZI0SRMLWEnWB94O7AfsChyUZNexy54KXFhVOwH/CLxmUvVIkiRJ0qRN8g7WHsDqqjqjqq4EPgocMHbNAcD72+1/B/ZJkgnWJEmSJEkTk6qazA9OHgPsW1VPa/f/Erh3VR02cs2P2mvOaff/u73m/LGfdShwaLt7R+AnEyl6edoSOP9Gr5puPsZh8DEOxyw8Th/jMPgYh2MWHqePcXi2q6oV4wc36KOStVVVRwNH911HH5Ksqqrd+65jknyMw+BjHI5ZeJw+xmHwMQ7HLDxOH+PsmOQQwXOBbUb2t26PzXtNkg2AWwAXTLAmSZIkSZqYSQasE4Cdk+yQZEPgQODYsWuOBZ7Ybj8G+HJNasyiJEmSJE3YxIYIVtXVSQ4DjgfWB95TVacmeSWwqqqOBd4NfCDJauA3NCFM1zcLQyN9jMPgYxyOWXicPsZh8DEOxyw8Th/jjJhYkwtJkiRJmjUTXWhYkiRJkmaJAUuSJEmSOmLAkiRJkqSOGLC0pJK8r+8apDWRZNu+a+hbkr36rkHScCR50Mj2DmPnHr30FU2OryGzzYC1jCR5b5L3LPD17r7r68jd+i5g0mbhBSTJESPbjx079+qlr2giPtV3AUshyfpJDkry/CR3aY89Ism3gLf1XJ7WUJKtk9xvZP+5SV7afu3UZ21dSXKzJDcZ2b9jkucM5XkVZuL14/Uj2x8fO/eSpSxkCXyq7wKWQvsasuXI/oZJDk3y4z7r6psBa3n5LPC5sa9TgH2Ah/VYV5dulmRlknvM99V3cR2ZhReQ0SUVXjh2bt+lLGSC0ncBS+TdwNOAWwFvSfJBmr/Dr62qlb1W1pEklyS5uP26ZGT/8iRX911fR14HbD6y/1fAZUABr+ijoAn4D2B7gDY0fhvYEXhGkn/osa4uDf31Iwtsz7c/7Yb2eG4gyYE0yyydkuRrSR4KnAHsBzy+1+J6NrF1sLT2qur3T6ZJdgReBDwAOIrmTdAQbAW8gfmfeAp40DzHp80svIDMwmPcKslbFjpZVc9aymImaHfgblV1bZKNgF8Bt6+qC3quqzNVtenofpJNgGfQhJBP9lJU9+5YVZ8d2b+8qt4AkOS/eqqpa7esqp+1208EPlJVz0yyIfB9bvhhzzQa+nNrLbA93/60m4XXkJcA96yq1e2H5N8GHlNVn+m5rt4ZsJaZJLvQ/IVdSfOJ5NOraiifsAKsrqohhKjFzMILyCw8xito3rQN3ZVVdS1AVf02yRlDClejkmwOPBt4AvBh4F4Deqwbje3vM7K9JcMw+tzyIJrXSKrqyiTX9lNS54b+3LpjkmNpwuLcNu3+Dgt/21SahdeQK6tqNUBV/SDJzwxXDQPWMpLkGOCeNHd4ngNcA2yWNB9aVdVv+qtOa2EWXkB2S3IxzWPauN2m3R9/ozetLqiq9/ddxBLYJckp7XaA27f7Aaqqpn7eZDs/4HnAXwDvAVZW1f/1W1XnLklyh6r6KVz3etF+aHdJr5V155QkrwfOBXYCvgC/D85DMfTXjwNGtl8/dm58f9rNwmvIrZM8d2R/89H9qnpjDzUtC6kawgciw5Dk51z3CVVx/eEAVVU7LnlRHUvykKr6Yt91TFKSBy52vqq+tlS1TEqSm1TVVX3XMUlJvlNVe85zfD3goKr6UA9ldS7Jdoudr6qzlqqWSUlyGXAe8F7mCRtDeBOQZF/gLcCrgB+0h+9JM9T88Kr6fF+1dSXJxsDhwG2B91TVye3x+9IMa/1An/V1YRZeP2bFQq8hQ5LkZYudr6qhzP9cawYsLakkX2HhYQ5VVfsscG5qJHlfVT2p7zomKckPqmooTUnmleQWwP+jmTd4LPBF4DCaOyEnV9UBi3z71EiyS1Wd3m7ftKp+N3Juz6r6Tn/VdSPJy1lkeNVQ3gS0XSCPAO7cHvoR8Lqq+lF/VU1O21HwLsC5VfXrvuvpSpK709yhO7WqBtWJLckBwNZV9fZ2/7vAivb0EVX1770V17Eba9NeVf+zVLVo6Rmwlpl2su7jue4F8lTgw6NveqZZknvOc3hPmjcFv66qey1xSZ2bkfBx4lA6zC0kyaeBC2km7e4D3JrmrvLhVXVSj6V1avTv6/jf3Vn4uzwLkmw7hDdzSf4ZeGtVndp+APJtmqH0WwDPr6qP9FpgB5K8FDiYZu7OvYF/qKp39VtVd5J8Eziwqs5u90+ieX69OfDeIXzIOifJD5lnNBJNoLx1Va3fS2EdSvKxqvrzdvs1VfWCkXNfqKqH9lddv5yDtYwk2ZXmk/Jvct3EyL2BFyc5oKpO7au2rlTV7yd8tkMh/pZmzs7ThzCEpXWzJCtZoONTVf1gvuNTZsXYuOvrGcKQK2DHqrorQJJ/AX4JbFtVv+23rM4NvWsZAEn2o+kyt2t76FTgNVV1XH9VdSvJfWjuuH69qn6d5G7AkcD9gW16La4b96+qp7fbTwZ+WlV/muSPgM8DUx+waOYJ3r2qLk9yK5rW9IMJWMCGc+Gq9Y220cwFSW7eV1GTMPf6MSfJ9sALgAcDQ1kvcueR7YfQPL45K5hhBqzl5a3AX4/PUUryYJoFP/+4l6o6luRhNJ0Sfwe8qqq+0nNJXZuFVvTrA5swoDfg8/j9HLOquibJOQMMVzD8rmUkOYSmJfsRwKr28O7AUUm2rqqjeyuuI0leBzwCOAl4QZLjadY3+wfgKT2W1qUrR7YfAhwDUFW/mmsGNQC/q6rLAarqgnbO55DccnSnqg4b2R3kG/IkOwMvprkj+QbgWQOaw7zYa8QgXj/WlQFredlqvgYQVfWlJG/to6CuJTmB5kn0dTTDOxhdYHggd3dmoRX9L6vqlX0XMWFznRLh+t0S57rrbdZfaZ3aul2rJSPbtPtb9VdWp54D3G+sE+uX27ta3wCmPmABf0LTHfG3SW4JnA3cpap+3m9ZnbooySNougjuBTwVIMkGwMZ9Ftah8c6Btx/pKlhVtX9/pXXiu0kOGR/2mOSvgO/1VNNEtHMiX0wz5eO1wFOr6pp+q+rc3Iid9WheI+dG74Th/JtcJwas5WW98UnmAO3in0P5s7oMuBR4TPs1aih3dxaU5F5VdULfdXRgMB8XL2QI4+PX0N+MbK8aOze+P60y3zIX7R2CPuqZhN/O3WGtqgvb9Wh+3nNNXfsrmk6JfwQ8u6p+1R7fB/hcb1V1a7x5zuu57k7AEP6yPgf4VJLHcf1ulzcF/rSvoibkZJoPOj4H7AHsMfp8M5CFhn8FvHGe7bn9mWWTi2UkyUtoGj48Y641cjtm9y3Aqhm4YzAISR5aVV8Y2d8VOKj9uqiqdu+tuI4kWUEzuXxO0Ty2wTyhJNli7NDgHuOsaDuVHTrX1nvk+G7Au6pqj34q606Si4Cvjxx6QLs/lDsfM2GeLnvfoxn1UcALquqYPuvrSpIHMdLMq6q+3Gc9k5DkSSzevXToa2TNNAPWMpPkMJp5AjejeWG8FHh9VQ1liOARVfXadvuxoy8WSV5dVS/qr7rutMF4LlRdBWwH7D6UT5STnMkNuyNtQvOJ3dOG8DgXeIyb0sxxGcRjhN8vwvsMmo6J76EZvnt/4L+B51XV6h7L60SS+wEfolkHa67Rzu7AE4GDq+obfdXWlZH1kzammXhewGrgChjG+kmz0LFsVrrsJbkrsEu7++OhLiWwkCQbVNXVfdfxh0rygMXOV9XXFzs/ZAasZSrJpgBVdYNFMafZLLSETvJtYDPgo8BHq+pnSc6sqh16Lm3ikjya5k7Bvn3XMilDe4xJvkAzFHBTmjdy7wU+QxOyHl9Ve/dXXXeS3IYmSM59an4a8PaRYWZTrV0T6lU0DS3mWrJvA7wPeNEQJtWPLg8xz+vHIJaOSHLC6HIlSd421wgiA1i4tm2v/2mav5un0HyAdVeav7MHVNXFi3z7VEnyjaq6X7v9gar6y5FzQ3m/85l5DhdwN2CbGRpqfwNDmdczCPO1vR4brzuE1tez0BL6f2maA9yGZmjHz5iRbjpV9Yl2qOtgDfAx3qaqXpTmyeasqnpde/z0JM/os7AuVdX/Ai+F3683eGfg2l6L6tZrae4i7zD3wVySzWjm8LwOeHZ/pXVmFjqWDb3L3t/RfKDzoKq6FqDtlHgUzQcEz+yxtq6Ntp2/89i5QbzfqapHju4n2YumS/SvGNaf5VozYC0vm/ZdwBIYfEvodl2WWwCPBl7etmjdPMkeVTWoLknjkmxC001osAb4GK+BZpJOkvPHzg0igCy2QG2SQSxQS9Oi/Q6jcwSr6uIkfw2czjAC1ix0LBt6l70HA3ebC1cAVXVtkhcBP+yvrImYhQ8EAEiyD826pgW8er6O2LPGgLWMVNUr+q5hCcy1vh5te027v1F/ZXWrqv6PZqjVe5PcmmbxyH9Msm1VTf2CnwssMnxLYH+aNdum3iw8xtZcW+hwwxbRQxnWOgsL1NZ8DVjaNdyG8mZuFjqWDb3L3pXzzT2qqquT/G6+b5himyd5FM0HApu3w8uheW69RX9ldSfJn9C0ov8/4CVDmM/aFedgLSPtYphfbefsBHg38GfAWcATq+rEXgvUWmu77VFV57X72811iJxmSV42dqiAC4CvV9UgPoWchccI12uOMK+BNEcYnbvzOeCYqnrf+LlpluRTwCeq6l/Hjh8M/LldBKfLULvsJTmdpvnTfFMEPlhVd1r6qiYjyXsXO19VT16qWiYlybXAOTQNrub7gGdmn3cMWMtIkh/RLBR5Vfvp1fOAhwIrgZdV1f17LbBDYx2ETquqU/usp0ttOH4ZcBgwN8HzapohSoNotT+kjo9roh0WSFVd2nctWntJvgK8gWaB2q8Au1TVr9IsUPujqtpl0R8wBZJsBXyCpmvgaKfEjYFHVdW5fdXWFTuWTb8kX2Xx1uV/vHTV6A81Cx/QrSsD1jKS5KSqunu7/WHgu1X15nZ/KB1n5joIbUvzicfgOgi1Q8v2o+k0d2Z7bEfgn4D/qKp/7LO+Lgzl7+ONaeevvJDrJitfCrymqt7RX1XdSnLKYuer6m5LVcukJLkD1y1Q+6aRu1cPAx5aVc/rsbxOjd35OK2q/rPPerpkxzJNmyR3BA5lpCU9cHRV/bS/qrqXZCNgp3Z3dbWLns8yA9YykuQHwJ/QrEdzFk2XnVPbcz8ewq3zJG8BrgSOmKeD0MZVNfVdZ5KcCDykqs4fO74C+MJAhiOdDOzNAp2Qquo3S1rQBLSdAu8LHFZVZ7THdgTeTPPhx9/3WV9X2nV2CvgwTXv2K0bPD2FI62KS3LyqLuu7Dq29kY5ltwReVVXzBTAtIyPzkOYUcD5w0gCXpbkPzV3lo2nm04VmRNIhwKOr6js9lteJdhTAq2mWhziL5jFuQzMH/cVDWB5iXRmwlpEkjwDeSTOs7DNVdUh7/IE0geRP+qyvC0lOo+kgdPXY8Q2AHw4kRP6oqu6ytuemSTsZ+VzmD1hVVTsucUmdS/ITYLfxT+KSbAycXFV36Key7iXZhWZexCNp1of6MM2HAVO/EOacdgjdbYFTqurKtvnMs4EnVdXtei1Oa8WOZdNrgXlJW9DchXzqUOaaAST5PM2Ih6+OHX8gcGRV7ddLYR1K8o80HbCfM8/yEFdU1eF91tcnA9Yy0waNTavqwpFjN6f5s5r6+R+jwyDX5tw0WWz43FCG1g2lMcBikpy+0Nycxc5NuyR/Abyd5o3B627s+mmQ5Nk0na5W03RjewfwGuBfgddW1S/7q05raqxj2avsWDYcSbYDPlZV9+67lq4k+elCH8Ql+UlV3XGpa+pakp8xtjxEe3x94PSq2rmfyvpnm/ZlZPTWeTLvyKtPLF01E7PRyNolo0LzxmcI5lrRjxtUK/qFJLlNNYu6Trtzk+wzPoel/fR8UG/I27s7BwKPohmi/Bzgk70W1a1DgTtW1W+SbAv8FNirqr5/I9+n5eUzNB3LLgCOSHLE6MlZ7lg27arqrCQ36buOji025HEow5JnYXmIdWLAWl4euci5YhgBa3ztkvFzU29GJlq/eXQnyeY0Swo8DrgTMIQhV88CPp3kG1y/K9tewAG9VdWxJF+jGeLxMZo1oi5oT22YZIshzKcDfjv3OKrqf9pPjw1X08cOcwPVNoMY2jpY27TzzscF2Gqpi5mQ05I8YYHlIU7vqaZlwSGCy0iSP6qqQYQMDV87F+kAmlC1kuZN+p/SrBN1bY+ldSLJTjRd5+7ASFc24CfAL6vqv/uqrUtJfs51bZNHXxDCcObT/Rr46MihA0f3q+pZS16U1lqS91XVk/quQ+uu7QQ5/sZzC5r5kX9ZVd9a+qomI8kTFztfVe9fqlomZRaWh1hXBqxlJMmvgB8BHwE+XlUX9VtR95IcUVWvbbcfW1XHjJybqbWVplm7jMD9gS/QvFH9Mk1r1h16LaxDST4LvLDGFhVu13B7dVUtdsdZy8gsvNGZBUOZwzrL2gYPo2885xZw/9ksd5ybdkNeHmJdGbCWkXZS4INpPl19OPAdmrD16aq6YrHvnRajL5DjL5a+eE6PtrX3ejRNAj5aVeckOWMIdzvmJDmhqu61wLkfVtVdl7qmSUgy/m+ugPOr6uw+6llqSTYYUrfEIUtyOk23y4WWh/jB0laktZXkEprnmNE/w7k3or8D/pumvffUv0FvOyYu9Ca7quqpS1nPJCTZYrHzAxlivk6cg7WMVNU1wPHA8Uk2pFms9kDgTUn+s6oe32uB3cgC2/Pta5mqqruPtPb+UpLzgU0H1OACYPNFzm28VEUsgTfMc2yL9jnooKo6aYnr6VySb1TV/drtD1TVX46c/h7gBzvTYSuav6/zLg8BPGhpy9HaqqpNFzrXfsh8F+BD7X+n3WfnObYNTROhoczV/j7XBeYbDDEHBvOh69oyYC1T7Totp9Gs+n1PmsYBQzA+NGChc1rGkuzZLpL4MuBlSe5JE7ZOSHJOVd233wo7sSrJIVX1rtGDSZ7GdWPNp15Vzds4IMnuwFuAByxtRRNx85HtO4+d84Od6bG6qgxRA9V+yHxykrf2XUsXqurjc9vtIvUvonk+PQp4d191dWzvoS9Gv64cIrjMJNmG5q7VQTRvCj5CMwRrEN1YklxD0540NHcBLp87BWxUVUNr0zpICw3nTLO+wP2r6us9lNWpJLehaVV+JdefvLshzeTdwTekGcqwXYcmD8MsrL+nYWlHeryEphHU64APDmlIss+fC/MO1jKS5Fs0QyCOAQ4ZYhvhGWlhPrPa9TCmPlwBtEMd75vkj7luuMrnqurLPZa1ZNqAOZRP4DZP8iiaeYObj6w5GOAW/ZWltXTEjV8iLQ9JjqEZgfQGmmGB1wCbza1zOpD5SY4AWIB3sJaRJA8A/quqKskmAFV1ac9ldSrJvYAtq+rzY8f3A349xFA5REkuYpEg5YKf06MdjjNf2+T7AodX1WeWvqputZPNF1RVT16qWrTukvyQ+UP/3JICd1vikqQFzbMExvUaewyhKdQ8S2BczywvgeEdrGWkqr6e5K+TvJBmeGDajjuvqap39FxeV15Ds5jpuNOA9+Ik5WlxHvM3R9D0WTW2P9c2+blV9ese6umcAWow3gN8E/gNYEtvLWtVtX3fNSyB0fWvNMKAtYwkeTGwF82kwTPaYzsCb06yRVX9fa8FdmPT+SZEVtVZSbbsoyCtk0ur6mt9F6E/3CysAZXk3sDRwO2BHwJPqaof91uV1sFWwJuAXWj+HL8JfAv41kCGW2lg2m6sj+e65jqnAh+uqt/1V1WnLpiF15B14RDBZSTJT4Ddquq3Y8c3Bk6uqjv0U1l3kqyuqp3W9pyWlyRfBh431+ghyROAPwPOAl7um53pkeQrLL5Wyz5LWc8kJFkFvJBmWOv+wNOq6mH9VqV11b5p3Z1mGOt92q+LqmrXXguTRiTZFTiW5oOAubs896T5IP2Aqjq1r9q6kuQ7VbVn33UsR97BWl5qPFy1B69Icm0fBU3Al5K8CnhJ2xBhrvPcK4CZaB4wEJvTdNebmzt4FPBM4O40dwoe01dhWmvPn+fYnjQNBQYxRBBYr6q+2G4f0w7D1vTaGNiMpkHJLYBf0NzRkpaTtwJ/PfLcA0CSBwNvA+ZdImPKPGOexep/b5YX/zZgLS/nJtlnfAXzJA8CftlTTV17HvAvwOokJ7XHdqOZB3JIX0Vpra03cpfqL4Cj2zU/Pj7y56opMNpYJskDgb8FNgKePt6MZoqNdg68wX5VfaKHmrSWkhxNM9TqEuC7NMMD31hVF/ZamDS/rcbDFUBVfWkoa30Br1/k3Ewv/m3AWl6eBXw6yTe4/ro7ewEH9FZVh6rqMuCgdm7Z78ckz80509TYIMkG7Xoe+wCHjp7rqSatoyQPo1mr5XfAq6rqKz2X1LWvAY9cYL8AA9Z02Ba4KfAz4FzgHOCiPguSFrFekpuOz7dKshHDeZ18UVV9u+8iliPnYC0z7T+8x3Fd+DgN+NB8QwenUZKDq+qD7fZeVfXNkXOHVdXb+qtOa6ptyPJw4HyaNz33aJcX2Al4f1Xt1WuBWmNJTgBW0CyCeYMXylka4pHkiU7YXt7aIeV3ppl/dV+aNep+A3y7ql7WZ23SqCQvoRlu/Yy55l5JtgfeAqyqqlf2WF4nXGh4YQasKZBkPeCgqvpQ37X8oUb/MY7/w/Qf6nRJsidwW+AL7Z1JktwB2GSW3pRPuyRfZfG1WmZmiIfPQdMjydY0ozvuCzwCuFVVbd5rUdKYJIfRzGe9WXvoMuD1VTWIIYJJTqyqlX3XsRwZsJaRJJsBz6BpRftp4Evt/vNpughO/TDB0X+M4/8w/YcqLV9JHjLffIIh8TloeUvyLK67c3UVbYv29uuHVTWUZlAamCSbAlTVJX3X0qUkF9F0Z51XVe2/dNUsL0MZAzoUHwAupBmmcwjwYppPk/+0qk7qsa4u1QLb8+1LWj5eAww6YOFz0HK3PXAM8JyqGkrjJw1UO8rjnYysvwcMbf2984A39F3EcuQdrGUkyQ+r6q7t9vo0nQO3Hcr8K4AklwOraYLj7dtt2v0dq+rmfdUmaWGzcHdnFh6jpKUxC+vv+Zy5MO9gLS9XzW1U1TVJzhlSuGrdqe8CJK2TWfg07ps3fokkrZFZWH/vzL4LWK4MWMvLbkku5rpJ5huP7FdVbdZfad2Y66Qzbq6RBzDveUn6Q7SjAm5ZVee3+xsCT6IZbnYngKo6rL8KJQ3MLKy/9525jSSPrapjRvZfXVUv6qes/jlEUEtqrJHHsTRzOg6jWYB4EI08pCFK8omqevSNX7n8JDmQZi7EZTRrKL0KeA9wAvB3dr2U1LUk713kdFXVU5asmAmxM/TCDFjLSLsG1tOBnYBTgPe0C7kORpJPc10jj32AW9PcoTt8QI08pKmR5Iiqem27PchPIJP8iKZZ0Ook96B5/nlMVX2m59IkaWrZGXph6/VdgK7n/cDuNN1mHs4wO7PsWFVPqqp30gwJ3BV4mOFK6s2BI9vjcwT2XcpCJujKqloNv184+WeGK0mTlOSRSbYb2X9pkpOTHJtkhz5r65CdoRfgHKzlZdeRLoLvBr7Xcz2TMAuNPKRpkgW259ufVrdO8tyR/c1H96vqjT3UJGnYXgXsCZDkEcDBNB8srwT+GRhCR8HR3gFzfQNo9zfqr6z+GbCWl9HwcXUylPc21zP4Rh7SlJmFTyDfBWy6yL4kda2q6vJ2+9HAu6vq+8D3k/y/HuvqTFWt33cNy5VzsJaRJNfQTMKG9tMA4HIMH5ImZOR5Z/Q5h3Z/o6q6SV+1SdK0SnIKcF+a59QzgT+rqlXtudOqatc+6+vCLPQOWFfOwVpGqmr9qtqs/dq0qjYY2R5EuEqyUZJnJ3lbkkOTeBdV6tHI887oc87c/iDCVZKPjWy/ZuzcF5a+Ikkz4E3AScAq4Mcj4Wol8Mv+yurULPQOWCfewdKSSvJvNEMh/wvYDzirqg7vtyppdiW5GXBVVV3V7t+R5oXy51X1yV6L68hYp6vxVsIz3elK0uQk2YqmW/LJVXVte+y2wE2q6n96La4DSX440jtgA+B7s9yafZR3sLTUdq2qg9sugo8B7t93QdKM+w9ge4AkO9G0MN8ROCzJUT3W1aXFPkn0U0ZJnUtycFWdW1UnAveZO15VvwT276+yTl2vd0CfhSw3BiwtNf8xSsvLLavqZ+32E4GPVNUzae4w/0l/ZXXqZklWJrknTWOdlUnuMbffd3GSBmm0c+lbx85N/SLDrd2SXNx+XQLcbW57pKPgTHL+i5babrl+G0+7CEr9Gr2D8yDgdQBVdWWSa/spqXO/At44z/bcviR1bfBLYNhFcGEGLC0p/zFKy84pSV4PnEvTCeoLAEk277OoLlXV3n3XIGnmzMISGFqATS4kaYYl2Rg4HLgtTYvdk9vj9wVuX1Uf6LO+LiR59GLnq+oTS1WLpNmQ5HJgNc3dqtu327T7O1bVzfuqTZPnHSxJmmFVdQUwXzOLs4G9lricSXnk2PZnRvYLMGBJ6tqd+i5A/TFgSZIASLICeCxwEHA7YBBt2qvqyXPbbVv2Jy92vST9oarqrPmOJ1mP5jl23vMaBrsIStIMS7JpkicmOR74Hs1Qlh2q6vZV9fyey5sEx8VLmrgkmyV5YZK3JXloGs8EzgD+vO/6NFnOwZKkGZbkCppg9RLgG1VVSc6oqh17Lm0ixhcalqRJSPJp4EKatQX3oVlwOMDhVXVSj6VpCRiwJGmGJXk2cCBwc+AjwL8BXxxSwEryGa67c/UA4Ouj56tqKIt+Slomkvywqu7abq8P/BLYtqp+229lWgoGLEkSSXakCVoHATsDLwU+VVU/7bWwDiR54GLnq+prS1WLpNkwfrfcu+ezxYAlSTMsyU7AbarqmyPH7gq8GXjgENauS/K+qnpS33VImh1JrgEum9sFNgYub7erqjbrqzZNnk0uJGm2vQm4ePRAVf0QeDbw+R7qmYS79V2ApNlSVetX1Wbt16ZVtcHItuFq4GzTLkmz7TZtoLqeqjolyXZ9FDQBN0uykuaT4xuoqh8scT2SpAEzYEnSbNt8kXMbL1URE7YV8AbmD1gFPGhpy5EkDZkBS5Jm26okh1TVu0YPJnka8P2eaura6qoyREmSloRNLiRphiW5DfBJ4EquC1S7AxsCj6qqX/VVW1eSnFhVK5NsBOzUHl5tu2RJ0iQYsCRJJPlj4C7t7qlV9eU+6+lSkofSLPT5VOAsmqGC2wDvBV5cVVf1WJ4kaWAMWJKkQUvyJmAT4DlVdUl7bDPg9cAVVXV4j+VJkgbGgCVJGrQkPwPuUGMveEnWB06vqp37qUySNESugyVJGroaD1ftwWtoughKktQZA5YkaehOS/KE8YNJDgZO76EeSdKAOURQkjRoSbYCPgFcwfU7JW5M0ynx3L5qkyQNjwFLkjQTkjwIuHO7e1pV/Wef9UiShsmAJUmSJEkdcQ6WJEmSJHXEgCVJkiRJHTFgSZKmUpJL1+Lalyd5/qR+viRJcwxYkiRJktQRA5YkaTCSPDLJd5OcmORLSW4zcnq3JN9O8rMkh4x8z98kOSHJKUleMc/PvG2Sryc5KcmPktx/SR6MJGkqGbAkSUPyDWDPqloJfBQ4YuTc3YAHAfcBXprkdkkeCuwM7AHcHbhnkgeM/czHAcdX1d2B3YCTJvkAJEnTbYO+C5AkqUNbA/+W5LbAhsCZI+c+XVVXAFck+QpNqLof8FDgxPaaTWgC19dHvu8E4D1JbgJ8qqpOmuxDkCRNM+9gSZKG5K3A26rqrsBfARuNnBtf+LGAAP9QVXdvv3aqqndf76KqrwMPAM4F3pfkCZMrX5I07QxYkqQhuQVNEAJ44ti5A5JslORWwN40d6aOB56SZBOAJFslufXoNyXZDvjfqnoX8C/APSZYvyRpyjlEUJI0rW6W5JyR/TcCLweOSXIh8GVgh5HzpwBfAbYE/q6qfgH8IsmdgG8nAbgUOBj49cj37Q38TZKr2vPewZIkLShV4yMmJEmSJEnrwiGCkiRJktQRA5YkSZIkdcSAJUmSJEkdMWBJkiRJUkcMWJIkSZLUEQOWJEmSJHXEgCVJkiRJHfn/MrHEHXSP9xQAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 864x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(\"For GLoVe: \")\n",
    "plot_labelwise_f1_scores(labels_to_index_bilstmcrf_glove, test_preds_bilstmcrf_glove_task1, test_true_bilstmcrf_glove_task1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For Fasttext: \n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 864x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(\"For Fasttext: \")\n",
    "plot_labelwise_f1_scores(labels_to_index_bilstmcrf_fasttext, test_preds_bilstmcrf_fasttext_task1, test_true_bilstmcrf_fasttext_task1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Delete the models and the dataloaders\n",
    "del model_fasttext_bilstmcrf_task1\n",
    "del model_glove_bilstmcrf_task1\n",
    "del model_word2vec_bilstmcrf_task1\n",
    "\n",
    "del test_dataloader_fasttext_bilstmcrf\n",
    "del test_dataloader_glove_bilstmcrf\n",
    "del test_dataloader_word2vec_bilstmcrf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 2 - ATE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Loading the Pickle Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to load the data from the json file\n",
    "def load_from_json(file_path):\n",
    "    with open(file_path, \"r\") as file:\n",
    "        data = json.load(file)\n",
    "    return data\n",
    "\n",
    "\"\"\"\n",
    "Task 2 - Embeddings\n",
    "\"\"\"\n",
    "fasttext_task2 = \"Task2_Fasttext_test_embeddings.pkl\"\n",
    "glove_task2 = \"Task2_GLoVe_test_embeddings.pkl\"\n",
    "word2vec_task2 = \"Task2_Word2Vec_test_embeddings.pkl\"\n",
    "\n",
    "# Load the embeddings\n",
    "fasttext_embeddings_task2 = pickle.load(open(fasttext_task2, \"rb\"))\n",
    "glove_embeddings_task2 = pickle.load(open(glove_task2, \"rb\"))\n",
    "word2vec_embeddings_task2 = pickle.load(open(word2vec_task2, \"rb\"))\n",
    "\n",
    "# Load the test labels\n",
    "test_label_path = \"ATE_test_labels.json\"\n",
    "test_labels_task2 = load_from_json(test_label_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Padding the Sequences to the Same Length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(83, 1), (83, 300), (83, 300), (83, 300)\n",
      "(83, 1), (83, 300), (83, 300), (83, 300)\n",
      "(83, 1), (83, 300), (83, 300), (83, 300)\n",
      "(83, 1), (83, 300), (83, 300), (83, 300)\n",
      "(83, 1), (83, 300), (83, 300), (83, 300)\n",
      "(83, 1), (83, 300), (83, 300), (83, 300)\n",
      "(83, 1), (83, 300), (83, 300), (83, 300)\n",
      "(83, 1), (83, 300), (83, 300), (83, 300)\n",
      "(83, 1), (83, 300), (83, 300), (83, 300)\n",
      "(83, 1), (83, 300), (83, 300), (83, 300)\n",
      "(83, 1), (83, 300), (83, 300), (83, 300)\n",
      "(83, 1), (83, 300), (83, 300), (83, 300)\n",
      "(83, 1), (83, 300), (83, 300), (83, 300)\n",
      "(83, 1), (83, 300), (83, 300), (83, 300)\n",
      "(83, 1), (83, 300), (83, 300), (83, 300)\n",
      "(83, 1), (83, 300), (83, 300), (83, 300)\n",
      "(83, 1), (83, 300), (83, 300), (83, 300)\n",
      "(83, 1), (83, 300), (83, 300), (83, 300)\n",
      "(83, 1), (83, 300), (83, 300), (83, 300)\n",
      "(83, 1), (83, 300), (83, 300), (83, 300)\n",
      "(83, 1), (83, 300), (83, 300), (83, 300)\n",
      "(83, 1), (83, 300), (83, 300), (83, 300)\n",
      "(83, 1), (83, 300), (83, 300), (83, 300)\n",
      "(83, 1), (83, 300), (83, 300), (83, 300)\n",
      "(83, 1), (83, 300), (83, 300), (83, 300)\n",
      "(83, 1), (83, 300), (83, 300), (83, 300)\n",
      "(83, 1), (83, 300), (83, 300), (83, 300)\n",
      "(83, 1), (83, 300), (83, 300), (83, 300)\n",
      "(83, 1), (83, 300), (83, 300), (83, 300)\n",
      "(83, 1), (83, 300), (83, 300), (83, 300)\n",
      "(83, 1), (83, 300), (83, 300), (83, 300)\n",
      "(83, 1), (83, 300), (83, 300), (83, 300)\n",
      "(83, 1), (83, 300), (83, 300), (83, 300)\n",
      "(83, 1), (83, 300), (83, 300), (83, 300)\n",
      "(83, 1), (83, 300), (83, 300), (83, 300)\n",
      "(83, 1), (83, 300), (83, 300), (83, 300)\n",
      "(83, 1), (83, 300), (83, 300), (83, 300)\n",
      "(83, 1), (83, 300), (83, 300), (83, 300)\n",
      "(83, 1), (83, 300), (83, 300), (83, 300)\n",
      "(83, 1), (83, 300), (83, 300), (83, 300)\n",
      "(83, 1), (83, 300), (83, 300), (83, 300)\n",
      "(83, 1), (83, 300), (83, 300), (83, 300)\n",
      "(83, 1), (83, 300), (83, 300), (83, 300)\n",
      "(83, 1), (83, 300), (83, 300), (83, 300)\n",
      "(83, 1), (83, 300), (83, 300), (83, 300)\n",
      "(83, 1), (83, 300), (83, 300), (83, 300)\n",
      "(83, 1), (83, 300), (83, 300), (83, 300)\n",
      "(83, 1), (83, 300), (83, 300), (83, 300)\n",
      "(83, 1), (83, 300), (83, 300), (83, 300)\n",
      "(83, 1), (83, 300), (83, 300), (83, 300)\n",
      "(83, 1), (83, 300), (83, 300), (83, 300)\n",
      "(83, 1), (83, 300), (83, 300), (83, 300)\n",
      "(83, 1), (83, 300), (83, 300), (83, 300)\n",
      "(83, 1), (83, 300), (83, 300), (83, 300)\n",
      "(83, 1), (83, 300), (83, 300), (83, 300)\n",
      "(83, 1), (83, 300), (83, 300), (83, 300)\n",
      "(83, 1), (83, 300), (83, 300), (83, 300)\n",
      "(83, 1), (83, 300), (83, 300), (83, 300)\n",
      "(83, 1), (83, 300), (83, 300), (83, 300)\n",
      "(83, 1), (83, 300), (83, 300), (83, 300)\n",
      "(83, 1), (83, 300), (83, 300), (83, 300)\n",
      "(83, 1), (83, 300), (83, 300), (83, 300)\n",
      "(83, 1), (83, 300), (83, 300), (83, 300)\n",
      "(83, 1), (83, 300), (83, 300), (83, 300)\n",
      "(83, 1), (83, 300), (83, 300), (83, 300)\n",
      "(83, 1), (83, 300), (83, 300), (83, 300)\n",
      "(83, 1), (83, 300), (83, 300), (83, 300)\n",
      "(83, 1), (83, 300), (83, 300), (83, 300)\n",
      "(83, 1), (83, 300), (83, 300), (83, 300)\n",
      "(83, 1), (83, 300), (83, 300), (83, 300)\n",
      "(83, 1), (83, 300), (83, 300), (83, 300)\n",
      "(83, 1), (83, 300), (83, 300), (83, 300)\n",
      "(83, 1), (83, 300), (83, 300), (83, 300)\n",
      "(83, 1), (83, 300), (83, 300), (83, 300)\n",
      "(83, 1), (83, 300), (83, 300), (83, 300)\n",
      "(83, 1), (83, 300), (83, 300), (83, 300)\n",
      "(83, 1), (83, 300), (83, 300), (83, 300)\n",
      "(83, 1), (83, 300), (83, 300), (83, 300)\n",
      "(83, 1), (83, 300), (83, 300), (83, 300)\n",
      "(83, 1), (83, 300), (83, 300), (83, 300)\n",
      "(83, 1), (83, 300), (83, 300), (83, 300)\n",
      "(83, 1), (83, 300), (83, 300), (83, 300)\n",
      "(83, 1), (83, 300), (83, 300), (83, 300)\n",
      "(83, 1), (83, 300), (83, 300), (83, 300)\n",
      "(83, 1), (83, 300), (83, 300), (83, 300)\n",
      "(83, 1), (83, 300), (83, 300), (83, 300)\n",
      "(83, 1), (83, 300), (83, 300), (83, 300)\n",
      "(83, 1), (83, 300), (83, 300), (83, 300)\n",
      "(83, 1), (83, 300), (83, 300), (83, 300)\n",
      "(83, 1), (83, 300), (83, 300), (83, 300)\n",
      "(83, 1), (83, 300), (83, 300), (83, 300)\n",
      "(83, 1), (83, 300), (83, 300), (83, 300)\n",
      "(83, 1), (83, 300), (83, 300), (83, 300)\n",
      "(83, 1), (83, 300), (83, 300), (83, 300)\n",
      "(83, 1), (83, 300), (83, 300), (83, 300)\n",
      "(83, 1), (83, 300), (83, 300), (83, 300)\n",
      "(83, 1), (83, 300), (83, 300), (83, 300)\n",
      "(83, 1), (83, 300), (83, 300), (83, 300)\n",
      "(83, 1), (83, 300), (83, 300), (83, 300)\n",
      "(83, 1), (83, 300), (83, 300), (83, 300)\n",
      "(83, 1), (83, 300), (83, 300), (83, 300)\n",
      "(83, 1), (83, 300), (83, 300), (83, 300)\n",
      "(83, 1), (83, 300), (83, 300), (83, 300)\n",
      "(83, 1), (83, 300), (83, 300), (83, 300)\n",
      "(83, 1), (83, 300), (83, 300), (83, 300)\n",
      "(83, 1), (83, 300), (83, 300), (83, 300)\n",
      "(83, 1), (83, 300), (83, 300), (83, 300)\n",
      "(83, 1), (83, 300), (83, 300), (83, 300)\n",
      "(83, 1), (83, 300), (83, 300), (83, 300)\n",
      "(83, 1), (83, 300), (83, 300), (83, 300)\n",
      "(83, 1), (83, 300), (83, 300), (83, 300)\n",
      "(83, 1), (83, 300), (83, 300), (83, 300)\n",
      "(83, 1), (83, 300), (83, 300), (83, 300)\n",
      "(83, 1), (83, 300), (83, 300), (83, 300)\n",
      "(83, 1), (83, 300), (83, 300), (83, 300)\n",
      "(83, 1), (83, 300), (83, 300), (83, 300)\n",
      "(83, 1), (83, 300), (83, 300), (83, 300)\n",
      "(83, 1), (83, 300), (83, 300), (83, 300)\n",
      "(83, 1), (83, 300), (83, 300), (83, 300)\n",
      "(83, 1), (83, 300), (83, 300), (83, 300)\n",
      "(83, 1), (83, 300), (83, 300), (83, 300)\n",
      "(83, 1), (83, 300), (83, 300), (83, 300)\n",
      "(83, 1), (83, 300), (83, 300), (83, 300)\n",
      "(83, 1), (83, 300), (83, 300), (83, 300)\n",
      "(83, 1), (83, 300), (83, 300), (83, 300)\n",
      "(83, 1), (83, 300), (83, 300), (83, 300)\n",
      "(83, 1), (83, 300), (83, 300), (83, 300)\n",
      "(83, 1), (83, 300), (83, 300), (83, 300)\n",
      "(83, 1), (83, 300), (83, 300), (83, 300)\n",
      "(83, 1), (83, 300), (83, 300), (83, 300)\n",
      "(83, 1), (83, 300), (83, 300), (83, 300)\n",
      "(83, 1), (83, 300), (83, 300), (83, 300)\n",
      "(83, 1), (83, 300), (83, 300), (83, 300)\n",
      "(83, 1), (83, 300), (83, 300), (83, 300)\n",
      "(83, 1), (83, 300), (83, 300), (83, 300)\n",
      "(83, 1), (83, 300), (83, 300), (83, 300)\n",
      "(83, 1), (83, 300), (83, 300), (83, 300)\n",
      "(83, 1), (83, 300), (83, 300), (83, 300)\n",
      "(83, 1), (83, 300), (83, 300), (83, 300)\n",
      "(83, 1), (83, 300), (83, 300), (83, 300)\n",
      "(83, 1), (83, 300), (83, 300), (83, 300)\n",
      "(83, 1), (83, 300), (83, 300), (83, 300)\n",
      "(83, 1), (83, 300), (83, 300), (83, 300)\n",
      "(83, 1), (83, 300), (83, 300), (83, 300)\n",
      "(83, 1), (83, 300), (83, 300), (83, 300)\n",
      "(83, 1), (83, 300), (83, 300), (83, 300)\n",
      "(83, 1), (83, 300), (83, 300), (83, 300)\n",
      "(83, 1), (83, 300), (83, 300), (83, 300)\n",
      "(83, 1), (83, 300), (83, 300), (83, 300)\n",
      "(83, 1), (83, 300), (83, 300), (83, 300)\n",
      "(83, 1), (83, 300), (83, 300), (83, 300)\n",
      "(83, 1), (83, 300), (83, 300), (83, 300)\n",
      "(83, 1), (83, 300), (83, 300), (83, 300)\n",
      "(83, 1), (83, 300), (83, 300), (83, 300)\n",
      "(83, 1), (83, 300), (83, 300), (83, 300)\n",
      "(83, 1), (83, 300), (83, 300), (83, 300)\n",
      "(83, 1), (83, 300), (83, 300), (83, 300)\n",
      "(83, 1), (83, 300), (83, 300), (83, 300)\n",
      "(83, 1), (83, 300), (83, 300), (83, 300)\n",
      "(83, 1), (83, 300), (83, 300), (83, 300)\n",
      "(83, 1), (83, 300), (83, 300), (83, 300)\n",
      "(83, 1), (83, 300), (83, 300), (83, 300)\n",
      "(83, 1), (83, 300), (83, 300), (83, 300)\n",
      "(83, 1), (83, 300), (83, 300), (83, 300)\n",
      "(83, 1), (83, 300), (83, 300), (83, 300)\n",
      "(83, 1), (83, 300), (83, 300), (83, 300)\n",
      "(83, 1), (83, 300), (83, 300), (83, 300)\n",
      "(83, 1), (83, 300), (83, 300), (83, 300)\n",
      "(83, 1), (83, 300), (83, 300), (83, 300)\n",
      "(83, 1), (83, 300), (83, 300), (83, 300)\n",
      "(83, 1), (83, 300), (83, 300), (83, 300)\n",
      "(83, 1), (83, 300), (83, 300), (83, 300)\n",
      "(83, 1), (83, 300), (83, 300), (83, 300)\n",
      "(83, 1), (83, 300), (83, 300), (83, 300)\n",
      "(83, 1), (83, 300), (83, 300), (83, 300)\n",
      "(83, 1), (83, 300), (83, 300), (83, 300)\n",
      "(83, 1), (83, 300), (83, 300), (83, 300)\n",
      "(83, 1), (83, 300), (83, 300), (83, 300)\n",
      "(83, 1), (83, 300), (83, 300), (83, 300)\n",
      "(83, 1), (83, 300), (83, 300), (83, 300)\n",
      "(83, 1), (83, 300), (83, 300), (83, 300)\n",
      "(83, 1), (83, 300), (83, 300), (83, 300)\n",
      "(83, 1), (83, 300), (83, 300), (83, 300)\n",
      "(83, 1), (83, 300), (83, 300), (83, 300)\n",
      "(83, 1), (83, 300), (83, 300), (83, 300)\n",
      "(83, 1), (83, 300), (83, 300), (83, 300)\n",
      "(83, 1), (83, 300), (83, 300), (83, 300)\n",
      "(83, 1), (83, 300), (83, 300), (83, 300)\n",
      "(83, 1), (83, 300), (83, 300), (83, 300)\n",
      "(83, 1), (83, 300), (83, 300), (83, 300)\n",
      "(83, 1), (83, 300), (83, 300), (83, 300)\n",
      "(83, 1), (83, 300), (83, 300), (83, 300)\n",
      "(83, 1), (83, 300), (83, 300), (83, 300)\n",
      "(83, 1), (83, 300), (83, 300), (83, 300)\n",
      "(83, 1), (83, 300), (83, 300), (83, 300)\n",
      "(83, 1), (83, 300), (83, 300), (83, 300)\n",
      "(83, 1), (83, 300), (83, 300), (83, 300)\n",
      "(83, 1), (83, 300), (83, 300), (83, 300)\n",
      "(83, 1), (83, 300), (83, 300), (83, 300)\n",
      "(83, 1), (83, 300), (83, 300), (83, 300)\n",
      "(83, 1), (83, 300), (83, 300), (83, 300)\n",
      "(83, 1), (83, 300), (83, 300), (83, 300)\n",
      "(83, 1), (83, 300), (83, 300), (83, 300)\n",
      "(83, 1), (83, 300), (83, 300), (83, 300)\n",
      "(83, 1), (83, 300), (83, 300), (83, 300)\n",
      "(83, 1), (83, 300), (83, 300), (83, 300)\n",
      "(83, 1), (83, 300), (83, 300), (83, 300)\n",
      "(83, 1), (83, 300), (83, 300), (83, 300)\n",
      "(83, 1), (83, 300), (83, 300), (83, 300)\n",
      "(83, 1), (83, 300), (83, 300), (83, 300)\n",
      "(83, 1), (83, 300), (83, 300), (83, 300)\n",
      "(83, 1), (83, 300), (83, 300), (83, 300)\n",
      "(83, 1), (83, 300), (83, 300), (83, 300)\n",
      "(83, 1), (83, 300), (83, 300), (83, 300)\n",
      "(83, 1), (83, 300), (83, 300), (83, 300)\n",
      "(83, 1), (83, 300), (83, 300), (83, 300)\n",
      "(83, 1), (83, 300), (83, 300), (83, 300)\n",
      "(83, 1), (83, 300), (83, 300), (83, 300)\n",
      "(83, 1), (83, 300), (83, 300), (83, 300)\n",
      "(83, 1), (83, 300), (83, 300), (83, 300)\n",
      "(83, 1), (83, 300), (83, 300), (83, 300)\n",
      "(83, 1), (83, 300), (83, 300), (83, 300)\n",
      "(83, 1), (83, 300), (83, 300), (83, 300)\n",
      "(83, 1), (83, 300), (83, 300), (83, 300)\n",
      "(83, 1), (83, 300), (83, 300), (83, 300)\n",
      "(83, 1), (83, 300), (83, 300), (83, 300)\n",
      "(83, 1), (83, 300), (83, 300), (83, 300)\n",
      "(83, 1), (83, 300), (83, 300), (83, 300)\n",
      "(83, 1), (83, 300), (83, 300), (83, 300)\n",
      "(83, 1), (83, 300), (83, 300), (83, 300)\n",
      "(83, 1), (83, 300), (83, 300), (83, 300)\n",
      "(83, 1), (83, 300), (83, 300), (83, 300)\n",
      "(83, 1), (83, 300), (83, 300), (83, 300)\n",
      "(83, 1), (83, 300), (83, 300), (83, 300)\n",
      "(83, 1), (83, 300), (83, 300), (83, 300)\n",
      "(83, 1), (83, 300), (83, 300), (83, 300)\n",
      "(83, 1), (83, 300), (83, 300), (83, 300)\n",
      "(83, 1), (83, 300), (83, 300), (83, 300)\n",
      "(83, 1), (83, 300), (83, 300), (83, 300)\n",
      "(83, 1), (83, 300), (83, 300), (83, 300)\n",
      "(83, 1), (83, 300), (83, 300), (83, 300)\n",
      "(83, 1), (83, 300), (83, 300), (83, 300)\n",
      "(83, 1), (83, 300), (83, 300), (83, 300)\n",
      "(83, 1), (83, 300), (83, 300), (83, 300)\n",
      "(83, 1), (83, 300), (83, 300), (83, 300)\n",
      "(83, 1), (83, 300), (83, 300), (83, 300)\n",
      "(83, 1), (83, 300), (83, 300), (83, 300)\n",
      "(83, 1), (83, 300), (83, 300), (83, 300)\n",
      "(83, 1), (83, 300), (83, 300), (83, 300)\n",
      "(83, 1), (83, 300), (83, 300), (83, 300)\n",
      "(83, 1), (83, 300), (83, 300), (83, 300)\n",
      "(83, 1), (83, 300), (83, 300), (83, 300)\n",
      "(83, 1), (83, 300), (83, 300), (83, 300)\n",
      "(83, 1), (83, 300), (83, 300), (83, 300)\n",
      "(83, 1), (83, 300), (83, 300), (83, 300)\n",
      "(83, 1), (83, 300), (83, 300), (83, 300)\n",
      "(83, 1), (83, 300), (83, 300), (83, 300)\n",
      "(83, 1), (83, 300), (83, 300), (83, 300)\n",
      "(83, 1), (83, 300), (83, 300), (83, 300)\n",
      "(83, 1), (83, 300), (83, 300), (83, 300)\n",
      "(83, 1), (83, 300), (83, 300), (83, 300)\n",
      "(83, 1), (83, 300), (83, 300), (83, 300)\n",
      "(83, 1), (83, 300), (83, 300), (83, 300)\n",
      "(83, 1), (83, 300), (83, 300), (83, 300)\n",
      "(83, 1), (83, 300), (83, 300), (83, 300)\n",
      "(83, 1), (83, 300), (83, 300), (83, 300)\n",
      "(83, 1), (83, 300), (83, 300), (83, 300)\n",
      "(83, 1), (83, 300), (83, 300), (83, 300)\n",
      "(83, 1), (83, 300), (83, 300), (83, 300)\n",
      "(83, 1), (83, 300), (83, 300), (83, 300)\n",
      "(83, 1), (83, 300), (83, 300), (83, 300)\n",
      "(83, 1), (83, 300), (83, 300), (83, 300)\n",
      "(83, 1), (83, 300), (83, 300), (83, 300)\n",
      "(83, 1), (83, 300), (83, 300), (83, 300)\n",
      "(83, 1), (83, 300), (83, 300), (83, 300)\n",
      "(83, 1), (83, 300), (83, 300), (83, 300)\n",
      "(83, 1), (83, 300), (83, 300), (83, 300)\n",
      "(83, 1), (83, 300), (83, 300), (83, 300)\n",
      "(83, 1), (83, 300), (83, 300), (83, 300)\n",
      "(83, 1), (83, 300), (83, 300), (83, 300)\n",
      "(83, 1), (83, 300), (83, 300), (83, 300)\n",
      "(83, 1), (83, 300), (83, 300), (83, 300)\n",
      "(83, 1), (83, 300), (83, 300), (83, 300)\n",
      "(83, 1), (83, 300), (83, 300), (83, 300)\n",
      "(83, 1), (83, 300), (83, 300), (83, 300)\n",
      "(83, 1), (83, 300), (83, 300), (83, 300)\n",
      "(83, 1), (83, 300), (83, 300), (83, 300)\n",
      "(83, 1), (83, 300), (83, 300), (83, 300)\n",
      "(83, 1), (83, 300), (83, 300), (83, 300)\n",
      "(83, 1), (83, 300), (83, 300), (83, 300)\n",
      "(83, 1), (83, 300), (83, 300), (83, 300)\n",
      "(83, 1), (83, 300), (83, 300), (83, 300)\n",
      "(83, 1), (83, 300), (83, 300), (83, 300)\n",
      "(83, 1), (83, 300), (83, 300), (83, 300)\n",
      "(83, 1), (83, 300), (83, 300), (83, 300)\n",
      "(83, 1), (83, 300), (83, 300), (83, 300)\n",
      "(83, 1), (83, 300), (83, 300), (83, 300)\n",
      "(83, 1), (83, 300), (83, 300), (83, 300)\n",
      "(83, 1), (83, 300), (83, 300), (83, 300)\n",
      "(83, 1), (83, 300), (83, 300), (83, 300)\n",
      "(83, 1), (83, 300), (83, 300), (83, 300)\n",
      "(83, 1), (83, 300), (83, 300), (83, 300)\n",
      "(83, 1), (83, 300), (83, 300), (83, 300)\n",
      "(83, 1), (83, 300), (83, 300), (83, 300)\n",
      "(83, 1), (83, 300), (83, 300), (83, 300)\n",
      "(83, 1), (83, 300), (83, 300), (83, 300)\n",
      "(83, 1), (83, 300), (83, 300), (83, 300)\n",
      "(83, 1), (83, 300), (83, 300), (83, 300)\n",
      "(83, 1), (83, 300), (83, 300), (83, 300)\n",
      "(83, 1), (83, 300), (83, 300), (83, 300)\n",
      "(83, 1), (83, 300), (83, 300), (83, 300)\n",
      "(83, 1), (83, 300), (83, 300), (83, 300)\n",
      "(83, 1), (83, 300), (83, 300), (83, 300)\n",
      "(83, 1), (83, 300), (83, 300), (83, 300)\n",
      "(83, 1), (83, 300), (83, 300), (83, 300)\n",
      "(83, 1), (83, 300), (83, 300), (83, 300)\n",
      "(83, 1), (83, 300), (83, 300), (83, 300)\n",
      "(83, 1), (83, 300), (83, 300), (83, 300)\n",
      "(83, 1), (83, 300), (83, 300), (83, 300)\n",
      "(83, 1), (83, 300), (83, 300), (83, 300)\n",
      "(83, 1), (83, 300), (83, 300), (83, 300)\n",
      "(83, 1), (83, 300), (83, 300), (83, 300)\n",
      "(83, 1), (83, 300), (83, 300), (83, 300)\n",
      "(83, 1), (83, 300), (83, 300), (83, 300)\n",
      "(83, 1), (83, 300), (83, 300), (83, 300)\n",
      "(83, 1), (83, 300), (83, 300), (83, 300)\n",
      "(83, 1), (83, 300), (83, 300), (83, 300)\n",
      "(83, 1), (83, 300), (83, 300), (83, 300)\n"
     ]
    }
   ],
   "source": [
    "max_length = 83\n",
    "\n",
    "# Padding the embeddings\n",
    "for key in fasttext_embeddings_task2:\n",
    "    label = test_labels_task2[key]\n",
    "    embeddings_fasttext = fasttext_embeddings_task2[key]\n",
    "    embeddings_glove = glove_embeddings_task2[key]\n",
    "    embeddings_word2vec = word2vec_embeddings_task2[key]\n",
    "\n",
    "    # Pad the labels\n",
    "    if len(label) < max_length:\n",
    "        label = label + ['O'] * (max_length - len(label))\n",
    "\n",
    "    # Pad the embeddings\n",
    "    if len(embeddings_fasttext) < max_length:\n",
    "        embeddings_fasttext = np.concatenate((embeddings_fasttext, np.zeros((max_length - len(embeddings_fasttext), 300))), axis=0)\n",
    "        embeddings_glove = np.concatenate((embeddings_glove, np.zeros((max_length - len(embeddings_glove), 300))), axis=0)\n",
    "        embeddings_word2vec = np.concatenate((embeddings_word2vec, np.zeros((max_length - len(embeddings_word2vec), 300))), axis=0)\n",
    "\n",
    "    # Update the 4 dictionaries\n",
    "    fasttext_embeddings_task2[key] = embeddings_fasttext\n",
    "    glove_embeddings_task2[key] = embeddings_glove\n",
    "    word2vec_embeddings_task2[key] = embeddings_word2vec\n",
    "    test_labels_task2[key] = label\n",
    "\n",
    "# Iterate through the embeddings to check the shape of the data\n",
    "for key in test_labels_task2:\n",
    "        print(f\"({len(test_labels_task2[key])}, {len(test_labels_task2[key][0])}), ({len(fasttext_embeddings_task2[key])}, {len(fasttext_embeddings_task2[key][0])}), ({len(glove_embeddings_task2[key])}, {len(glove_embeddings_task2[key][0])}), ({len(word2vec_embeddings_task2[key])}, {len(word2vec_embeddings_task2[key][0])})\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the embeddings to tensor\n",
    "embeddings_fasttext_task2 = torch.tensor([fasttext_embeddings_task2[key] for key in fasttext_embeddings_task2], dtype=torch.float)\n",
    "embeddings_glove_task2 = torch.tensor([glove_embeddings_task2[key] for key in glove_embeddings_task2], dtype=torch.float)\n",
    "embeddings_word2vec_task2 = torch.tensor([word2vec_embeddings_task2[key] for key in word2vec_embeddings_task2], dtype=torch.float)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Label to Index for all Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Task 2 - Labels to Index\n",
    "\"\"\"\n",
    "\n",
    "labels_to_index_rnn_fasttext_task2 = {'B': 0, 'I': 1, 'O': 2}\n",
    "labels_to_index_rnn_glove_task2 = {'B': 0, 'I': 1, 'O': 2}\n",
    "labels_to_index_rnn_word2vec_task2 = {'B': 0, 'O': 1, 'I': 2}\n",
    "\n",
    "labels_to_index_lstm_fasttext_task2 =  {'B': 0, 'O': 1, 'I': 2}\n",
    "labels_to_index_lstm_glove_task2 = {'I': 0, 'B': 1, 'O': 2}\n",
    "labels_to_index_lstm_word2vec_task2 = {'O': 0, 'I': 1, 'B': 2}\n",
    "\n",
    "labels_to_index_gru_fasttext_task2 = {'I': 0, 'B': 1, 'O': 2}\n",
    "labels_to_index_gru_glove_task2 = {'I': 0, 'O': 1, 'B': 2}\n",
    "labels_to_index_gru_word2vec_task2 = {'B': 0, 'I': 1, 'O': 2}\n",
    "\n",
    "labels_to_index_bilstmcrf_fasttext_task2 = {'<START>': 0, '<STOP>': 1, 'I': 2, 'O': 3, 'B': 4}\n",
    "labels_to_index_bilstmcrf_glove_task2 = {'O': 0, 'B': 1, '<START>': 2, '<STOP>': 3, 'I': 4}\n",
    "labels_to_index_bilstmcrf_word2vec_task2 = {'I': 0, '<START>': 1, 'B': 2, 'O': 3, '<STOP>': 4}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 83, 300]) torch.Size([32, 83])\n"
     ]
    }
   ],
   "source": [
    "# Convert labels to indices for RNN\n",
    "test_labels_rnn_fasttext_task2 = labels_to_indices(test_labels_task2.values(), labels_to_index_rnn_fasttext_task2)\n",
    "test_labels_rnn_glove_task2 = labels_to_indices(test_labels_task2.values(), labels_to_index_rnn_glove_task2)\n",
    "test_labels_rnn_word2vec_task2 = labels_to_indices(test_labels_task2.values(), labels_to_index_rnn_word2vec_task2)\n",
    "\n",
    "# Convert labels to tensor\n",
    "test_labels_rnn_fasttext_tensor_task2 = torch.tensor(test_labels_rnn_fasttext_task2, dtype=torch.long)\n",
    "test_labels_rnn_glove_tensor_task2 = torch.tensor(test_labels_rnn_glove_task2, dtype=torch.long)\n",
    "test_labels_rnn_word2vec_tensor_task2 = torch.tensor(test_labels_rnn_word2vec_task2, dtype=torch.long)\n",
    "\n",
    "# Dataloaders for RNN\n",
    "test_dataset_fasttext_rnn_task2 = TensorDataset(embeddings_fasttext_task2, test_labels_rnn_fasttext_tensor_task2)\n",
    "test_dataloader_fasttext_rnn_task2 = DataLoader(test_dataset_fasttext_rnn_task2, batch_size=32, shuffle=False)\n",
    "\n",
    "test_dataset_glove_rnn_task2 = TensorDataset(embeddings_glove_task2, test_labels_rnn_glove_tensor_task2)\n",
    "test_dataloader_glove_rnn_task2 = DataLoader(test_dataset_glove_rnn_task2, batch_size=32, shuffle=False)\n",
    "\n",
    "test_dataset_word2vec_rnn_task2 = TensorDataset(embeddings_word2vec_task2, test_labels_rnn_word2vec_tensor_task2)\n",
    "test_dataloader_word2vec_rnn_task2 = DataLoader(test_dataset_word2vec_rnn_task2, batch_size=32, shuffle=False)\n",
    "\n",
    "# Iterate through dataloaders to check the shape of the data\n",
    "for i, (x, y) in enumerate(test_dataloader_fasttext_rnn_task2):\n",
    "    print(x.shape, y.shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 2 - RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNNModel_Task2(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, output_dim, num_layers):\n",
    "        super(RNNModel_Task2, self).__init__()\n",
    "        self.rnn = nn.RNN(input_dim, hidden_dim, num_layers, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_dim, output_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out, _ = self.rnn(x)\n",
    "        out = self.fc(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Task2 - RNN Word2Vec - F1: 0.7390856301123915\n",
      "Task2 - RNN Word2Vec - Accuracy: 0.9851601528063474\n",
      "Task2 - RNN GLoVe - F1: 0.7929509870722535\n",
      "Task2 - RNN GLoVe - Accuracy: 0.9868131060828681\n",
      "Task2 - RNN Fasttext - F1: 0.5638986815562818\n",
      "Task2 - RNN Fasttext - Accuracy: 0.9779973552747576\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Word2Vec\n",
    "\"\"\"\n",
    "\n",
    "model_word2vec_rnn_task2 = RNNModel_Task2(input_dim=300, hidden_dim=256, output_dim=3, num_layers=1)\n",
    "\n",
    "# Load the model\n",
    "model_word2vec_rnn_task2.load_state_dict(torch.load(\"Task2_RNN_Word2Vec_model.pth\"))\n",
    "\n",
    "# Set the model to evaluation mode\n",
    "model_word2vec_rnn_task2.eval()\n",
    "\n",
    "# Evaluation\n",
    "test_preds_rnn_word2vec_task2 = []\n",
    "test_true_rnn_word2vec_task2 = []\n",
    "\n",
    "with torch.no_grad():  # Do not compute gradients\n",
    "    for inputs, labels in test_dataloader_word2vec_rnn_task2:\n",
    "        outputs = model_word2vec_rnn_task2(inputs)\n",
    "        _, predicted = torch.max(outputs.data, 2)  # Get the predicted classes\n",
    "        \n",
    "        test_preds_rnn_word2vec_task2.extend(predicted.view(-1).numpy())  # Flatten and store predictions\n",
    "        test_true_rnn_word2vec_task2.extend(labels.view(-1).numpy())  # Flatten and store true labels\n",
    "\n",
    "# Calculate the F1-score\n",
    "f1_score_rnn_word2vec_task2 = f1_score(test_true_rnn_word2vec_task2, test_preds_rnn_word2vec_task2, average='macro')\n",
    "\n",
    "# Calculate the accuracy\n",
    "accuracy_rnn_word2vec_task2 = accuracy_score(test_true_rnn_word2vec_task2, test_preds_rnn_word2vec_task2)\n",
    "\n",
    "print(f\"Task2 - RNN Word2Vec - F1: {f1_score_rnn_word2vec_task2}\")\n",
    "print(f\"Task2 - RNN Word2Vec - Accuracy: {accuracy_rnn_word2vec_task2}\")\n",
    "\n",
    "\"\"\"\n",
    "GloVe\n",
    "\"\"\"\n",
    "\n",
    "model_glove_rnn_task2 = RNNModel_Task2(input_dim=300, hidden_dim=256, output_dim=3, num_layers=1)\n",
    "\n",
    "# Load the model\n",
    "model_glove_rnn_task2.load_state_dict(torch.load(\"Task2_RNN_GloVe_model.pth\"))\n",
    "\n",
    "# Set the model to evaluation mode\n",
    "model_glove_rnn_task2.eval()\n",
    "\n",
    "# Evaluation\n",
    "test_preds_rnn_glove_task2 = []\n",
    "test_true_rnn_glove_task2 = []\n",
    "\n",
    "with torch.no_grad():  # Do not compute gradients\n",
    "    for inputs, labels in test_dataloader_glove_rnn_task2:\n",
    "        outputs = model_glove_rnn_task2(inputs)\n",
    "        _, predicted = torch.max(outputs.data, 2)  # Get the predicted classes\n",
    "        \n",
    "        test_preds_rnn_glove_task2.extend(predicted.view(-1).numpy())  # Flatten and store predictions\n",
    "        test_true_rnn_glove_task2.extend(labels.view(-1).numpy())  # Flatten and store true labels\n",
    "\n",
    "# Calculate the F1-score\n",
    "f1_score_rnn_glove_task2 = f1_score(test_true_rnn_glove_task2, test_preds_rnn_glove_task2, average='macro')\n",
    "\n",
    "# Calculate the accuracy\n",
    "accuracy_rnn_glove_task2 = accuracy_score(test_true_rnn_glove_task2, test_preds_rnn_glove_task2)\n",
    "\n",
    "print(f\"Task2 - RNN GLoVe - F1: {f1_score_rnn_glove_task2}\")\n",
    "print(f\"Task2 - RNN GLoVe - Accuracy: {accuracy_rnn_glove_task2}\")\n",
    "\n",
    "\"\"\"\n",
    "Fasttext\n",
    "\"\"\"\n",
    "\n",
    "model_fasttext_rnn_task2 = RNNModel_Task2(input_dim=300, hidden_dim=256, output_dim=3, num_layers=1)\n",
    "\n",
    "# Load the model\n",
    "model_fasttext_rnn_task2.load_state_dict(torch.load(\"Task2_RNN_FastText_model.pth\"))\n",
    "\n",
    "# Set the model to evaluation mode\n",
    "model_fasttext_rnn_task2.eval()\n",
    "\n",
    "# Evaluation\n",
    "test_preds_rnn_fasttext_task2 = []\n",
    "test_true_rnn_fasttext_task2 = []\n",
    "\n",
    "with torch.no_grad():  # Do not compute gradients \n",
    "    for inputs, labels in test_dataloader_fasttext_rnn_task2:\n",
    "        outputs = model_fasttext_rnn_task2(inputs)\n",
    "        _, predicted = torch.max(outputs.data, 2)  # Get the predicted classes\n",
    "        \n",
    "        test_preds_rnn_fasttext_task2.extend(predicted.view(-1).numpy())  # Flatten and store predictions\n",
    "        test_true_rnn_fasttext_task2.extend(labels.view(-1).numpy())  # Flatten and store true labels\n",
    "\n",
    "# Calculate the F1-score\n",
    "f1_score_rnn_fasttext_task2 = f1_score(test_true_rnn_fasttext_task2, test_preds_rnn_fasttext_task2, average='macro')\n",
    "\n",
    "# Calculate the accuracy\n",
    "accuracy_rnn_fasttext_task2 = accuracy_score(test_true_rnn_fasttext_task2, test_preds_rnn_fasttext_task2)\n",
    "\n",
    "print(f\"Task2 - RNN Fasttext - F1: {f1_score_rnn_fasttext_task2}\")\n",
    "print(f\"Task2 - RNN Fasttext - Accuracy: {accuracy_rnn_fasttext_task2}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Delete the models and the dataloaders\n",
    "del model_fasttext_rnn_task2\n",
    "del model_glove_rnn_task2\n",
    "del model_word2vec_rnn_task2\n",
    "\n",
    "del test_dataloader_fasttext_rnn_task2\n",
    "del test_dataloader_glove_rnn_task2\n",
    "del test_dataloader_word2vec_rnn_task2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 2 - GLoVe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the LSTM model\n",
    "class LSTMModel_Task2(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, output_dim, num_layers, dropout):\n",
    "        super(LSTMModel_Task2, self).__init__()\n",
    "        self.lstm = nn.LSTM(input_dim, hidden_dim, num_layers, batch_first=True, dropout=dropout)\n",
    "        self.fc = nn.Linear(hidden_dim, output_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out, _ = self.lstm(x)\n",
    "        out = self.fc(out)  # Take the output of the last timestep\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 83, 300]) torch.Size([32, 83])\n"
     ]
    }
   ],
   "source": [
    "# Convert labels to indices for LSTM\n",
    "test_labels_lstm_fasttext_task2 = labels_to_indices(test_labels_task2.values(), labels_to_index_lstm_fasttext_task2)\n",
    "test_labels_lstm_glove_task2 = labels_to_indices(test_labels_task2.values(), labels_to_index_lstm_glove_task2)\n",
    "test_labels_lstm_word2vec_task2 = labels_to_indices(test_labels_task2.values(), labels_to_index_lstm_word2vec_task2)\n",
    "\n",
    "# Convert labels to tensor\n",
    "test_labels_lstm_fasttext_tensor_task2 = torch.tensor(test_labels_lstm_fasttext_task2, dtype=torch.long)\n",
    "test_labels_lstm_glove_tensor_task2 = torch.tensor(test_labels_lstm_glove_task2, dtype=torch.long)\n",
    "test_labels_lstm_word2vec_tensor_task2 = torch.tensor(test_labels_lstm_word2vec_task2, dtype=torch.long)\n",
    "\n",
    "# Dataloaders for LSTM\n",
    "test_dataset_fasttext_lstm_task2 = TensorDataset(embeddings_fasttext_task2, test_labels_lstm_fasttext_tensor_task2)\n",
    "test_dataloader_fasttext_lstm_task2 = DataLoader(test_dataset_fasttext_lstm_task2, batch_size=32, shuffle=False)\n",
    "\n",
    "test_dataset_glove_lstm_task2 = TensorDataset(embeddings_glove_task2, test_labels_lstm_glove_tensor_task2)\n",
    "test_dataloader_glove_lstm_task2 = DataLoader(test_dataset_glove_lstm_task2, batch_size=32, shuffle=False)\n",
    "\n",
    "test_dataset_word2vec_lstm_task2 = TensorDataset(embeddings_word2vec_task2, test_labels_lstm_word2vec_tensor_task2)\n",
    "test_dataloader_word2vec_lstm_task2 = DataLoader(test_dataset_word2vec_lstm_task2, batch_size=32, shuffle=False)\n",
    "\n",
    "# Iterate through dataloaders to check the shape of the data\n",
    "for i, (x, y) in enumerate(test_dataloader_fasttext_lstm_task2):\n",
    "    print(x.shape, y.shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Task2 - LSTM Word2Vec - F1: 0.7342678975895388\n",
      "Task2 - LSTM Word2Vec - Accuracy: 0.985049955921246\n",
      "Task2 - LSTM GLoVe - F1: 0.7813560882766556\n",
      "Task2 - LSTM GLoVe - Accuracy: 0.9864825154275639\n",
      "Task2 - LSTM Fasttext - F1: 0.5971760537214629\n",
      "Task2 - LSTM Fasttext - Accuracy: 0.9801645606817514\n"
     ]
    }
   ],
   "source": [
    "\"\"\"For Word2Vec\"\"\"\n",
    "\n",
    "model_word2vec_lstm_task2 = LSTMModel_Task2(input_dim=300, hidden_dim=256, output_dim=3, num_layers=1, dropout=0)\n",
    "\n",
    "# Load the model\n",
    "model_word2vec_lstm_task2.load_state_dict(torch.load(\"Task2_LSTM_Word2Vec_model.pth\"))\n",
    "\n",
    "# Set the model to evaluation mode\n",
    "model_word2vec_lstm_task2.eval()\n",
    "\n",
    "# Evaluation\n",
    "test_preds_lstm_word2vec_task2 = []\n",
    "test_true_lstm_word2vec_task2 = []\n",
    "\n",
    "with torch.no_grad():  # Do not compute gradients\n",
    "    for inputs, labels in test_dataloader_word2vec_lstm_task2:\n",
    "        outputs = model_word2vec_lstm_task2(inputs)\n",
    "        _, predicted = torch.max(outputs.data, 2)  # Get the predicted classes\n",
    "        \n",
    "        test_preds_lstm_word2vec_task2.extend(predicted.view(-1).numpy())  # Flatten and store predictions\n",
    "        test_true_lstm_word2vec_task2.extend(labels.view(-1).numpy())  # Flatten and store true labels\n",
    "\n",
    "# Calculate the F1-score\n",
    "f1_score_lstm_word2vec_task2 = f1_score(test_true_lstm_word2vec_task2, test_preds_lstm_word2vec_task2, average='macro')\n",
    "\n",
    "# Calculate the accuracy\n",
    "accuracy_lstm_word2vec_task2 = accuracy_score(test_true_lstm_word2vec_task2, test_preds_lstm_word2vec_task2)\n",
    "\n",
    "print(f\"Task2 - LSTM Word2Vec - F1: {f1_score_lstm_word2vec_task2}\")\n",
    "print(f\"Task2 - LSTM Word2Vec - Accuracy: {accuracy_lstm_word2vec_task2}\")\n",
    "\n",
    "\"\"\"For GLoVe\"\"\"\n",
    "\n",
    "model_glove_lstm_task2 = LSTMModel_Task2(input_dim=300, hidden_dim=256, output_dim=3, num_layers=1, dropout=0)\n",
    "\n",
    "# Load the model\n",
    "model_glove_lstm_task2.load_state_dict(torch.load(\"Task2_LSTM_GloVe_model.pth\"))\n",
    "\n",
    "# Set the model to evaluation mode\n",
    "model_glove_lstm_task2.eval()\n",
    "\n",
    "# Evaluation\n",
    "test_preds_lstm_glove_task2 = []\n",
    "test_true_lstm_glove_task2 = []\n",
    "\n",
    "with torch.no_grad():  # Do not compute gradients\n",
    "    for inputs, labels in test_dataloader_glove_lstm_task2:\n",
    "        outputs = model_glove_lstm_task2(inputs)\n",
    "        _, predicted = torch.max(outputs.data, 2)  # Get the predicted classes\n",
    "        \n",
    "        test_preds_lstm_glove_task2.extend(predicted.view(-1).numpy())  # Flatten and store predictions\n",
    "        test_true_lstm_glove_task2.extend(labels.view(-1).numpy())  # Flatten and store true labels\n",
    "\n",
    "# Calculate the F1-score\n",
    "f1_score_lstm_glove_task2 = f1_score(test_true_lstm_glove_task2, test_preds_lstm_glove_task2, average='macro')\n",
    "\n",
    "# Calculate the accuracy\n",
    "accuracy_lstm_glove_task2 = accuracy_score(test_true_lstm_glove_task2, test_preds_lstm_glove_task2)\n",
    "\n",
    "print(f\"Task2 - LSTM GLoVe - F1: {f1_score_lstm_glove_task2}\")\n",
    "print(f\"Task2 - LSTM GLoVe - Accuracy: {accuracy_lstm_glove_task2}\")\n",
    "\n",
    "\"\"\"For Fasttext\"\"\"\n",
    "\n",
    "model_fasttext_lstm_task2 = LSTMModel_Task2(input_dim=300, hidden_dim=256, output_dim=3, num_layers=1, dropout=0)\n",
    "\n",
    "# Load the model\n",
    "model_fasttext_lstm_task2.load_state_dict(torch.load(\"Task2_LSTM_Fasttext_model.pth\"))\n",
    "\n",
    "# Set the model to evaluation mode\n",
    "model_fasttext_lstm_task2.eval()\n",
    "\n",
    "# Evaluation\n",
    "test_preds_lstm_fasttext_task2 = []\n",
    "test_true_lstm_fasttext_task2 = []\n",
    "\n",
    "with torch.no_grad():  # Do not compute gradients\n",
    "    for inputs, labels in test_dataloader_fasttext_lstm_task2:\n",
    "        outputs = model_fasttext_lstm_task2(inputs)\n",
    "        _, predicted = torch.max(outputs.data, 2)  # Get the predicted classes\n",
    "        \n",
    "        test_preds_lstm_fasttext_task2.extend(predicted.view(-1).numpy())  # Flatten and store predictions\n",
    "        test_true_lstm_fasttext_task2.extend(labels.view(-1).numpy())  # Flatten and store true labels\n",
    "\n",
    "# Calculate the F1-score\n",
    "f1_score_lstm_fasttext_task2 = f1_score(test_true_lstm_fasttext_task2, test_preds_lstm_fasttext_task2, average='macro')\n",
    "\n",
    "# Calculate the accuracy\n",
    "accuracy_lstm_fasttext_task2 = accuracy_score(test_true_lstm_fasttext_task2, test_preds_lstm_fasttext_task2)\n",
    "\n",
    "print(f\"Task2 - LSTM Fasttext - F1: {f1_score_lstm_fasttext_task2}\")\n",
    "print(f\"Task2 - LSTM Fasttext - Accuracy: {accuracy_lstm_fasttext_task2}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Delete the models and the dataloaders\n",
    "del model_fasttext_lstm_task2\n",
    "del model_glove_lstm_task2\n",
    "del model_word2vec_lstm_task2\n",
    "\n",
    "del test_dataloader_fasttext_lstm_task2\n",
    "del test_dataloader_glove_lstm_task2\n",
    "del test_dataloader_word2vec_lstm_task2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 2 - GRU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the GRU model\n",
    "class GRUModel(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, output_dim, num_layers, dropout):\n",
    "        super(GRUModel, self).__init__()\n",
    "        self.gru = nn.GRU(input_dim, hidden_dim, num_layers, batch_first=True, dropout=dropout)\n",
    "        self.fc = nn.Linear(hidden_dim, output_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out, _ = self.gru(x)\n",
    "        out = self.fc(out)  # Take the output of the last timestep\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 83, 300]) torch.Size([32, 83])\n"
     ]
    }
   ],
   "source": [
    "# Convert labels to indices for GRU\n",
    "test_labels_gru_fasttext_task2 = labels_to_indices(test_labels_task2.values(), labels_to_index_gru_fasttext_task2)\n",
    "test_labels_gru_glove_task2 = labels_to_indices(test_labels_task2.values(), labels_to_index_gru_glove_task2)\n",
    "test_labels_gru_word2vec_task2 = labels_to_indices(test_labels_task2.values(), labels_to_index_gru_word2vec_task2)\n",
    "\n",
    "# Convert labels to tensor\n",
    "test_labels_gru_fasttext_tensor_task2 = torch.tensor(test_labels_gru_fasttext_task2, dtype=torch.long)\n",
    "test_labels_gru_glove_tensor_task2 = torch.tensor(test_labels_gru_glove_task2, dtype=torch.long)\n",
    "test_labels_gru_word2vec_tensor_task2 = torch.tensor(test_labels_gru_word2vec_task2, dtype=torch.long)\n",
    "\n",
    "# Dataloaders for GRU\n",
    "test_dataset_fasttext_gru_task2 = TensorDataset(embeddings_fasttext_task2, test_labels_gru_fasttext_tensor_task2)\n",
    "test_dataloader_fasttext_gru_task2 = DataLoader(test_dataset_fasttext_gru_task2, batch_size=32, shuffle=False)\n",
    "\n",
    "test_dataset_glove_gru_task2 = TensorDataset(embeddings_glove_task2, test_labels_gru_glove_tensor_task2)\n",
    "test_dataloader_glove_gru_task2 = DataLoader(test_dataset_glove_gru_task2, batch_size=32, shuffle=False)\n",
    "\n",
    "test_dataset_word2vec_gru_task2 = TensorDataset(embeddings_word2vec_task2, test_labels_gru_word2vec_tensor_task2)\n",
    "test_dataloader_word2vec_gru_task2 = DataLoader(test_dataset_word2vec_gru_task2, batch_size=32, shuffle=False)\n",
    "\n",
    "# Iterate through dataloaders to check the shape of the data\n",
    "for i, (x, y) in enumerate(test_dataloader_fasttext_gru_task2):\n",
    "    print(x.shape, y.shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Task2 - GRU Word2Vec - F1: 0.789032773905856\n",
      "Task2 - GRU Word2Vec - Accuracy: 0.9864825154275639\n",
      "Task2 - GRU GLoVe - F1: 0.8099840106802813\n",
      "Task2 - GRU GLoVe - Accuracy: 0.9875844842785777\n",
      "Task2 - GRU Fasttext - F1: 0.7181476427826373\n",
      "Task2 - GRU Fasttext - Accuracy: 0.9837275933000293\n"
     ]
    }
   ],
   "source": [
    "\"\"\"For Word2Vec\"\"\"\n",
    "\n",
    "model_word2vec_gru_task2 = GRUModel(input_dim=300, hidden_dim=256, output_dim=3, num_layers=1, dropout=0)\n",
    "\n",
    "# Load the model\n",
    "model_word2vec_gru_task2.load_state_dict(torch.load(\"Task2_GRU_Word2Vec_model.pth\"))\n",
    "\n",
    "# Set the model to evaluation mode\n",
    "model_word2vec_gru_task2.eval()\n",
    "\n",
    "# Evaluation\n",
    "test_preds_gru_word2vec_task2 = []\n",
    "test_true_gru_word2vec_task2 = []\n",
    "\n",
    "with torch.no_grad():  # Do not compute gradients\n",
    "    for inputs, labels in test_dataloader_word2vec_gru_task2:\n",
    "        outputs = model_word2vec_gru_task2(inputs)\n",
    "        _, predicted = torch.max(outputs.data, 2)  # Get the predicted classes\n",
    "        \n",
    "        test_preds_gru_word2vec_task2.extend(predicted.view(-1).numpy())  # Flatten and store predictions\n",
    "        test_true_gru_word2vec_task2.extend(labels.view(-1).numpy())  # Flatten and store true labels\n",
    "\n",
    "# Calculate the F1-score\n",
    "f1_score_gru_word2vec_task2 = f1_score(test_true_gru_word2vec_task2, test_preds_gru_word2vec_task2, average='macro')\n",
    "\n",
    "# Calculate the accuracy\n",
    "accuracy_gru_word2vec_task2 = accuracy_score(test_true_gru_word2vec_task2, test_preds_gru_word2vec_task2)\n",
    "\n",
    "print(f\"Task2 - GRU Word2Vec - F1: {f1_score_gru_word2vec_task2}\")\n",
    "print(f\"Task2 - GRU Word2Vec - Accuracy: {accuracy_gru_word2vec_task2}\")\n",
    "\n",
    "\"\"\"For GLoVe\"\"\"\n",
    "\n",
    "model_glove_gru_task2 = GRUModel(input_dim=300, hidden_dim=256, output_dim=3, num_layers=1, dropout=0)\n",
    "\n",
    "# Load the model\n",
    "model_glove_gru_task2.load_state_dict(torch.load(\"Task2_GRU_GloVe_model.pth\"))\n",
    "\n",
    "# Set the model to evaluation mode\n",
    "model_glove_gru_task2.eval()\n",
    "\n",
    "# Evaluation\n",
    "test_preds_gru_glove_task2 = []\n",
    "test_true_gru_glove_task2 = []\n",
    "\n",
    "with torch.no_grad():  # Do not compute gradients\n",
    "    for inputs, labels in test_dataloader_glove_gru_task2:\n",
    "        outputs = model_glove_gru_task2(inputs)\n",
    "        _, predicted = torch.max(outputs.data, 2)  # Get the predicted classes\n",
    "        \n",
    "        test_preds_gru_glove_task2.extend(predicted.view(-1).numpy())  # Flatten and store predictions\n",
    "        test_true_gru_glove_task2.extend(labels.view(-1).numpy())  # Flatten and store true labels\n",
    "\n",
    "# Calculate the F1-score\n",
    "f1_score_gru_glove_task2 = f1_score(test_true_gru_glove_task2, test_preds_gru_glove_task2, average='macro')\n",
    "\n",
    "# Calculate the accuracy\n",
    "accuracy_gru_glove_task2 = accuracy_score(test_true_gru_glove_task2, test_preds_gru_glove_task2)\n",
    "\n",
    "print(f\"Task2 - GRU GLoVe - F1: {f1_score_gru_glove_task2}\")\n",
    "print(f\"Task2 - GRU GLoVe - Accuracy: {accuracy_gru_glove_task2}\")\n",
    "\n",
    "\"\"\"For Fasttext\"\"\"\n",
    "\n",
    "model_fasttext_gru_task2 = GRUModel(input_dim=300, hidden_dim=256, output_dim=3, num_layers=1, dropout=0)\n",
    "\n",
    "# Load the model\n",
    "model_fasttext_gru_task2.load_state_dict(torch.load(\"Task2_GRU_Fasttext_model.pth\"))\n",
    "\n",
    "# Set the model to evaluation mode\n",
    "model_fasttext_gru_task2.eval()\n",
    "\n",
    "# Evaluation\n",
    "test_preds_gru_fasttext_task2 = []\n",
    "test_true_gru_fasttext_task2 = []\n",
    "\n",
    "with torch.no_grad():  # Do not compute gradients\n",
    "    for inputs, labels in test_dataloader_fasttext_gru_task2:\n",
    "        outputs = model_fasttext_gru_task2(inputs)\n",
    "        _, predicted = torch.max(outputs.data, 2)  # Get the predicted classes\n",
    "        \n",
    "        test_preds_gru_fasttext_task2.extend(predicted.view(-1).numpy())  # Flatten and store predictions\n",
    "        test_true_gru_fasttext_task2.extend(labels.view(-1).numpy())  # Flatten and store true labels\n",
    "\n",
    "# Calculate the F1-score\n",
    "f1_score_gru_fasttext_task2 = f1_score(test_true_gru_fasttext_task2, test_preds_gru_fasttext_task2, average='macro')\n",
    "\n",
    "# Calculate the accuracy\n",
    "accuracy_gru_fasttext_task2 = accuracy_score(test_true_gru_fasttext_task2, test_preds_gru_fasttext_task2)\n",
    "\n",
    "print(f\"Task2 - GRU Fasttext - F1: {f1_score_gru_fasttext_task2}\")\n",
    "print(f\"Task2 - GRU Fasttext - Accuracy: {accuracy_gru_fasttext_task2}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Delete the models and the dataloaders\n",
    "del model_fasttext_gru_task2\n",
    "del model_glove_gru_task2\n",
    "del model_word2vec_gru_task2\n",
    "\n",
    "del test_dataloader_fasttext_gru_task2\n",
    "del test_dataloader_glove_gru_task2\n",
    "del test_dataloader_word2vec_gru_task2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 2 - BiLSTM-CRF (Part 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Helper functions to train the model\n",
    "\"\"\"\n",
    "START_TAG = \"<START>\"\n",
    "STOP_TAG = \"<STOP>\"\n",
    "\n",
    "def argmax(vec):\n",
    "    # return the argmax as a python int\n",
    "    _, idx = torch.max(vec, 1)\n",
    "    return idx.item()\n",
    "\n",
    "def prepare_sequence(seq, to_ix):\n",
    "    idxs = [to_ix[w] for w in seq]\n",
    "    return torch.tensor(idxs, dtype=torch.long)\n",
    "\n",
    "# Compute log sum exp in a numerically stable way for the forward algorithm\n",
    "def log_sum_exp(vec):\n",
    "    max_score = vec[0, argmax(vec)]\n",
    "    max_score_broadcast = max_score.view(1, -1).expand(1, vec.size()[1])\n",
    "    return max_score + \\\n",
    "        torch.log(torch.sum(torch.exp(vec - max_score_broadcast)))\n",
    "\n",
    "class BiLSTM_CRF(nn.Module):\n",
    "\n",
    "    def __init__(self, tag_to_ix, embedding_dim, hidden_dim, batch_size):\n",
    "        super(BiLSTM_CRF, self).__init__()\n",
    "        self.embedding_dim = embedding_dim\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.tag_to_ix = tag_to_ix\n",
    "        self.batch_size = batch_size\n",
    "        self.tagset_size = len(tag_to_ix)\n",
    "\n",
    "        self.lstm = nn.LSTM(embedding_dim, hidden_dim // 2,\n",
    "                            num_layers=1, bidirectional=True)\n",
    "\n",
    "        # Maps the output of the LSTM into tag space.\n",
    "        self.hidden2tag = nn.Linear(hidden_dim, self.tagset_size)\n",
    "\n",
    "        # Matrix of transition parameters.  Entry i,j is the score of\n",
    "        # transitioning *to* i *from* j.\n",
    "        self.transitions = nn.Parameter(\n",
    "            torch.randn(self.tagset_size, self.tagset_size))\n",
    "\n",
    "        # These two statements enforce the constraint that we never transfer\n",
    "        # to the start tag and we never transfer from the stop tag\n",
    "        self.transitions.data[tag_to_ix[START_TAG], :] = -10000\n",
    "        self.transitions.data[:, tag_to_ix[STOP_TAG]] = -10000\n",
    "\n",
    "\n",
    "    def init_hidden(self, batch_size):\n",
    "        num_layers = 2 if self.lstm.bidirectional else 1\n",
    "        return (torch.randn(num_layers, batch_size, self.hidden_dim // 2),\n",
    "            torch.randn(num_layers, batch_size, self.hidden_dim // 2))\n",
    "\n",
    "    def _forward_alg(self, feats):\n",
    "        # Do the forward algorithm to compute the partition function\n",
    "        init_alphas = torch.full((1, self.tagset_size), -10000.)\n",
    "        # START_TAG has all of the score.\n",
    "        init_alphas[0][self.tag_to_ix[START_TAG]] = 0.\n",
    "\n",
    "        # Wrap in a variable so that we will get automatic backprop\n",
    "        forward_var = init_alphas\n",
    "\n",
    "        # Iterate through the sentence\n",
    "        for feat in feats:\n",
    "            alphas_t = []  # The forward tensors at this timestep\n",
    "            for next_tag in range(self.tagset_size):\n",
    "                # broadcast the emission score: it is the same regardless of\n",
    "                # the previous tag\n",
    "                emit_score = feat[next_tag].view(\n",
    "                    1, -1).expand(1, self.tagset_size)\n",
    "                # the ith entry of trans_score is the score of transitioning to\n",
    "                # next_tag from i\n",
    "                trans_score = self.transitions[next_tag].view(1, -1)\n",
    "                # The ith entry of next_tag_var is the value for the\n",
    "                # edge (i -> next_tag) before we do log-sum-exp\n",
    "                next_tag_var = forward_var + trans_score + emit_score\n",
    "                # The forward variable for this tag is log-sum-exp of all the\n",
    "                # scores.\n",
    "                alphas_t.append(log_sum_exp(next_tag_var).view(1))\n",
    "            forward_var = torch.cat(alphas_t).view(1, -1)\n",
    "        terminal_var = forward_var + self.transitions[self.tag_to_ix[STOP_TAG]]\n",
    "        alpha = log_sum_exp(terminal_var)\n",
    "        return alpha\n",
    "\n",
    "    def _get_lstm_features(self, embeds):\n",
    "        hidden = self.init_hidden(batch_size=embeds.shape[0])\n",
    "        embeds = embeds.permute(1, 0, 2)\n",
    "\n",
    "        lstm_out, hidden = self.lstm(embeds, hidden)\n",
    "        lstm_out = lstm_out.permute(1, 0, 2).contiguous().view(-1, self.hidden_dim)\n",
    "        lstm_feats = self.hidden2tag(lstm_out)\n",
    "        return lstm_feats\n",
    "\n",
    "    def _score_sentence(self, feats, tags):\n",
    "        # Gives the score of a provided tag sequence\n",
    "        score = torch.zeros(1)\n",
    "        tags = tags.view(-1) # flatten the tags\n",
    "        #print(torch.tensor([self.tag_to_ix[START_TAG]], dtype=torch.long).shape)\n",
    "        tags = torch.cat([torch.tensor([self.tag_to_ix[START_TAG]], dtype=torch.long), tags], dim=0)\n",
    "        for i, feat in enumerate(feats):\n",
    "            score = score + \\\n",
    "                self.transitions[tags[i + 1], tags[i]] + feat[tags[i + 1]]\n",
    "        score = score + self.transitions[self.tag_to_ix[STOP_TAG], tags[-1]]\n",
    "        return score\n",
    "\n",
    "    def _viterbi_decode(self, feats):\n",
    "        backpointers = []\n",
    "\n",
    "        # Initialize the viterbi variables in log space\n",
    "        init_vvars = torch.full((1, self.tagset_size), -10000.)\n",
    "        init_vvars[0][self.tag_to_ix[START_TAG]] = 0\n",
    "\n",
    "        # forward_var at step i holds the viterbi variables for step i-1\n",
    "        forward_var = init_vvars\n",
    "        for feat in feats:\n",
    "            bptrs_t = []  # holds the backpointers for this step\n",
    "            viterbivars_t = []  # holds the viterbi variables for this step\n",
    "\n",
    "            for next_tag in range(self.tagset_size):\n",
    "                # next_tag_var[i] holds the viterbi variable for tag i at the\n",
    "                # previous step, plus the score of transitioning\n",
    "                # from tag i to next_tag.\n",
    "                # We don't include the emission scores here because the max\n",
    "                # does not depend on them (we add them in below)\n",
    "                next_tag_var = forward_var + self.transitions[next_tag]\n",
    "                best_tag_id = argmax(next_tag_var)\n",
    "                bptrs_t.append(best_tag_id)\n",
    "                viterbivars_t.append(next_tag_var[0][best_tag_id].view(1))\n",
    "            # Now add in the emission scores, and assign forward_var to the set\n",
    "            # of viterbi variables we just computed\n",
    "            forward_var = (torch.cat(viterbivars_t) + feat).view(1, -1)\n",
    "            backpointers.append(bptrs_t)\n",
    "\n",
    "        # Transition to STOP_TAG\n",
    "        terminal_var = forward_var + self.transitions[self.tag_to_ix[STOP_TAG]]\n",
    "        best_tag_id = argmax(terminal_var)\n",
    "        path_score = terminal_var[0][best_tag_id]\n",
    "\n",
    "        # Follow the back pointers to decode the best path.\n",
    "        best_path = [best_tag_id]\n",
    "        for bptrs_t in reversed(backpointers):\n",
    "            best_tag_id = bptrs_t[best_tag_id]\n",
    "            best_path.append(best_tag_id)\n",
    "        # Pop off the start tag (we dont want to return that to the caller)\n",
    "        start = best_path.pop()\n",
    "        assert start == self.tag_to_ix[START_TAG]  # Sanity check\n",
    "        best_path.reverse()\n",
    "        return path_score, best_path\n",
    "\n",
    "    def neg_log_likelihood(self, embeddings, tags):\n",
    "        feats = self._get_lstm_features(embeds=embeddings)\n",
    "        forward_score = self._forward_alg(feats)\n",
    "        gold_score = self._score_sentence(feats, tags)\n",
    "        return forward_score - gold_score\n",
    "\n",
    "    def forward(self, sentence):  # dont confuse this with _forward_alg above.\n",
    "        # Get the emission scores from the BiLSTM\n",
    "        lstm_feats = self._get_lstm_features(sentence)\n",
    "\n",
    "        # Find the best path, given the features.\n",
    "        score, tag_seq = self._viterbi_decode(lstm_feats)\n",
    "        return score, tag_seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 83, 300]) torch.Size([1, 83])\n"
     ]
    }
   ],
   "source": [
    "# Convert labels to indices for BiLSTM-CRF\n",
    "test_labels_bilstmcrf_fasttext_task2 = labels_to_indices(test_labels_task2.values(), labels_to_index_bilstmcrf_fasttext_task2)\n",
    "test_labels_bilstmcrf_glove_task2 = labels_to_indices(test_labels_task2.values(), labels_to_index_bilstmcrf_glove_task2)\n",
    "test_labels_bilstmcrf_word2vec_task2 = labels_to_indices(test_labels_task2.values(), labels_to_index_bilstmcrf_word2vec_task2)\n",
    "\n",
    "# Convert labels to tensor\n",
    "test_labels_bilstmcrf_fasttext_tensor_task2 = torch.tensor(test_labels_bilstmcrf_fasttext_task2, dtype=torch.long)\n",
    "test_labels_bilstmcrf_glove_tensor_task2 = torch.tensor(test_labels_bilstmcrf_glove_task2, dtype=torch.long)\n",
    "test_labels_bilstmcrf_word2vec_tensor_task2 = torch.tensor(test_labels_bilstmcrf_word2vec_task2, dtype=torch.long)\n",
    "\n",
    "# Dataloaders for BiLSTM-CRF\n",
    "test_dataset_fasttext_bilstmcrf_task2 = TensorDataset(embeddings_fasttext_task2, test_labels_bilstmcrf_fasttext_tensor_task2)\n",
    "test_dataloader_fasttext_bilstmcrf_task2 = DataLoader(test_dataset_fasttext_bilstmcrf_task2, batch_size=1, shuffle=False)\n",
    "\n",
    "test_dataset_glove_bilstmcrf_task2 = TensorDataset(embeddings_glove_task2, test_labels_bilstmcrf_glove_tensor_task2)\n",
    "test_dataloader_glove_bilstmcrf_task2 = DataLoader(test_dataset_glove_bilstmcrf_task2, batch_size=1, shuffle=False)\n",
    "\n",
    "test_dataset_word2vec_bilstmcrf_task2 = TensorDataset(embeddings_word2vec_task2, test_labels_bilstmcrf_word2vec_tensor_task2)\n",
    "test_dataloader_word2vec_bilstmcrf_task2 = DataLoader(test_dataset_word2vec_bilstmcrf_task2, batch_size=1, shuffle=False)\n",
    "\n",
    "# Iterate through dataloaders to check the shape of the data\n",
    "for i, (x, y) in enumerate(test_dataloader_fasttext_bilstmcrf_task2):\n",
    "    print(x.shape, y.shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Task2 - BiLSTM-CRF Word2Vec - F1: 0.7933406056758345\n",
      "Task2 - BiLSTM-CRF Word2Vec - Accuracy: 0.9868131060828681\n"
     ]
    }
   ],
   "source": [
    "\"\"\"For Word2Vec\"\"\"\n",
    "\n",
    "model_word2vec_bilstmcrf_task2 = BiLSTM_CRF(tag_to_ix=labels_to_index_bilstmcrf_word2vec_task2, embedding_dim=300, hidden_dim=256, batch_size=1)\n",
    "\n",
    "# Load the model\n",
    "model_word2vec_bilstmcrf_task2.load_state_dict(torch.load(\"Task2_BiLSTMCRF_Word2Vec.pt\"))\n",
    "\n",
    "# Evaluation\n",
    "test_preds_bilstmcrf_word2vec_task2 = []\n",
    "test_true_bilstmcrf_word2vec_task2 = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for i, (embeddings, labels) in enumerate(test_dataloader_word2vec_bilstmcrf_task2):\n",
    "        # Run forward pass\n",
    "        _, predicted = model_word2vec_bilstmcrf_task2(embeddings)\n",
    "        predicted = torch.tensor(predicted, dtype=torch.long)\n",
    "        labels = labels.view(-1)\n",
    "        predicted = predicted.view(-1)\n",
    "\n",
    "        # Append the predictions and true labels\n",
    "        test_preds_bilstmcrf_word2vec_task2.extend(predicted.tolist())\n",
    "        test_true_bilstmcrf_word2vec_task2.extend(labels.tolist())\n",
    "\n",
    "# Calculate the F1-score\n",
    "f1_score_bilstmcrf_word2vec_task2 = f1_score(test_true_bilstmcrf_word2vec_task2, test_preds_bilstmcrf_word2vec_task2, average='macro')\n",
    "\n",
    "# Calculate the accuracy\n",
    "accuracy_bilstmcrf_word2vec_task2 = accuracy_score(test_true_bilstmcrf_word2vec_task2, test_preds_bilstmcrf_word2vec_task2)\n",
    "\n",
    "print(f\"Task2 - BiLSTM-CRF Word2Vec - F1: {f1_score_bilstmcrf_word2vec_task2}\")\n",
    "print(f\"Task2 - BiLSTM-CRF Word2Vec - Accuracy: {accuracy_bilstmcrf_word2vec_task2}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Task2 - BiLSTM-CRF GLOVE - F1: 0.8351154940267326\n",
      "Task2 - BiLSTM-CRF GLOVE - Accuracy: 0.9892374375550984\n",
      "Task2 - BiLSTM-CRF Fasttext - F1: 0.8031410157889162\n",
      "Task2 - BiLSTM-CRF Fasttext - Accuracy: 0.9861886570672935\n"
     ]
    }
   ],
   "source": [
    "\"\"\"Glove\"\"\"\n",
    "\n",
    "model_glove_bilstmcrf_task2 = BiLSTM_CRF(tag_to_ix=labels_to_index_bilstmcrf_glove_task2, embedding_dim=300, hidden_dim=256, batch_size=1)\n",
    "\n",
    "# Load the model\n",
    "model_glove_bilstmcrf_task2.load_state_dict(torch.load(\"Task2_BiLSTMCRF_Glove.pt\"))\n",
    "\n",
    "# Evaluation\n",
    "test_preds_bilstmcrf_glove_task2 = []\n",
    "test_true_bilstmcrf_glove_task2 = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for i, (embeddings, labels) in enumerate(test_dataloader_glove_bilstmcrf_task2):\n",
    "        # Run forward pass\n",
    "        _, predicted = model_glove_bilstmcrf_task2(embeddings)\n",
    "        predicted = torch.tensor(predicted, dtype=torch.long)\n",
    "        labels = labels.view(-1)\n",
    "        predicted = predicted.view(-1)\n",
    "\n",
    "        # Append the predictions and true labels\n",
    "        test_preds_bilstmcrf_glove_task2.extend(predicted.tolist())\n",
    "        test_true_bilstmcrf_glove_task2.extend(labels.tolist())\n",
    "\n",
    "# Calculate the F1-score\n",
    "f1_score_bilstmcrf_glove_task2 = f1_score(test_true_bilstmcrf_glove_task2, test_preds_bilstmcrf_glove_task2, average='macro')\n",
    "\n",
    "# Calculate the accuracy\n",
    "accuracy_bilstmcrf_glove_task2 = accuracy_score(test_true_bilstmcrf_glove_task2, test_preds_bilstmcrf_glove_task2)\n",
    "\n",
    "print(f\"Task2 - BiLSTM-CRF GLOVE - F1: {f1_score_bilstmcrf_glove_task2}\")\n",
    "print(f\"Task2 - BiLSTM-CRF GLOVE - Accuracy: {accuracy_bilstmcrf_glove_task2}\")\n",
    "\n",
    "\"\"\"Fasttext\"\"\"\n",
    "\n",
    "model_fasttext_bilstmcrf_task2 = BiLSTM_CRF(tag_to_ix=labels_to_index_bilstmcrf_fasttext_task2, embedding_dim=300, hidden_dim=256, batch_size=1)\n",
    "\n",
    "# Load the model\n",
    "model_fasttext_bilstmcrf_task2.load_state_dict(torch.load(\"Task2_BiLSTMCRF_Fasttext.pt\"))\n",
    "\n",
    "# Evaluation\n",
    "test_preds_bilstmcrf_fasttext_task2 = []\n",
    "test_true_bilstmcrf_fasttext_task2 = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for i, (embeddings, labels) in enumerate(test_dataloader_fasttext_bilstmcrf_task2):\n",
    "        # Run forward pass\n",
    "        _, predicted = model_fasttext_bilstmcrf_task2(embeddings)\n",
    "        predicted = torch.tensor(predicted, dtype=torch.long)\n",
    "        labels = labels.view(-1)\n",
    "        predicted = predicted.view(-1)\n",
    "\n",
    "        # Append the predictions and true labels\n",
    "        test_preds_bilstmcrf_fasttext_task2.extend(predicted.tolist())\n",
    "        test_true_bilstmcrf_fasttext_task2.extend(labels.tolist())\n",
    "\n",
    "# Calculate the F1-score\n",
    "f1_score_bilstmcrf_fasttext_task2 = f1_score(test_true_bilstmcrf_fasttext_task2, test_preds_bilstmcrf_fasttext_task2, average='macro')\n",
    "\n",
    "# Calculate the accuracy\n",
    "accuracy_bilstmcrf_fasttext_task2 = accuracy_score(test_true_bilstmcrf_fasttext_task2, test_preds_bilstmcrf_fasttext_task2)\n",
    "\n",
    "print(f\"Task2 - BiLSTM-CRF Fasttext - F1: {f1_score_bilstmcrf_fasttext_task2}\")\n",
    "print(f\"Task2 - BiLSTM-CRF Fasttext - Accuracy: {accuracy_bilstmcrf_fasttext_task2}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Delete the models and the dataloaders\n",
    "del model_fasttext_bilstmcrf_task2\n",
    "del model_glove_bilstmcrf_task2\n",
    "del model_word2vec_bilstmcrf_task2\n",
    "\n",
    "del test_dataloader_fasttext_bilstmcrf_task2\n",
    "del test_dataloader_glove_bilstmcrf_task2\n",
    "del test_dataloader_word2vec_bilstmcrf_task2"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
